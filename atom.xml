<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>我的梦想是星辰大海</title>
  
  <subtitle>知识源于积累,登峰造极源于自律</subtitle>
  <link href="http://xubatian.cn/atom.xml" rel="self"/>
  
  <link href="http://xubatian.cn/"/>
  <updated>2022-02-14T07:00:18.604Z</updated>
  <id>http://xubatian.cn/</id>
  
  <author>
    <name>xubatian</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink 原理与实现: Flink中的Window API</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%B8%AD%E7%9A%84Window-API/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%B8%AD%E7%9A%84Window-API/</id>
    <published>2022-02-14T06:26:50.000Z</published>
    <updated>2022-02-14T07:00:18.604Z</updated>
    
    <content type="html"><![CDATA[<p>附录算子俯瞰图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214142001.png"></p><span id="more"></span><h1 id="TimeWindow-时间窗口"><a href="#TimeWindow-时间窗口" class="headerlink" title="TimeWindow(时间窗口)"></a>TimeWindow(时间窗口)</h1><p><strong>时间窗口有三种:滚动窗口,滑动窗口, 会话窗口</strong></p><p>​        <strong>TimeWindow是将指定时间范围内的所有数据组成一个window，一次对一个window里面的所有数据进行计算。</strong></p><p>​        注意：timeWindow函数必须在keyBy之后，timeWindowAll则不需要</p><p><strong>不管你是三种窗口中的哪一种，如果你的窗口函数的后面没有加All的话，那就是基于我们的keyedStream的，加了All就是基于我们的DataStream的.</strong></p><h2 id="1-滚动窗口（Tumbling-Window）"><a href="#1-滚动窗口（Tumbling-Window）" class="headerlink" title="1.滚动窗口（Tumbling Window）"></a>1.滚动窗口（Tumbling Window）</h2><p>Flink默认的时间窗口根据Processing Time 进行窗口的划分，将Flink获取到的数据根据进入Flink的时间划分到不同的窗口中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val minTempPerWindow = dataStream</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .timeWindow(Time.seconds(15))</span><br><span class="line">  .reduce((r1, r2) =&gt; (r1._1, r1._2.min(r2._2)))</span><br></pre></td></tr></table></figure><p>注意:</p><p>​        滚动窗口一定要在keyBy之后去调用.keyBy之后调用的话,由于它是滚动窗口.我们只需要传一个参数,就是窗口的长度就可以了.<br>​        如果你仔细想的话,你发现有一个问题:  就是假设我窗口的长度为15秒,那么当前某一个窗口他的起始的时间是怎么算的?是不是就是把你当前的时间除以15呀.直接除以15取模,取模之后的到一个什么?</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214143417.png"></p><p>​            时间间隔可以通过<strong>Time.milliseconds(x)毫秒，Time.seconds(x)秒，Time.minutes(x)分钟</strong>,等其中的一个来指定。</p><p>​            TimeWindow()实际上就是设置我们的窗口.窗口设置好之后,要么做聚合要么做其他操做,一般来说就是做聚合.</p><h2 id="2-滑动窗口（SlidingEventTimeWindows）"><a href="#2-滑动窗口（SlidingEventTimeWindows）" class="headerlink" title="2.滑动窗口（SlidingEventTimeWindows）"></a>2.滑动窗口（SlidingEventTimeWindows）</h2><p>​        <strong>滑动窗口和滚动窗口的函数名是完全一致的</strong>，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。</p><p>​        下面代码中的sliding_size设置为了5s，也就是说，窗口每5s就计算一次，每一次计算的window范围是15s内的所有元素。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val minTempPerWindow: DataStream[(String, Double)] = dataStream</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .timeWindow(Time.seconds(15), Time.seconds(5))</span><br><span class="line">  .reduce((r1, r2) =&gt; (r1._1, r1._2.min(r2._2)))</span><br><span class="line">.window(EventTimeSessionWindows.withGap(Time.minutes(10))</span><br></pre></td></tr></table></figure><p><strong>时间间隔可以通过Time.milliseconds(x)，Time.seconds(x)，Time.minutes(x)等其中的一个来指定。</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214143631.png"></p><h1 id="CountWindow-计数窗口"><a href="#CountWindow-计数窗口" class="headerlink" title="CountWindow(计数窗口)"></a>CountWindow(计数窗口)</h1><p>​        **CountWindow(计数窗口)**也有所谓的滚动窗口和滑动窗口,但是他只有这两个,没有所谓的会话窗口</p><p>​        CountWindow根据窗口中相同key元素的数量来触发执行，执行时只计算元素数量达到窗口大小的key对应的结果。</p><p>​        注意：CountWindow的window_size指的是相同Key的元素的个数，不是输入的所有元素的总数。</p><h2 id="1-滚动窗口（Tumbling-Window）-1"><a href="#1-滚动窗口（Tumbling-Window）-1" class="headerlink" title="1.滚动窗口（Tumbling Window）"></a>1.滚动窗口（Tumbling Window）</h2><p>​       <strong>默认的CountWindow是一个滚动窗口，只需要指定窗口大小即可，当元素数量达到窗口大小时，就会触发窗口的执行。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val minTempPerWindow: DataStream[(String, Double)] = dataStream</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .countWindow(5)</span><br><span class="line">  .reduce((r1, r2) =&gt; (r1._1, r1._2.max(r2._2)))</span><br></pre></td></tr></table></figure><h2 id="2-滑动窗口（SlidingEventTimeWindows）-1"><a href="#2-滑动窗口（SlidingEventTimeWindows）-1" class="headerlink" title="2.滑动窗口（SlidingEventTimeWindows）"></a>2.滑动窗口（SlidingEventTimeWindows）</h2><p>​        滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。</p><p>​        下面代码中的sliding_size设置为了2，也就是说，每收到两个相同key的数据就计算一次，每一次计算的window范围是5个元素。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val keyedStream: KeyedStream[(String, Int), Tuple] = dataStream.map(r =&gt; (r.id, r.temperature)).keyBy(0)</span><br><span class="line">//每当某一个key的个数达到2的时候,触发计算，计算最近该key最近10个元素的内容</span><br><span class="line">val windowedStream: WindowedStream[(String, Int), Tuple, GlobalWindow] = keyedStream.countWindow(10,2)</span><br><span class="line">val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</span><br></pre></td></tr></table></figure><h1 id="window-function-窗口函数"><a href="#window-function-窗口函数" class="headerlink" title="window function(窗口函数)"></a>window function(窗口函数)</h1><p> <strong>window function(窗口函数) :  这里面有增量聚合函数和全窗口函数</strong></p><p>​        <strong>window function 定义了要对窗口中收集的数据做的计算操作，主要可以分为两类：</strong></p><h2 id="1-增量聚合函数（incremental-aggregation-functions）"><a href="#1-增量聚合函数（incremental-aggregation-functions）" class="headerlink" title="1.增量聚合函数（incremental aggregation functions）"></a>1.增量聚合函数（incremental aggregation functions）</h2><p>​                        每条数据到来就进行计算，保持一个简单的状态。典型的增量聚合函数有ReduceFunction, AggregateFunction。</p><h2 id="2-全窗口函数（full-window-functions）"><a href="#2-全窗口函数（full-window-functions）" class="headerlink" title="2.全窗口函数（full window functions）"></a>2.全窗口函数（full window functions）</h2><p>​                        先把窗口所有数据收集起来，等到计算的时候会遍历所有数据。</p><p>​                        ProcessWindowFunction和ProcessAllWindowFunction就是一个全窗口函数。</p><p>​                        Apply也是全量的.</p><h1 id="其它可选API"><a href="#其它可选API" class="headerlink" title="其它可选API"></a>其它可选API</h1><p><strong>.trigger() —— 触发器</strong></p><p>定义 window 什么时候关闭，触发计算并输出结果</p><p><strong>.evitor() —— 移除器</strong></p><p>定义移除某些数据的逻辑</p><p><strong>.allowedLateness()</strong> —— 允许处理迟到的数据</p><p><strong>.sideOutputLateData()</strong> —— 将迟到的数据放入侧输出流</p><p><strong>.getSideOutput()</strong> —— 获取侧输出流</p><h2 id="什么叫允许处理迟到的数据"><a href="#什么叫允许处理迟到的数据" class="headerlink" title="什么叫允许处理迟到的数据?"></a>什么叫允许处理迟到的数据?</h2><p>这个时候就得考虑,我们的开窗的规则.他到底是按照什么时间来确定的.如果你开窗的规则不是按照执行时间,而是按照数据生成的时间.那就有可能出现所谓迟到的数据.举例:假设我数据的产生是在2:05分产生的.产生数据之后通过kafka再到我们的flink里面.中间是不是有一个过程呀?中间可能隔离一分钟等时间.然后到了我们的FlinkJob里面之后,Flink Job默认情况下他不是探讨你的数据生成的时间,而是探讨执行时间.执行时间肯定是按照顺序来的.但有没有可能是2:05产生的数据先来,下一条数据是2:04分生成的数据呢?当然有可能.所以假设以后要做这个流处理,要严格按照这个数据的生成时间,那这个时候就会出现所谓的迟到的数据.比如说2:05分的数据来了之后发现2:04分的数据还没来.他是真正执行完之后可能下一个窗口才来.那这个就叫所谓的迟到的数据.如果你要严格按照时间顺序的话,你就需要将2:05分的数据等一下.就要想办法让2:04分的这个迟到的数据放到2:05分的数据之前处理.那有什么解决办法呢?</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214145930.png"></p><p>**这三个操作就是其中一个解决方法.就是把迟到的数据单独放到一个分支流数据中.叫侧输出流.放到侧输出流中,我们还得取到侧输出流中的数据.这就是一个不太好的办法.**这个实际上也没法做到实时性.而且你也不知道到底哪个是迟到的数据.什么样的数据才算做迟到的数据.没有一个标准.所以这种处理迟到数据的办法不是最好的.只是他是其中一种.当然还有其他的一些参数,这里只介绍到这里.</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214150000.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;附录算子俯瞰图:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214142001.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink中的Window</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%B8%AD%E7%9A%84Window/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%B8%AD%E7%9A%84Window/</id>
    <published>2022-02-14T06:03:51.000Z</published>
    <updated>2022-02-14T06:22:43.400Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Window主要分为哪几种?</strong><br>window主要分为<br><strong>CountWindow</strong>:  计数窗口:按照指定的数据条数生成一个Window，与时间无关。</p><p><strong>TimeWindow</strong>:    时间窗口:按照指定的数据条数生成一个Window，与时间无关。</p><p>而我们最关心的就是<strong>TimeWindow</strong>,因为他和时间有关系.<br><strong>TimeWindow又分为三种: 滑动窗口,滚动窗口,会话窗口.</strong></p><p>滚动窗口和滑动窗口有一个特点,就是他们的时间是对齐的.</p><p>所谓的时间对齐是什么意思呢?</p><span id="more"></span><p>就是你不管是哪一个并行度,里面所有的时间是对齐的.对齐说的是数据的时间对齐.比如说我这窗口的起始时间是10:05分,那我所有的,只要是10:05分的数据,都属于我接下来这新开的窗口.因为我假设我开窗的起始时间,实际上说的就是 我的开窗时间是10:05分的话,那么我不管你是哪个组的,也不管你是哪个分区的.我们的数据只要到达10:05分,就属于当前我们这个窗口.这就叫所谓的时间对齐.滚动窗口是没有滑动步长的,只有滑动窗口才有滑动步长.</p><p>​    如果我们在选择窗口开窗的时候,还需要对窗口里面的数据进行处理.对数据进行处理的话,我们称之为windowFunction,也称之为窗口函数.<br>​    <strong>WindowFunction(窗口函数)分为两类,一类叫增量聚合函数,另一种叫全窗口函数</strong><br>​    增量聚合函数的意思就是说,在窗口里面,因为一个窗口是一个起始时间到结束时间.这个时间段内,源源不断的会有数据过来.那么你来一条数据我就处理一条数据,来一条数据我就处理一条数据.这是一种情况.还有一种情况就是全窗口函数,等这个窗口结束了,所有数据都来了,我一次性处理.这两种处理方式就是所谓的增量聚合函数和全窗口函数.在大多数的</p><p>​    生产环境中,我们使用增量聚合函数比较合适.因为假设你后面一个窗口里面数据量特别多的话.你如果一次性全部处理的话,你处理时间是比较长的.但是如果我数据量很多,我来一条就处理一条,来一条就处理一条,那我事实上我就把我处理的时间均匀的分散到这个很长的时间段里面去了.所以他实际上比不会耽误我们的时间.</p><p>所以我们重点关心增量聚合函数.他有两大类,<br><strong>一个叫ReduceFunction,另一个叫AggregateFunction,都是属于增量聚合函数.</strong></p><h1 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h1><p>Window开窗,开往窗口之后怎么办?是由windowFunctions来决定的</p><p><strong>Window就是把无限的流，按照时间或者条数或者会话切成有限的流。本来你的流是无限的,我们按照一定规则切成一段一段的有限的流.而每一小段就是一段窗口(window)</strong></p><h2 id="Window概述"><a href="#Window概述" class="headerlink" title="Window概述"></a>Window概述</h2><p>​        Spark streaming流式计算是一种被设计用于处理无限数据集的数据处理引擎，而无限数据集是指一种不断增长的本质上无限的数据集，而<strong>window是一种切割无限数据为有限块进行处理的手段</strong>。</p><p>​        Window是无限数据流处理的核心，Window将一个无限的stream拆分成有限大小的”buckets”桶，我们可以在这些桶上做计算操作。</p><h2 id="Window类型"><a href="#Window类型" class="headerlink" title="Window类型"></a>Window类型</h2><p><strong>Window可以分成两类</strong>：<br>        CountWindow(计数窗口)：按照指定的数据条数生成一个Window，与时间无关。<br>        TimeWindow(时间窗口)：按照时间生成Window。<br>对于TimeWindow，可以根据窗口实现原理的不同分成三类：<strong>滚动窗口（Tumbling Window）、滑动窗口（Sliding Window）和会话窗口(Session Window）。</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141018.png"></p><p><strong>滑动窗口有可能有某两条数据进到第一个窗口同时又进入到第二个窗口</strong></p><p><strong>滚动窗口只要设置窗口的长度就可以了.</strong></p><h3 id="1-滚动窗口（Tumbling-Windows）"><a href="#1-滚动窗口（Tumbling-Windows）" class="headerlink" title="1.滚动窗口（Tumbling Windows）"></a>1.滚动窗口（Tumbling Windows）</h3><p>将数据依据固定的窗口长度对数据进行切片。<br><strong>特点：时间对齐，窗口长度固定，没有重叠。</strong></p><p><strong>时间对齐是啥意思?什么情况下时间对齐?如果你的窗口没有加ALL的话</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141145.png"></p><p>​        我们的窗口是基于KeyedStream的.就是分完组之后再使用窗口函数.你既然是KeyedStream那就是有很多一组一组的数据.如下图所示: user1,user2,user3你可以理解为三个组.这三个组他的时间一定是一致的.所以称之为时间对齐.就是说,如果Window1的时间是2019年11月11日11点11分11秒的话,那么window2,window3,window4等等所有的滑动窗口的组都是这个时间.所以说是时间对齐.窗口长度固定,没有重叠.没有重叠就是说任何一条数据不可能重复进入到两个窗口.随意说,我们定义这样的一个滚动窗口只需要定义窗口长度就可以了.</p><p>滚动窗口分配器将每个元素分配到一个指定窗口大小的窗口中，滚动窗口有一个固定的大小，并且不会出现重叠。例如：如果你指定了一个5分钟大小的滚动窗口，窗口的创建如下图所示：</p><p><strong>滚动窗口</strong>示例图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141305.png"></p><p><strong>适用场景</strong>：适合做BI统计等（做每个时间段的聚合计算）。</p><h3 id="2-滑动窗口（Sliding-Windows）"><a href="#2-滑动窗口（Sliding-Windows）" class="headerlink" title="2.滑动窗口（Sliding Windows）"></a>2.滑动窗口（Sliding Windows）</h3><p>滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成。</p><p><strong>特点：时间对齐，窗口长度固定,增加滑动步长，可以有重叠。</strong></p><p>​    由于他增加了滑动步长,所以说,他可以出现数据的重叠.<br>​    滑动窗口分配器将元素分配到固定长度的窗口中，与滚动窗口类似，窗口的大小由窗口大小参数来配置，另一个窗口滑动参数控制滑动窗口开始的频率。因此，滑动窗口如果滑动参数小于窗口大小的话，窗口是可以重叠的，在这种情况下元素会被分配到多个窗口中。<br>​    例如，你有10分钟的窗口和5分钟的滑动，那么每个窗口中5分钟的窗口里包含着上个10分钟产生的数据，如下图所示：</p><p><strong>滑动窗口</strong>示例图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141539.png"></p><p><strong>适用场景</strong>：对最近一个时间段内的统计（求某接口最近5min的失败率来决定是否要报警）。</p><h3 id="3-会话窗口（Session-Windows）"><a href="#3-会话窗口（Session-Windows）" class="headerlink" title="3.会话窗口（Session Windows）"></a>3.会话窗口（Session Windows）</h3><p>​        会话窗口就是说在<strong>某一个你指定的时间长度内.没有数据来了.假设我规定这个时间长度为5秒.那么上一个窗口结束之后5秒内都没有数据来.5秒钟之后,到第六秒开始有数据来了.那么我们就认为,从第六秒开始,就是一个新的窗口了</strong>.所以他中间有一个时间的间隙.这就称之为会话窗口.为什么称之为会话窗口呢?因为你发现没有,既然他有时间的间隙的话,就好比一次一次的会话一样.</p><p>​        假如你开发了一个web项目跑在Tomcat里面的话.默认情况下,会话的超时时间是多少?半小时.所谓默认的会话超时时间是什么意思?他这个半小时是从什么时刻开始算的?是从你这个会话的最后一次访问的时间开始算的.半个小时之后你这个会话就超时了. 会话超时的话,说白了你这个会话就结束了.那么以后来的数据就是另外一个会话.或者以后来的请求就是另外一个会话.这里我们的timeout就是所谓的会话超时时间.这个会话超时时间假设你设定为5秒.那么这5秒从哪里开始算呢?就是从window1的最后一条数据进来的时间开始算.5秒钟之后,如果你还是没有数据来.那么就会产生一个窗口2;但是假设你这5秒钟内还一直有数据来呢?有数据来还是属于window1.而这个window1的边界就开始往后延伸.因为他是严格按照会话的超时时间来进行切割window.来切割widow的话,这个特点就是他这个时间没有对齐的.</p><p>​        很明显时间没有对齐呀!因为很有可能某一个window他的数据量比较大,且时间跨度比较长.那么下一个窗口的量比较大,时间跨度比较短,这也是有可能的.所以时间无对齐的. </p><p>​         所以会话窗口（Session Windows）由一系列事件组合一个指定时间长度的timeout间隙组成，类似于web应用的session，也就是一段时间没有接收到新数据就会生成新的窗口。</p><p>​        特点：时间无对齐。</p><p>​        session窗口分配器通过session活动来对元素进行分组，session窗口跟滚动窗口和滑动窗口相比，不会有重叠和固定的开始时间和结束时间的情况，相反，当它在一个固定的时间周期内不再收到元素，即非活动间隔产生，那个这个窗口就会关闭。一个session窗口通过一个session间隔来配置，这个session间隔定义了非活跃周期的长度，当这个非活跃周期产生，那么当前的session将关闭并且后续的元素将被分配到新的session窗口中去。</p><p><strong>会话窗口</strong>示例图</p><p>​    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141811.png"></p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214142001.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Window主要分为哪几种?&lt;/strong&gt;&lt;br&gt;window主要分为&lt;br&gt;&lt;strong&gt;CountWindow&lt;/strong&gt;:  计数窗口:按照指定的数据条数生成一个Window，与时间无关。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TimeWindow&lt;/strong&gt;:    时间窗口:按照指定的数据条数生成一个Window，与时间无关。&lt;/p&gt;
&lt;p&gt;而我们最关心的就是&lt;strong&gt;TimeWindow&lt;/strong&gt;,因为他和时间有关系.&lt;br&gt;&lt;strong&gt;TimeWindow又分为三种: 滑动窗口,滚动窗口,会话窗口.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;滚动窗口和滑动窗口有一个特点,就是他们的时间是对齐的.&lt;/p&gt;
&lt;p&gt;所谓的时间对齐是什么意思呢?&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>YARN调度器【capacity-scheduler.xml】默认配置</title>
    <link href="http://xubatian.cn/Hadoop%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/YARN%E8%B0%83%E5%BA%A6%E5%99%A8%E3%80%90capacity-scheduler-xml%E3%80%91%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE/"/>
    <id>http://xubatian.cn/Hadoop%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/YARN%E8%B0%83%E5%BA%A6%E5%99%A8%E3%80%90capacity-scheduler-xml%E3%80%91%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE/</id>
    <published>2022-02-12T10:11:21.000Z</published>
    <updated>2022-02-12T10:20:31.134Z</updated>
    
    <content type="html"><![CDATA[<p>Hadoop版本：3.1.3</p><pre><code>1、三种常见调度器    1.1、先进先出调度器    1.2、容量调度器    1.3、公平调度器2、容量调度器 多队列配置3、单词4、默认配置【capacity-scheduler.xml】</code></pre><span id="more"></span><h1 id="1、三种常见调度器"><a href="#1、三种常见调度器" class="headerlink" title="1、三种常见调度器"></a>1、三种常见调度器</h1><h2 id="1-1、先进先出调度器"><a href="#1-1、先进先出调度器" class="headerlink" title="1.1、先进先出调度器"></a>1.1、先进先出调度器</h2><pre><code>first-in first-out schedulerFIFO Scheduler后入队的任务 要等待 前入队的任务 出队</code></pre><p>可配置：<br>    1、每个用户的最大资源占比，防止单个用户把资源占满<br>    2、限制哪些用户可以提交应用到本队列 </p><h2 id="1-2、容量调度器"><a href="#1-2、容量调度器" class="headerlink" title="1.2、容量调度器"></a>1.2、容量调度器</h2><pre><code>Capacity Scheduler相当于 多个 FIFO Scheduler不同队列上的任务可以并行（比如 3个队列就可以并行3个任务）相同队列上的任务不能并行</code></pre><p>可配置：<br>    1、默认容量占比：各个队列占据一定百分比的资源<br>    （如：a队列40% b队列60%）<br>    2、最大容量占比：队列占据的资源百分比的最大值<br>    （如：a队列最大70%，当超出40%时，可以借b队列的空闲资源，最多借30%） </p><pre><code>划分方式：按业务划分（更常用）：下单、支付、物流…按技术划分：HIVE、Spark、Flink…</code></pre><h2 id="1-3、公平调度器"><a href="#1-3、公平调度器" class="headerlink" title="1.3、公平调度器"></a>1.3、公平调度器</h2><pre><code>Fair Scheduler和Capacity Scheduler类似，可以多队列配置；不同的是，叶子队列不是FIFO的在同一条叶子队列上，所有作业可以并发；资源分配的依据：时间尺度、优先级、资源缺额…</code></pre><p>在时间尺度上获得公平的资源</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220212181307.png"></p><p>最大最小公平分配算法</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220212181328.png"></p><h1 id="2、容量调度器-多队列配置"><a href="#2、容量调度器-多队列配置" class="headerlink" title="2、容量调度器 多队列配置"></a>2、容量调度器 多队列配置</h1><h2 id="1、编辑配置文件"><a href="#1、编辑配置文件" class="headerlink" title="1、编辑配置文件"></a>1、编辑配置文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim $HADOOP_HOME/etc/hadoop/capacity-scheduler.xml</span><br></pre></td></tr></table></figure><h2 id="2、修改根队列下面的叶队列名称，逗号分隔（此处新增队列名称为hive）"><a href="#2、修改根队列下面的叶队列名称，逗号分隔（此处新增队列名称为hive）" class="headerlink" title="2、修改根队列下面的叶队列名称，逗号分隔（此处新增队列名称为hive）"></a>2、修改<strong>根队列</strong>下面的<strong>叶队列</strong>名称，逗号分隔（此处新增队列名称为<code>hive</code>）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;default,hive&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;在根队列下设置叶队列名称&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h2 id="3、修改-名为default的队列-的容量占比"><a href="#3、修改-名为default的队列-的容量占比" class="headerlink" title="3、修改 名为default的队列 的容量占比"></a>3、修改 名为default的队列 的容量占比</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;40&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;设置root下名为default队列的容量占比&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h2 id="4、给新队列配置"><a href="#4、给新队列配置" class="headerlink" title="4、给新队列配置"></a>4、给新队列配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;60&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;root下名为hive的队列 的 容量占比&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.user-limit-factor&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;每个用户可以占据该队列资源占比的上限（防止某用户把资源占满）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.maximum-capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;80&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;该队列的最大容量占比（可外借80-60=20）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.state&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;RUNNING&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;该队列状态（RUNNING或STOPPED）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.acl_submit_applications&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;访问控制列表：限定哪些用户 能访问该队列&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.acl_administer_queue&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;访问控制列表：限定哪些用户 可以管理该队列上的作业&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.acl_application_max_priority&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.maximum-application-lifetime&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;提交到该队列的应用 的 最大生存时间（-1表示无限时间）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.default-application-lifetime&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;提交到该队列的应用 的 默认生存时间（-1表示无限时间；要求小于最大生存时间）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h2 id="5、分发配置"><a href="#5、分发配置" class="headerlink" title="5、分发配置"></a>5、分发配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync.py $HADOOP_HOME/etc/hadoop/capacity-scheduler.xml</span><br></pre></td></tr></table></figure><h2 id="6、查看浏览器，端口8088"><a href="#6、查看浏览器，端口8088" class="headerlink" title="6、查看浏览器，端口8088"></a>6、查看浏览器，端口<code>8088</code></h2><p><img src="https://img-blog.csdnimg.cn/20210423104042285.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1llbGxvd19weXRob24=,size_16,color_FFFFFF,t_70"></p><p>7、提交到指定队列</p><ul><li>Java代码的<code>org.apache.hadoop.conf.Configuration</code></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">configuration.set(&quot;mapred.job.queuename&quot;, &quot;hive&quot;);</span><br></pre></td></tr></table></figure><ul><li>HIVE</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapred.job.queue.name=hive</span><br></pre></td></tr></table></figure><h1 id="3、单词"><a href="#3、单词" class="headerlink" title="3、单词"></a>3、单词</h1><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220212181655.png"></p><h1 id="4、默认配置【capacity-scheduler-xml】"><a href="#4、默认配置【capacity-scheduler-xml】" class="headerlink" title="4、默认配置【capacity-scheduler.xml】"></a>4、默认配置【capacity-<a href="https://so.csdn.net/so/search?q=scheduler&spm=1001.2101.3001.7020">scheduler</a>.xml】</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 容量调度器中 挂起和运行的应用程序 的 最大数量 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.maximum-applications&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;10000&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Maximum number of applications that can be pending and running.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 可以用来运行【Application Masters】的最大资源占比 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.maximum-am-resource-percent&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;0.1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Maximum percent of resources in the cluster which can be used to run </span><br><span class="line">application masters i.e. controls number of concurrent running applications.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 容量调度器中的【资源计算器】，它用来 比较资源，默认比较资源的内存，</span><br><span class="line">另外可以选择别的资源计算器，从资源的多个维度（不仅内存，还有CPU等）来比较 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.resource-calculator&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">The ResourceCalculator implementation to be used to compare Resources in the scheduler.</span><br><span class="line">The default i.e. DefaultResourceCalculator only uses Memory while</span><br><span class="line">DominantResourceCalculator uses dominant-resource to compare </span><br><span class="line">multi-dimensional resources such as Memory, CPU etc.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 在 名为root的队列 下 设置队列名称（默认default一条队列，可设置多队列） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;default&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;The queues at the this level (root is the root queue).&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- root下名为default的队列 的 容量占比 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;100&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Default queue target capacity.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 每个用户可以占据该队列资源占比的上限（防止某用户把资源占满） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.user-limit-factor&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Default queue user limit a percentage from 0.0 to 1.0.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 该队列的最大容量占比 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.maximum-capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;100&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 该队列状态（RUNNING or STOPPED） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.state&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;RUNNING&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 访问控制列表：限定哪些用户 能访问该队列 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.acl_submit_applications&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 访问控制列表：限定哪些用户 可以管理该队列上的作业 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.acl_administer_queue&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;The ACL of who can administer jobs on the default queue.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.acl_application_max_priority&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">The ACL of who can submit applications with configured priority.</span><br><span class="line">For e.g, [user=&#123;name&#125; group=&#123;name&#125; max_priority=&#123;priority&#125; default_priority=&#123;priority&#125;]</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 提交到该队列的应用 的 最大生存时间（-1表示无限时间） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.maximum-application-lifetime&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Maximum lifetime of an application which is submitted to a queue</span><br><span class="line">in seconds. Any value less than or equal to zero will be considered as disabled.</span><br><span class="line">This will be a hard time limit for all applications in this</span><br><span class="line">queue. If positive value is configured then any application submitted</span><br><span class="line">to this queue will be killed after exceeds the configured lifetime.</span><br><span class="line">User can also specify lifetime per application basis in</span><br><span class="line">application submission context. But user lifetime will be</span><br><span class="line">overridden if it exceeds queue maximum lifetime. It is point-in-time</span><br><span class="line">configuration.</span><br><span class="line">Note : Configuring too low value will result in killing application</span><br><span class="line">sooner. This feature is applicable only for leaf queue.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 提交到该队列的应用 的 默认生存时间（-1表示无限时间；要求小于最大生存时间） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.default-application-lifetime&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Default lifetime of an application which is submitted to a queue</span><br><span class="line">in seconds. Any value less than or equal to zero will be considered as</span><br><span class="line">disabled.</span><br><span class="line">If the user has not submitted application with lifetime value then this</span><br><span class="line">value will be taken. It is point-in-time configuration.</span><br><span class="line">Note : Default lifetime can&#x27;t exceed maximum lifetime. This feature is</span><br><span class="line">applicable only for leaf queue.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.node-locality-delay&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;40&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Number of missed scheduling opportunities after which the CapacityScheduler </span><br><span class="line">attempts to schedule rack-local containers.</span><br><span class="line">When setting this parameter, the size of the cluster should be taken into account.</span><br><span class="line">We use 40 as the default value, which is approximately the number of nodes in one rack.</span><br><span class="line">Note, if this value is -1, the locality constraint in the container request</span><br><span class="line">will be ignored, which disables the delay scheduling.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.rack-locality-additional-delay&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Number of additional missed scheduling opportunities over the node-locality-delay</span><br><span class="line">ones, after which the CapacityScheduler attempts to schedule off-switch containers,</span><br><span class="line">instead of rack-local ones.</span><br><span class="line">Example: with node-locality-delay=40 and rack-locality-delay=20, the scheduler will</span><br><span class="line">attempt rack-local assignments after 40 missed opportunities, and off-switch assignments</span><br><span class="line">after 40+20=60 missed opportunities.</span><br><span class="line">When setting this parameter, the size of the cluster should be taken into account.</span><br><span class="line">We use -1 as the default value, which disables this feature. In this case, the number</span><br><span class="line">of missed opportunities for assigning off-switch containers is calculated based on</span><br><span class="line">the number of containers and unique locations specified in the resource request,</span><br><span class="line">as well as the size of the cluster.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.queue-mappings&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">A list of mappings that will be used to assign jobs to queues</span><br><span class="line">The syntax for this list is [u|g]:[name]:[queue_name][,next mapping]*</span><br><span class="line">Typically this list will be used to map users to queues,</span><br><span class="line">for example, u:%user:%user maps all users to queues with the same name</span><br><span class="line">as the user.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.queue-mappings-override.enable&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">If a queue mapping is present, will it override the value specified</span><br><span class="line">by the user? This can be used by administrators to place jobs in queues</span><br><span class="line">that are different than the one specified by the user.</span><br><span class="line">The default is false.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.per-node-heartbeat.maximum-offswitch-assignments&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Controls the number of OFF_SWITCH assignments allowed</span><br><span class="line">during a node&#x27;s heartbeat. Increasing this value can improve</span><br><span class="line">scheduling rate for OFF_SWITCH containers. Lower values reduce</span><br><span class="line">&quot;clumping&quot; of applications on particular nodes. The default is 1.</span><br><span class="line">Legal values are 1-MAX_INT. This config is refreshable.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.application.fail-fast&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Whether RM should fail during recovery if previous applications&#x27;</span><br><span class="line">queue is no longer valid.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220212181909.png"></p><p>知识源于积累,登峰造极源于自律!</p><p>好文章就得收藏慢慢品, 文章转载于: <a href="https://blog.csdn.net/Yellow_python/article/details/116021592">https://blog.csdn.net/Yellow_python/article/details/116021592</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Hadoop版本：3.1.3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1、三种常见调度器
    1.1、先进先出调度器
    1.2、容量调度器
    1.3、公平调度器
2、容量调度器 多队列配置
3、单词
4、默认配置【capacity-scheduler.xml】
&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="hadoop" scheme="http://xubatian.cn/tags/hadoop/"/>
    
    <category term="yarn" scheme="http://xubatian.cn/tags/yarn/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之并行度（Parallelism）</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E5%B9%B6%E8%A1%8C%E5%BA%A6%EF%BC%88Parallelism%EF%BC%89/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E5%B9%B6%E8%A1%8C%E5%BA%A6%EF%BC%88Parallelism%EF%BC%89/</id>
    <published>2022-02-11T05:04:57.000Z</published>
    <updated>2022-02-11T05:13:29.938Z</updated>
    
    <content type="html"><![CDATA[<p>Flink程序的执行具有并行、分布式的特性。<br>在执行过程中，一个流（stream）包含一个或多个分区（stream partition），而每一个算子（operator）可以包含一个或多个子任务（operator subtask），这些子任务在不同的线程、不同的物理机或不同的容器中彼此互不依赖地执行。</p><pre><code>一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。streamEnv.setParallelism(1)//加在ENV上表示默认所有的算子平行度都是1</code></pre><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130627.png"></p><p>Stream在算子之间传输数据的形式可以是one-to-one(forwarding)的模式也可以是redistributing的模式，具体是哪一种形式，取决于算子的种类。</p><p>​        <strong>One-to-one</strong>：stream(比如在source和map operator之间)维护着分区以及元素的顺序。那意味着map 算子的子任务看到的元素的个数以及顺序跟source 算子的子任务生产的元素的个数、顺序相同，map、fliter、flatMap等算子都是one-to-one的对应关系。</p><p>​        <strong>类似于spark中的窄依赖</strong></p><p>​        <strong>Redistributing</strong>：stream(map()跟keyBy/window之间或者keyBy/window跟sink之间)的分区会发生改变。每一个算子的子任务依据所选择的transformation发送数据到不同的目标任务。例如，keyBy() 基于hashCode重分区、broadcast和rebalance会随机重新分区，这些算子都会引起redistribute(重新分配过程)过程，而redistribute过程就<strong>类似于Spark中的shuffle过程</strong>。</p><p>​        <strong>类似于spark中的宽依赖</strong></p><h2 id="博主解析"><a href="#博主解析" class="headerlink" title="博主解析:"></a>博主解析:</h2><p>​        <strong>并行度就是在执行过程中,尤其是我们Flink的Job执行过程中,一个流(Stream)包含一个或者多个分区.由于他包含一个或多个分区,从而就造成了一个算子他就包含一个或者多个子任务</strong>.实际上这流(Stream)和算子,这两个是因果关系.就因为你这流包含了一个或者两个或者多个分区.从而造成流所对应的算子就会出现一个或者多个子任务.这些子任务在不同的Slot上运行.而且也可能是不同的物理机.或者是不同的不同的容器,彼此之间相互互不依赖地执行.但是实际上他们有依赖关系吗?实际上他们也有依赖关系的.完全没有依赖关系是不可能的,因为我们还有一个数据的依赖.因为我们的数据一定是从上一个子任务到下一个子任务的.</p><p>​        一个特定的算子它到底有多少个子任务呢?就是由我们这个并行度来决定的.而并行度就是由我们parallelism来设置的.我们可以在代码的后面通过setParallelism()方法来设置并行度.也可以统一的在ENV,来设置算子的并行度.在ENV上设置算子的并行度就是所谓默认的.由于我们设置了并行度,所以就造成了两种情况.就是造成了我们的Stream和Stream之间有两种关系存在.</p><p>​        <strong>一种是One-to-one(一对一对应关系),还有一种就是Redistributing(重新分配)</strong></p><p>​        One-to-one:就是一个对应一个.什么情况下才是一个对应一个呢?</p><p>如图所示:</p><p>​        <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211131006.png"></p><p>​            <strong>Redistribute</strong>:重新分配的意思,实际上就是变了.本来可能是只有一个并行度,通过一个算子之后变成了两个或者三个等并行度了</p><p>如图所示:</p><p>​    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211131056.png"></p><h2 id="目前Flink的dataStream支持8种物理分区策略"><a href="#目前Flink的dataStream支持8种物理分区策略" class="headerlink" title="目前Flink的dataStream支持8种物理分区策略"></a>目前Flink的dataStream支持8种物理分区策略</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">①GlobalPartitioner(全局分区)： 数据会被分发到下游算子的第一个实例中进行处理。</span><br><span class="line">②ShufflePartitioner(shuffle分区) ：数据会被随机分发到下游算子的每一个实例中进行。</span><br><span class="line">③RebalancePartitioner(重新平衡分区)： 数据会被循环发送到下游的每一个实例中进行处理。</span><br><span class="line">④RescalePartitioner (重新调节分区)：这种分区器会根据上下游算子的并行度，循环的方式输出到下游算子的每个实例。这里有点难以理解，假设上游并行度为 2，编号为 A 和 B。下游并行度为 4，编号为 1，2，3，4。那么 A 则把数据循环发送给 1 和 2，B 则把数据循环发送给 3 和 4。假设上游并行度为 4，编号为 A，B，C，D。下游并行度为 2，编号为 1，2。那么 A 和 B 则把数据发送给 1，C 和 D 则把数据发送给 2。</span><br><span class="line">⑤BroadcastPartitioner (广播分区) ：广播分区会将上游数据输出到下游算子的每个实例中。适合于大数据集和小数据集做Jion的场景。</span><br><span class="line">⑥ForwardPartitioner (forward分区)：用于将记录输出到下游本地的算子实例。它要求上下游算子并行度一样。简单的说，ForwardPartitioner用来做数据的控制台打印。</span><br><span class="line">⑦KeyGroupStreamPartitioner ：Hash 分区器。会将数据按Key的Hash值输出到下游算子实例中。​​​​</span><br><span class="line">⑧CustomPartitionerWrapper：用户自定义分区器。需要用户自己实现 Partitioner 接口，来定义自己的分区逻辑。</span><br><span class="line">static class CustomPartitioner implements Partitioner&lt;String&gt; &#123; </span><br><span class="line">    @Override </span><br><span class="line">    public int partition(String key, int numPartitions) &#123; </span><br><span class="line">        switch (key)&#123; </span><br><span class="line">            case &quot;1&quot;: return 1;</span><br><span class="line">            case &quot;2&quot;: return 2;</span><br><span class="line">            case &quot;3&quot;: return 3;</span><br><span class="line">            default : return 4;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211131134.png"></p><h2 id="Flink8种传输数据操作"><a href="#Flink8种传输数据操作" class="headerlink" title="Flink8种传输数据操作"></a>Flink8种传输数据操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">KeyBy: 按照key的hash值分区, 相同的key一定会分到相同的分区.即相同的key进入相同的并行度,也就是说进入同一个子任务.</span><br><span class="line">Shuffle: 随机分的.</span><br><span class="line">Rebalance: 全局轮询,即上游的所有并行度都对下游所有并行度轮询.</span><br><span class="line">Rescale: 局部轮询,也就是说上游两个,下游四个.我上游两个在两个里面轮询了,一个人在两个里面轮询.</span><br><span class="line">Global: 所有数据发送到下游同一个并行度.</span><br><span class="line">Broadcast:所有数据发送到下游所有并行度.</span><br><span class="line">Forward:要求并行度相同,因为他是一对一的.</span><br><span class="line">Customer: 自定义.</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211131309.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink程序的执行具有并行、分布式的特性。&lt;br&gt;在执行过程中，一个流（stream）包含一个或多个分区（stream partition），而每一个算子（operator）可以包含一个或多个子任务（operator subtask），这些子任务在不同的线程、不同的物理机或不同的容器中彼此互不依赖地执行。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。
streamEnv.setParallelism(1)//加在ENV上表示默认所有的算子平行度都是1
&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之执行图（ExecutionGraph）</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E6%89%A7%E8%A1%8C%E5%9B%BE%EF%BC%88ExecutionGraph%EF%BC%89/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E6%89%A7%E8%A1%8C%E5%9B%BE%EF%BC%88ExecutionGraph%EF%BC%89/</id>
    <published>2022-02-11T04:56:45.000Z</published>
    <updated>2022-02-11T05:03:45.814Z</updated>
    
    <content type="html"><![CDATA[<p>​        由Flink程序直接映射成的数据流图是StreamGraph，也被称为逻辑流图，因为它们表示的是计算逻辑的高级视图。为了执行一个流处理程序，Flink需要将逻辑流图转换为物理数据流图（也叫执行图），详细说明程序的执行方式。</p><p>​        <strong>Flink 中的执行图可以分成四层：StreamGraph(数据流图) -&gt; JobGraph(工作图) -&gt; ExecutionGraph (执行图)-&gt; 物理执行图。</strong></p><p>​        </p><p>​        <strong>StreamGraph</strong>：(数据流图)是根据用户通过 Stream API 编写的代码生成的最初的图。用来表示程序的拓扑结构有效。</p><p>​        <strong>JobGraph</strong>：StreamGraph经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。</p><p>​        <strong>ExecutionGraph</strong>：JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。</p><p>​        <strong>物理执行图</strong>：JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构</p><span id="more"></span><h2 id="四个流图的转换过程"><a href="#四个流图的转换过程" class="headerlink" title="四个流图的转换过程"></a>四个流图的转换过程</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130057.png"></p><p>​        StreamGraph称之为数据流图,数据流图是根据用户通过API的编程,尤其是通过dataStream API的编程,编程就是你写好的代码.就是根据你写好的代码来生成一个最初的图,这个图用来描述你代码或者说你程序的拓扑结构,这样的图就称之为StreamGraph(数据流图)</p><p>​        举例:如图所示:</p><p>​        <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130206.png"></p><p>​        假设我写的代码里面第一个写的是Source读数据,读完数据之后调用FlatMap,接下来调用第三个Map算子;这些完全是根据自己的代码而定的.我这里先不管代码中我Map算子设置的并行度是几或者我的FlatMap中设置的并行度是几.我就把我写好的代码根据算子调用的顺序得到上面这张图,这张图就称之为数据流图.这张数据流图就是用来展示你写的代码的拓扑结构.这张数据流图是我们看不到的,因为Web-UI界面是不会给我展示这张图的.当然,自己写代码的人自己心里面是有这样图的.然后根据我的数据流图,优化之后的到一个JobGraph,这个我们称之为工作图.</p><p>​        JobGraph是什么意思呢?</p><p>​        他实际上是将前面的StreamGraph(数据流图)进行优化,优化之后呢.他会把多个符合条件的节点,通过operatorChain(任务链)连在一起.他时通过任务链把多个符合条件的节点连在一起.如下图所示:</p><p>​    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130241.png"></p><p>​            上面两个图都是在客户端完成的,客户端完成之后就要开始要提交了.客户端提交给JobManager,JobManager在接收到你提交过来的Job之后,他首先会根据你提交过来的图,将这个图变成执行图.执行图里面有什么特点呢?</p><p>​            他是根据你这个执行图看看你有几个管道,找到你有几个管道,每个管道之间的数据通信是什么样子的.这就是所谓的执行图.变成执行图之后,每个管道还要得到不同的任务,因为你已经得到管道了,得到管道之后你就可以得到各个不同的任务.这个每个任务在哪个Slot上运行.后面这个图就叫物理执行图了.因为物理执行图就是实施去哪个TaskManager上的Slot去运行的.所以这四个图是这么来的.</p><pre><code>    Flink 中的执行图可以分成四层：    StreamGraph(数据流图) -&gt; JobGraph(工作图) -&gt; ExecutionGraph (执行图)-&gt; 物理执行图</code></pre><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130331.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;​        由Flink程序直接映射成的数据流图是StreamGraph，也被称为逻辑流图，因为它们表示的是计算逻辑的高级视图。为了执行一个流处理程序，Flink需要将逻辑流图转换为物理数据流图（也叫执行图），详细说明程序的执行方式。&lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;Flink 中的执行图可以分成四层：StreamGraph(数据流图) -&amp;gt; JobGraph(工作图) -&amp;gt; ExecutionGraph (执行图)-&amp;gt; 物理执行图。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​        &lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;StreamGraph&lt;/strong&gt;：(数据流图)是根据用户通过 Stream API 编写的代码生成的最初的图。用来表示程序的拓扑结构有效。&lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;JobGraph&lt;/strong&gt;：StreamGraph经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。&lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;ExecutionGraph&lt;/strong&gt;：JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。&lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;物理执行图&lt;/strong&gt;：JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之TaskManger与Slots</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8BTaskManger%E4%B8%8ESlots/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8BTaskManger%E4%B8%8ESlots/</id>
    <published>2022-02-11T04:45:08.000Z</published>
    <updated>2022-02-11T04:50:06.695Z</updated>
    
    <content type="html"><![CDATA[<p>​        在Flink job的运行过程中,Flink Job中每一个worker(TaskManager)都是一个JVM进程，它可能会在独立的Slot(线程)上执行一个或多个subtask(子任务)。为了控制一个worker能接收多少个task，worker通过task slot来进行控制（一个worker至少有一个task slot）。</p><p>​        每个task slot表示TaskManager拥有资源的一个固定大小的子集。假如一个TaskManager有三个slot，那么它会将其管理的内存分成三份给各个slot。资源slot化意味着一个subtask将不需要跟来自其他job的subtask竞争被管理的内存，取而代之的是它将拥有一定数量的内存储备。需要注意的是，这里不会涉及到CPU的隔离，slot目前仅仅用来隔离task的受管理的内存。</p><p>​        通过调整task slot的数量，允许用户定义subtask之间如何互相隔离。如果一个TaskManager一个slot，那将意味着每个task group运行在独立的JVM中（该JVM可能是通过一个特定的容器启动的），而一个TaskManager多个slot意味着更多的subtask可以共享同一个JVM。而在同一个JVM进程中的task将共享TCP连接（基于多路复用）和心跳消息。它们也可能共享数据集和数据结构，因此这减少了每个task的负载。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124632.png"></p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124731.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124817.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124840.png"></p><p>默认情况下，Flink允许子任务共享slot，即使它们是不同任务的子任务（前提是它们来自同一个job）。 这样的结果是，一个slot可以保存作业的整个管道。<br><strong>Task Slot是静态的概念，是指TaskManager具有的并发执行能力</strong>，可以通过参数taskmanager.numberOfTaskSlots进行配置；<strong>而并行度parallelism是动态概念</strong>，即TaskManager运行程序时实际使用的并发能力，可以通过参数parallelism.default进行配置。<br>也就是说，假设一共有3个TaskManager，每一个TaskManager中的分配3个TaskSlot，也就是每个TaskManager可以接收3个task，一共9个TaskSlot，如果我们设置parallelism.default=1，即运行程序默认的并行度为1，9个TaskSlot只用了1个，有8个空闲，因此，设置合适的并行度才能提高效率。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124935.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124954.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;​        在Flink job的运行过程中,Flink Job中每一个worker(TaskManager)都是一个JVM进程，它可能会在独立的Slot(线程)上执行一个或多个subtask(子任务)。为了控制一个worker能接收多少个task，worker通过task slot来进行控制（一个worker至少有一个task slot）。&lt;/p&gt;
&lt;p&gt;​        每个task slot表示TaskManager拥有资源的一个固定大小的子集。假如一个TaskManager有三个slot，那么它会将其管理的内存分成三份给各个slot。资源slot化意味着一个subtask将不需要跟来自其他job的subtask竞争被管理的内存，取而代之的是它将拥有一定数量的内存储备。需要注意的是，这里不会涉及到CPU的隔离，slot目前仅仅用来隔离task的受管理的内存。&lt;/p&gt;
&lt;p&gt;​        通过调整task slot的数量，允许用户定义subtask之间如何互相隔离。如果一个TaskManager一个slot，那将意味着每个task group运行在独立的JVM中（该JVM可能是通过一个特定的容器启动的），而一个TaskManager多个slot意味着更多的subtask可以共享同一个JVM。而在同一个JVM进程中的task将共享TCP连接（基于多路复用）和心跳消息。它们也可能共享数据集和数据结构，因此这减少了每个task的负载。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124632.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink任务调度原理概念</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%E6%A6%82%E5%BF%B5/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%E6%A6%82%E5%BF%B5/</id>
    <published>2022-02-11T04:33:07.000Z</published>
    <updated>2022-02-11T04:36:00.355Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211123327.png"></p><span id="more"></span><p>​        客户端不是运行时和程序执行的一部分，但它用于准备并发送dataflow(JobGraph)给Master(JobManager)，然后，客户端断开连接或者维持连接以等待接收计算结果。</p><p>​        当 Flink 集群启动后，首先会启动一个 JobManger 和一个或多个的 TaskManager。由 Client 提交任务给 JobManager，JobManager 再调度任务到各个 TaskManager 去执行，然后 TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述三者均为独立的 JVM 进程.</p><p>​        <strong>Client</strong> 为提交 Job 的客户端，可以是运行在任何机器上（与 JobManager 环境连通即可）。提交 Job 后，Client 可以结束进程（Streaming的任务），也可以不结束并等待结果返回。</p><p>​        <strong>JobManager</strong> 主要负责调度 Job 并协调 Task 做 checkpoint，职责上很像 Storm 的 Nimbus。从 Client 处接收到 Job 和 JAR 包等资源后，会生成优化后的执行计划，并以 Task 的单元调度到各个 TaskManager 去执行。</p><p>​        <strong>TaskManager</strong> 在启动的时候就设置好了槽位数（Slot），每个 slot 能启动一个 Task，Task 为线程。从 JobManager 处接收需要部署的 Task，部署启动后，与自己的上游建立 Netty 连接，接收数据并处理。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211123327.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink任务提交流程</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/</id>
    <published>2022-02-11T04:27:14.000Z</published>
    <updated>2022-02-11T04:33:57.133Z</updated>
    
    <content type="html"><![CDATA[<p>当一个应用提交执行时，Flink的各个组件是如何交互协作的?</p><p>任务提交和组件交互流程图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211122757.png"></p><span id="more"></span><p>上图是从一个较为高层级的视角，来看应用中各组件的交互协作。如果部署的集群环境不同（例如YARN，Mesos，Kubernetes，standalone等），其中一些步骤可以被省略，或是有些组件会运行在同一个JVM进程中。</p><p>具体地，如果我们将Flink集群部署到YARN上，那么就会有如下的提交流程(Yarn模式任务提交流程图)：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211122847.png"></p><p>Flink任务提交后，Client向HDFS上传Flink的Jar包和配置，之后向Yarn ResourceManager提交任务，ResourceManager分配Container资源并通知对应的NodeManager启动ApplicationMaster，ApplicationMaster启动后加载Flink的Jar包和配置构建环境，然后启动JobManager，之后ApplicationMaster向ResourceManager申请资源启动TaskManager，ResourceManager分配Container资源后，由ApplicationMaster通知资源所在节点的NodeManager启动TaskManager，NodeManager加载Flink的Jar包和配置构建环境并启动TaskManager，TaskManager启动后向JobManager发送心跳包，并等待JobManager向其分配任务.</p><h2 id="博主解析任务提交流程"><a href="#博主解析任务提交流程" class="headerlink" title="博主解析任务提交流程:"></a>博主解析任务提交流程:</h2><p>这个提交流程就是我写好的一个Flink的job或者写好的一个Flink的程序program.现在我要提交到Flink集群中去运行了.提交有两种提交方式:<br>第一种是通过Web-UI进行提交,这个很秀,因为spark就没有这个功能,Web-UI中首先上传了一个jar包,然后在jar包中指定我要运行那个主类,传什么样的参数,等等,然后点击提交(Submit).一点击提交,就会把我们的Application或者说我们的Flink Job提交给JobManager了.JobManager马上去ResourceManager中申请资源即去ResourceManager中申请Slot.假设我只需要三个Slot就ok了,这个时候他就找到一个对应的TaskManager,因为我们一个TaskManager默认情况下我们设置的是三个Slot.(当然这三个是我们设置的,原始的配置文件默认只有一个;当然在真正生产环境下不可能一个TaskManager只有一个Slot的,至少是三的几倍).启动相应的TaskManager,然后开始注册我们的Slot,注册Slot就表示我这个Slot开始要运行了,然后发出提供Slot的指令,然后开始提供Slot来运行.真正我们的Task是在Slot中运行的,运行的时候他还会把运行的状态信息提供给TaskManager和JobManager.如果有多个TaskManager,在TaskManager之间他是可以交换数据的.为什么可以交换数据呢?为什么TaskManager之间可以交换数据呢?如果有多个TaskManager的话,TaskManager之间是可以交换数据的.不单单是多个TaskManager,你如果是一个TaskManager和多个Slot之间也是可以交换数据的.为什么呢?<br>因为假设其中一个Slot运行一个Source    ,source运行完成之后把数据要给谁呢?是要把数据给转换算子,这个转换算子有可能在另外一个Slot中.那么数据是不是就得给他呢.<br>那么,有没有一种可能就是,你的转换算子的任务是运行在另外一个TaskManager上的Slot中,那我是不是需要把数据给他呢. 当然,这就属于跨机器了.所以要交换数据.<br>当然,这些都是属于站在上帝的视角看的.</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211123026.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211123052.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;当一个应用提交执行时，Flink的各个组件是如何交互协作的?&lt;/p&gt;
&lt;p&gt;任务提交和组件交互流程图:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211122757.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink运行时的组件</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9A%84%E7%BB%84%E4%BB%B6/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9A%84%E7%BB%84%E4%BB%B6/</id>
    <published>2022-02-11T04:20:15.000Z</published>
    <updated>2022-02-11T04:33:53.821Z</updated>
    
    <content type="html"><![CDATA[<p>Flink运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作：作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager），以及分发器（Dispatcher）。因为Flink是用Java和Scala实现的，所以所有组件都会运行在Java虚拟机上。每个组件的职责如下</p><span id="more"></span><h2 id="作业管理器（JobManager）"><a href="#作业管理器（JobManager）" class="headerlink" title="作业管理器（JobManager）"></a>作业管理器（JobManager）</h2><p>控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager所控制执行。JobManager会先接收到要执行的应用程序，这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的JAR包。JobManager会把JobGraph转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。JobManager会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上。而在运行过程中，JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</p><h3 id="博主解析"><a href="#博主解析" class="headerlink" title="博主解析:"></a>博主解析:</h3><p>JobManager是控制整个Flink Job运行的,所谓的控制就是,<br>①他负责监控②他负责Slot的分配或者Slot的调度.<br>这个Task在哪个Slot上运行,他给你分配好,这就是所谓的控制,JobManager就一句话,就是用来控制Flink Job的主进程的运行.<br>什么叫控制?控制的意思就是说你整个Job分成好几个任务,那么我这几个任务我需要把他分配到哪些Task Manager的哪些Slot上,这个Slot就表示资源的意思,同时还负责监控</p><h2 id="资源管理器（ResourceManager）"><a href="#资源管理器（ResourceManager）" class="headerlink" title="资源管理器（ResourceManager）"></a>资源管理器（ResourceManager）</h2><p>主要负责管理任务管理器（TaskManager）的插槽（slot），TaskManger插槽是Flink中定义的处理资源单元。Flink为不同的环境和资源管理工具提供了不同资源管理器，比如YARN、Mesos、K8s，以及standalone部署。当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager分配给JobManager。如果ResourceManager没有足够的插槽来满足JobManager的请求，它还可以向资源提供平台发起会话，以提供启动TaskManager进程的容器。另外，ResourceManager还负责终止空闲的TaskManager，释放计算资源。</p><h3 id="博主解析-1"><a href="#博主解析-1" class="headerlink" title="博主解析:"></a>博主解析:</h3><p>ResourceManager如果是yarn模式的话,这个在hadoop就讲过了.但是如果是Standalone模式的话.这个ResourceManager实际上就和我们的JobManager在一个进程里面,这点需要注意.<br>但是如果是yarn模式的话,ResourceManager是独立的,是yarn里面的主节点,主要负责资源的管理,管理所有Task Manager上的Slot.<br>这里面有个迷糊的地方,这个ResourceManager早就在hadoop上学过了,但是为什么说他是管理所以Task Manager的Slot呢?问题是,你这个Task Manager是属于你的Flink的.原来我们学Hadoop的时候说的是,ResourceManager是管理NodeManager上的资源的.可是,现在我们又说是管理Task Manager上的资源.这两句话难道是一样的吗?其实,这两句话本质上是一样的.为什么呢?因为,请问,在yarn模式下,这个TaskManager这个节点会运行在哪些节点上呢?是运行在NodeManager节点上呢?还是在ResourceManager节点上?还是运行在与NodeManager和ResourceManager都没关系的其他节点上呢?其实,他一定是运行在NodeManager上,并且他只能运行在NodeManager上,他是在NodeManager上去启动TaskManager.那如果是这样的话.你在NodeManager上启动TaskManager的话,你不就是申请NodeManager上的资源嘛.申请了NodeManager上的资源你才能够启动对应的TaskManager.所以说,我们之前学的ResourceManager就是来管理和分配NodeManager上的资源的.这句话是对的.由于你NodeManager上有资源,所以他可以在某一个NodoManager上去启动Flink Job需要运行的TaskManager.假设在hadoop102上的NodeManager上启动了一个TaskManager,他之所以能够启动,一定是他有空余的资源才能够启动.假设他有空余一个G的资源,那启动了一个TaskManager.(为什么这里说是一个G呢?因为我们配置文件中指定了默认情况下TaskManager占用内存是一个G,所以这和Flink的配置文件是关联起来的).所以,假设是启动一个G,这一个G是给TaskManager用的,并且你指定了TaskManager上的Slot数量是3,那么他会把这一个G的资源均匀的切成三份,分给这三个Slot.由于在我们Flink这个框架里面,我们的资源是在TaskManager上的Slot的,所以我们也可以用另外一句话来描述,就是说,我们ResourceManager来负责管理和分配TaskManager上的Slot.</p><h2 id="任务管理器（TaskManager）"><a href="#任务管理器（TaskManager）" class="headerlink" title="任务管理器（TaskManager）"></a>任务管理器（TaskManager）</h2><p>Flink中的工作进程。通常在Flink中会有多个TaskManager运行，每一个TaskManager都包含了一定数量的插槽（slots）。插槽的数量限制了TaskManager能够执行的任务数量。启动之后，TaskManager会向资源管理器(ResourceManager)注册它的插槽；收到资源管理器的指令后，TaskManager就会将一个或者多个插槽提供给JobManager调用。JobManager就可以向插槽分配任务（tasks）来执行了。在执行过程中，一个TaskManager可以跟其它运行同一应用程序的TaskManager交换数据。</p><h3 id="博主解析-2"><a href="#博主解析-2" class="headerlink" title="博主解析:"></a>博主解析:</h3><p>TaskManager是在Flink job运行过程中,是他的工作进程.TaskManager一定是一个进程.每一个TaskManager包含一定数量的Slot.这个Slot的数量就限制了你这个TaskManager的并行执行任务的数量.<br>那Slot的数量是在哪里设置的呢? 就是在你的配置文件中设置的.也可以在命令中设置.这个命令是yarn-session -s…略…(这个-s 里面就是你的Slot数量)<br>上面详细说过,这Slot是共享整个TaskManager上的内存资源的.如果你这个TaskManager是一个G,那么我三个Slot都共享这一个G.<br>还有一点就是,在yarn模式下,这个TaskManager是在你的Flink Job 提交之后,根据你这个Job的资源的需求情况来启动这个TaskManager的.当前,前提条件是基于你的yarn模式,不是基于standalone模式的.<br>所以,这个TaskManager在yarn模式中是这样的.就是你这Job一提交,ResourceManager根据你提交的Job运行时候的执行图,确定你需要多少Slot.假设你需要三个Slot,ResourceManager发现你需要三个Slot,那ResourceManager就只需要启动一个TaskManager就可以了.因为一个TaskManager上就有三个Slot(配置文件上指定的),够用了.尽管其他的NodeManager上也可以启动TaskManager,但是这就没必要启动了.这就是Flink的特点.Flink和MapReduce和Spark不一样.他不是在Job没提交之前就将所有改启动的都先启动了.因为这样有些东西的浪费的.比如Work进程里面的executor,他尽管没有运行executor,他也运行在哪里,这就很浪费.<br>所以,当假设你需要三个Slot,那我就给你启动一个TaskManager,这时候你肯定还有其他空闲的资源,这时候,我用户还可以提交一个新的Flink Job进来.新的Flink job也是一样,ResourceManager根据你这个新的Flink job运行的资源,需求情况,又给你去启动对应的TaskManager.<br>新问题: 假设我写的task任务(即task job)运行的时候需要的Slot比较多.我需要九个Slot.如果你资源有的情况下,他一定会给你启动三个TaskManager.反正他启动的TaskManager一定是够你这个task Job用的.除非我ResourceManager所管理的资源已经没有了,那就没办法了,只能等待.因为他已经没有资源给你运行了</p><h2 id="分发器（Dispatcher）"><a href="#分发器（Dispatcher）" class="headerlink" title="分发器（Dispatcher）"></a>分发器（Dispatcher）</h2><p>可以跨作业运行，它为应用提交提供了REST接口。当一个应用被提交执行时，分发器就会启动并将应用移交给一个JobManager。由于是REST接口，所以Dispatcher可以作为集群的一个HTTP接入点，这样就能够不受防火墙阻挡。Dispatcher也会启动一个Web UI，用来方便地展示和监控作业执行的信息。Dispatcher在架构中可能并不是必需的，这取决于应用提交运行的方式。</p><h3 id="博主解析-3"><a href="#博主解析-3" class="headerlink" title="博主解析:"></a>博主解析:</h3><p>什么是分发器呢?如果我通过谷歌访问Flink的web-UI界面,访问的端口号是默认的是8081,这个就是Dispatcher(分发器).<br>在Flink自带的standalone模式下也是有Dispatcher(分发器)的.在Yarn模式下也是有的.那个Dispatcher是在哪里呢?其实他是在JobManager里面的.<br>实际上,在实际操作中我们先打开了8088这个hadoop的yarn的页面,在8088这个页面看到了Application,Application这一行的最右面有一个ApplicationMaster的超链接,点击这个ApplicationMaster就打开了我们的Dispatcher(分发器)了.<br>所以Dispatcher实际上就是给我们提供的一个restful的一个接口.restful接口实际上就是可以通过HTTP来接入的.<br>要知道,在standalone和yarn模式下都有Dispatcher的.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作：作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager），以及分发器（Dispatcher）。因为Flink是用Java和Scala实现的，所以所有组件都会运行在Java虚拟机上。每个组件的职责如下&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之任务链</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E4%BB%BB%E5%8A%A1%E9%93%BE/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E4%BB%BB%E5%8A%A1%E9%93%BE/</id>
    <published>2022-02-10T14:15:46.000Z</published>
    <updated>2022-02-12T09:30:30.801Z</updated>
    
    <content type="html"><![CDATA[<h3 id="好记性-烂笔头"><a href="#好记性-烂笔头" class="headerlink" title="好记性,烂笔头:"></a>好记性,烂笔头:</h3><p>①socket不能多并行度消费. 而kafka是可以多并行度消费的. kafka有多个分区.   </p><p>②keyby不是一个算子,他是决定我们的数据进入到下游的哪一个并行度里面的.他自己没有并行度的.他不会对数据做任何的操作.数据可能从一个并行度来的. 进过keyby之后,可能把他发到好多个并行度里面去了.</p><p>8种数据传输的方式:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">KeyBy: 按照key的hash值分区, 相同的key一定会分到相同的分区.即相同的key进入相同的并行度,也就是说进入同一个子任务.</span><br><span class="line">Shuffle: 随机分的.</span><br><span class="line">Rebalance: 全局轮询,即上游的所有并行度都对下游所有并行度轮询.</span><br><span class="line">Rescale: 局部轮询,也就是说上游两个,下游四个.我上游两个在两个里面轮询了,一个人在两个里面轮询.</span><br><span class="line">Global: 所有数据发送到下游同一个并行度.</span><br><span class="line">Broadcast:所有数据发送到下游所有并行度.</span><br><span class="line">Forward:要求并行度相同,因为他是一对一的.</span><br><span class="line">Customer: 自定义.</span><br></pre></td></tr></table></figure><span id="more"></span><h3 id="正文"><a href="#正文" class="headerlink" title="正文:"></a>正文:</h3><p>任务链的意思就是说,我们把两个算子按照一定的条件连接在一起.形成一个统一的Task<br>这就是所谓的任务链.并且我们可以在图上可以看到,如下图所示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210221830.png"></p><p>任务链可以当做Spark中的stage理解. 但是他比stage灵活. spark中根据宽依赖划分stage. 所以Flink保留此特点. 如果你是重分区的操作.他就一定会划分到两个不同的任务链里面来. 除此之外Flink的任务链还要看并行度. </p><p>这个任务链有一定的条件,首先他们的<strong>①并行度要相同</strong>.所谓的并行度相同就是One-to-one,One-to-one不是说他们只有一个,而是指他们的并行度相同.第二个条件就是他们<strong>②中间没有shuffle</strong>.中间没有shuffle才会通过任务链把他们合在一起.这个任务链不用我们去做的.不过呢,我们可以设置让所有的算子之间完全隔离.就算你有条件来通过这个任务链来进行合并,我们也不让你构建一个任务链.我们只要加一个disableOperatorChaining(禁用这个任务链),禁用这个任务链之后,就算你符合条件,他也不把你这两个task链在一起,形成一个统一的Task.<br>但是这两种那个更好呢?<strong>当然是有任务链的更好.有任务链可以提高吞吐,减少IO操作</strong>.<br>所以,大多数情况下,我这一行代码(streamEnv.disableOperatorChaining)不应该做.</p><p><strong>③共享组不同也不能形成任务链</strong> 共享组的作用就是把同一个任务放在同一个slot里面</p><p>相同并行度的one to one操作，Flink这样相连的算子链接在一起形成一个task，原来的算子成为里面的一部分。将算子链接成task是非常有效的优化：它能减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。链接的行为可以在编程API中进行指定。<br>streamEnv.disableOperatorChaining:表示所有操作算子都不构建任务链<br>.disableChaining() 加在其中一个算子中，表示：该算子和其他算子不一起构建任务链。它是独立的</p><p>图 task与operator chains:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210222115.png"></p><p>任务链案例代码地址:</p><p><a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo02/Flink01_WordCount_Chain.java">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo02/Flink01_WordCount_Chain.java</a></p><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-11_12-04-16.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;好记性-烂笔头&quot;&gt;&lt;a href=&quot;#好记性-烂笔头&quot; class=&quot;headerlink&quot; title=&quot;好记性,烂笔头:&quot;&gt;&lt;/a&gt;好记性,烂笔头:&lt;/h3&gt;&lt;p&gt;①socket不能多并行度消费. 而kafka是可以多并行度消费的. kafka有多个分区.   &lt;/p&gt;
&lt;p&gt;②keyby不是一个算子,他是决定我们的数据进入到下游的哪一个并行度里面的.他自己没有并行度的.他不会对数据做任何的操作.数据可能从一个并行度来的. 进过keyby之后,可能把他发到好多个并行度里面去了.&lt;/p&gt;
&lt;p&gt;8种数据传输的方式:&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;KeyBy: 按照key的hash值分区, 相同的key一定会分到相同的分区.即相同的key进入相同的并行度,也就是说进入同一个子任务.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Shuffle: 随机分的.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Rebalance: 全局轮询,即上游的所有并行度都对下游所有并行度轮询.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Rescale: 局部轮询,也就是说上游两个,下游四个.我上游两个在两个里面轮询了,一个人在两个里面轮询.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Global: 所有数据发送到下游同一个并行度.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Broadcast:所有数据发送到下游所有并行度.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Forward:要求并行度相同,因为他是一对一的.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Customer: 自定义.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink总结速览</title>
    <link href="http://xubatian.cn/Flink%E6%80%BB%E7%BB%93%E9%80%9F%E8%A7%88/"/>
    <id>http://xubatian.cn/Flink%E6%80%BB%E7%BB%93%E9%80%9F%E8%A7%88/</id>
    <published>2022-02-10T06:11:48.000Z</published>
    <updated>2022-02-10T06:40:53.045Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Flink-核心特点"><a href="#Flink-核心特点" class="headerlink" title="Flink 核心特点"></a>Flink 核心特点</h3><h4 id="批流一体"><a href="#批流一体" class="headerlink" title="批流一体"></a>批流一体</h4><p>所有的数据都天然带有时间的概念，必然发生在某一个时间点。把事件按照时间顺序排列起来，就形成了一个事件流，也叫作数据流。<strong>「无界数据」</strong>是持续产生的数据，所以必须持续地处理无界数据流。<strong>「有界数据」</strong>，就是在一个确定的时间范围内的数据流，有开始有结束，一旦确定了就不会再改变。</p><span id="more"></span><h4 id="可靠的容错能力"><a href="#可靠的容错能力" class="headerlink" title="可靠的容错能力"></a>可靠的容错能力</h4><ul><li><p>集群级容错</p></li><li><ul><li>集群管理器集成（Hadoop YARN、Mesos或Kubernetes）</li><li>高可用性设置（HA模式基于ApacheZooKeeper）</li></ul></li><li><p>应用级容错（ Checkpoint）</p></li><li><ul><li>一致性（其本身支持Exactly-Once 语义）</li><li>轻量级（检查点的执行异步和增量检查点）</li></ul></li><li><p>高吞吐、低延迟</p></li></ul><h4 id="运行时架构"><a href="#运行时架构" class="headerlink" title="运行时架构"></a>运行时架构</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141319.png"></p><ul><li><p>Flink 客户端</p></li><li><ul><li>提交Flink作业到Flink集群</li><li>Stream Graph 和 Job Graph构建</li></ul></li><li><p>JobManager</p></li><li><ul><li>资源申请</li><li>任务调度</li><li>应用容错</li></ul></li><li><p>TaskManager</p></li><li><ul><li>接收JobManager 分发的子任务，管理子任务</li><li>任务处理（消费数据、处理数据）</li></ul></li></ul><h2 id="Flink-应用"><a href="#Flink-应用" class="headerlink" title="Flink 应用"></a>Flink 应用</h2><h4 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h4><h5 id="DataStream-体系"><a href="#DataStream-体系" class="headerlink" title="DataStream 体系"></a>DataStream 体系</h5><ol><li><p>DataStream(每个DataStream都有一个Transformation对象)</p></li><li><p>DataStreamSource（DataStream的起点）</p></li><li><p>DataStreamSink（DataStream的输出）</p></li><li><p>KeyedStream（表示根据指定的Key记性分组的数据流）</p></li><li><p>WindowdeStream &amp; AllWindowedStream（根据key分组且基于WindowAssigner切分窗口的数据流）</p></li><li><p>JoinedStreams &amp; CoGroupedStreams</p></li><li><ol><li>JoinedStreams底层使用CoGroupedStreams来实现</li><li>CoGrouped侧重的是Group，对数据进行分组，是对同一个key上的两组集合进行操作</li><li>Join侧重的是数据对，对同一个key的每一对元素进行操作</li></ol></li><li><p>ConnectedStreams（表示两个数据流的组合）</p></li><li><p>BroadcastStream &amp; BroadcastConnectedStream（DataStream的广播行为）</p></li><li><p>IterativeStream（包含IterativeStream的Dataflow是一个有向有环图）</p></li><li><p>AsyncDataStream（在DataStream上使用异步函数的能力）</p></li></ol><h5 id="处理数据API"><a href="#处理数据API" class="headerlink" title="处理数据API"></a>处理数据API</h5><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141359.png"></p><h2 id="核心抽象"><a href="#核心抽象" class="headerlink" title="核心抽象"></a>核心抽象</h2><h3 id="环境对象"><a href="#环境对象" class="headerlink" title="环境对象"></a>环境对象</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141427.png"></p><h3 id="数据流元素"><a href="#数据流元素" class="headerlink" title="数据流元素"></a>数据流元素</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141448.png"></p><ol><li><p>StreamRecord（数据流中的一条记录｜事件）</p></li><li><ol><li>数据的值本身</li><li>时间戳（可选）</li></ol></li><li><p>LatencyMarker（用来近似评估延迟）</p></li><li><ol><li>周期性的在数据源算子中创造出来的时间戳</li><li>算子编号</li><li>数据源所在的Task编号</li></ol></li><li><p>Watemark（是一个时间戳，用来告诉算子所有时间早于等于Watermark的事件或记录都已经到达，不会再有比Watermark更早的记录，算子可以根据Watermark触发窗口的计算、清理资源等）</p></li><li><p>StreamStatus（用来通知Task是否会继续接收到上游的记录或者Watermark）</p></li><li><ol><li>空闲状态（IDLE）。</li><li>活动状态（ACTIVE）。</li></ol></li></ol><h3 id="Flink-异步IO"><a href="#Flink-异步IO" class="headerlink" title="Flink 异步IO"></a>Flink 异步IO</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141557.png"></p><p>顺序输出模式（先收到的数据元素先输出，后续数据元素的异步函数调用无论是否先完成，都需要等待）</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141620.png"></p><p>无序输出模式（先处理完的数据元素先输出，不保证消息顺序）</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141640.png"></p><h3 id="数据分区"><a href="#数据分区" class="headerlink" title="数据分区"></a>数据分区</h3><ul><li>ForwardPartitioner（用于在同一个OperatorChain中上下游算子之间的数据转发，实际上数据是直接传递给下游的）</li><li>ShufflePartitioner（随机将元素进行分区，可以确保下游的Task能够均匀地获得数据）</li><li>ReblancePartitioner（以Round-robin的方式为每个元素分配分区，确保下游的Task可以均匀地获得数据，避免数据倾斜）</li><li>RescalingPartitioner（用Round-robin选择下游的一个Task进行数据分区，如上游有2个Source，下游有6个Map，那么每个Source会分配3个固定的下游Map，不会向未分配给自己的分区写入数据）</li><li>BroadcastPartitioner（将该记录广播给所有分区）</li><li>KeyGroupStreamPartitioner（KeyedStream根据KeyGroup索引编号进行分区，该分区器不是提供给用户来用的）</li></ul><h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141709.png"></p><ul><li><p>WindowAssigner（用来决定某个元素被分配到哪个/哪些窗口中去）</p></li><li><p>WindowTrigger（决定一个窗口何时能够呗计算或清除，每一个窗口都拥有一个属于自己的Trigger）</p></li><li><p>WindowEvictor（窗口数据的过滤器，可在Window Function 执行前或后，从Window中过滤元素）</p></li><li><ul><li>CountEvictor：计数过滤器。在Window中保留指定数量的元素，并从窗口头部开始丢弃其余元素</li><li>DeltaEvictor：阈值过滤器。丢弃超过阈值的数据记录</li><li>TimeEvictor：时间过滤器。保留最新一段时间内的元素</li></ul></li></ul><h3 id="Watermark-（水印）"><a href="#Watermark-（水印）" class="headerlink" title="Watermark （水印）"></a>Watermark （水印）</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>用于处理乱序事件，而正确地处理乱序事件，通常用Watermark机制结合窗口来实现</p><h4 id="DataStream-Watermark-生成"><a href="#DataStream-Watermark-生成" class="headerlink" title="DataStream Watermark 生成"></a>DataStream Watermark 生成</h4><ol><li><p>Source Function 中生成Watermark</p></li><li><p>DataStream API 中生成Watermark</p></li><li><ol><li>AssingerWithPeriodicWatermarks （周期性的生成Watermark策略，不会针对每个事件都生成）</li><li>AssingerWithPunctuatedWatermarks （对每个事件都尝试进行Watermark的生成，如果生成的结果是null 或Watermark小于之前的，则不会发往下游）</li></ol></li></ol><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><h3 id="自主内存管理"><a href="#自主内存管理" class="headerlink" title="自主内存管理"></a>自主内存管理</h3><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><ol><li><p>JVM内存管理的不足</p></li><li><ol><li>有效数据密度低</li><li>垃圾回收（大数据场景下需要消耗大量的内存，更容易触发Full GC ）</li><li>OOM 问题影响稳定性</li><li>缓存未命中问题（Java对象在堆上存储时并不是连续的）</li></ol></li><li><p>自主内存管理</p></li><li><ol><li>堆上内存的使用、监控、调试简单，堆外内存出现问题后的诊断则较为复杂</li><li>Flink有时需要分配短生命周期的MemorySegment，在堆外内存上分配比在堆上内存开销更高。</li><li>在Flink的测试中，部分操作在堆外内存上会比堆上内存慢</li><li>大内存（上百GB）JVM的启动需要很长时间，Full GC可以达到分钟级。使用堆外内存，可以将大量的数据保存在堆外，极大地减小堆内存，避免GC和内存溢出的问题。</li><li>高效的IO操作。堆外内存在写磁盘或网络传输时是zero-copy，而堆上内存则至少需要1次内存复制。</li><li>堆外内存是进程间共享的。也就是说，即使JVM进程崩溃也不会丢失数据。这可以用来做故障恢复（Flink暂时没有利用这项功能，不过未来很可能会去做）</li><li>堆外内存的优势</li><li>堆外内存的不足</li></ol></li></ol><h3 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h3><h4 id="内存模型图"><a href="#内存模型图" class="headerlink" title="内存模型图"></a>内存模型图</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141759.png"></p><h4 id="MemorySegment（内存段）"><a href="#MemorySegment（内存段）" class="headerlink" title="MemorySegment（内存段）"></a>MemorySegment（内存段）</h4><p>一个MemorySegment对应着一个32KB大小的内存块。这块内存既可以是堆上内存（Java的byte数组），也可以是堆外内存（基于Netty的DirectByteBuffer）</p><h5 id="图解"><a href="#图解" class="headerlink" title="图解"></a>图解</h5><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141819.png"></p><h5 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h5><ul><li><p>BYTE_ARRAY_BASE_OFFSET（二进制字节数组的起始索引）</p></li><li><p>LITTLE_ENDIAN（判断是否为Little Endian模式的字节存储顺序，若不是，就是Big Endian模式）</p></li><li><ul><li>Big Endian：低地址存放最高有效字节（MSB）</li><li>Little Endian：低地址存放最低有效字节（LSB）X86机器</li></ul></li><li><p>HeapMemory（如果MemeorySegment使用堆上内存，则表示一个堆上的字节数组（byte［］），如果MemorySegment使用堆外内存，则为null）</p></li><li><p>address（字节数组对应的相对地址）</p></li><li><p>addressLimit（标识地址结束位置）</p></li><li><p>size（内存段的字节数）</p></li></ul><h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><ul><li>HybirdMemorySegment：用来分配堆上和堆外内存和堆上内存，Flink 在实际使用中只使用了改方式。原因是当有多个实现时，JIT无法直接在编译时自动识别优化</li><li>HeapMemorySegment：用来分配堆上内存，实际没有实现</li></ul><h4 id="MemroyManager（内存管理器）"><a href="#MemroyManager（内存管理器）" class="headerlink" title="MemroyManager（内存管理器）"></a>MemroyManager（内存管理器）</h4><p>实际申请的是堆外内存，通过RocksDB的Block Cache和WriterBufferManager参数来限制，RocksDB使用的内存量</p><h2 id="State（状态）"><a href="#State（状态）" class="headerlink" title="State（状态）"></a>State（状态）</h2><p>状态管理需要考虑的因素：</p><ol><li>状态数据的存储和访问</li><li>状态数据的备份和恢复</li><li>状态数据的划分和动态扩容</li><li>状态数据的清理</li></ol><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141844.png"></p><h3 id="状态存储"><a href="#状态存储" class="headerlink" title="状态存储"></a>状态存储</h3><ul><li>MemoryStateBackend：纯内存，适用于验证、测试，不推荐生产环境</li><li>FsStateBackend：内存+文件，适用于长周期大规模的数据</li><li>RocksDBStateBackend：RocksDB，适用于长周期大规模的数据</li></ul><h3 id="重分布"><a href="#重分布" class="headerlink" title="重分布"></a>重分布</h3><ul><li>ListState：并行度在改变的时候，会将并发上的每个List都取出，然后把这些List合并到一个新的List,根据元素的个数均匀分配给新的Task</li><li>UnionListState:把划分的方式交给用户去做，当改变并发的时候，会将原来的List拼接起来，然后不做划分，直接交给用户</li><li>BroadcastState:变并发的时候，把这些数据分发到新的Task即可</li><li>KeyState：Key-Group数量取决于最大并行度（MaxParallism）</li></ul><h2 id="作业提交"><a href="#作业提交" class="headerlink" title="作业提交"></a>作业提交</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141900.png"></p><h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><h3 id="关系图"><a href="#关系图" class="headerlink" title="关系图"></a>关系图</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141918.png"></p><h3 id="Slot选择策略"><a href="#Slot选择策略" class="headerlink" title="Slot选择策略"></a>Slot选择策略</h3><ul><li><p>LocationPreferenceSlotSelectionStrategy（位置优先的选择策略）</p></li><li><ul><li>DefaultLocationPreferenceSlotSelectionStrategy（默认策略），该策略不考虑资源的均衡分配，会从满足条件的可用Slot集合选择第1个</li><li>EvenlySpreadOutLocationPreferenceSlotSelectionStrategy（均衡策略），该策略考虑资源的均衡分配，会从满足条件的可用Slot集合中选择剩余资源最多的Slot，尽量让各个TaskManager均衡地承担计算压力</li></ul></li><li><p>PreviousAllocationSlotSelectionStrategy（已分配Slot优先的选择策略），如果当前没有空闲的已分配Slot，则仍然会使用位置优先的策略来分配和申请Slot</p></li></ul><h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><ul><li><p>SchedulerNG （调度器）</p></li><li><ul><li>作用</li><li>实现</li></ul></li><li><ol><li>DefaultScheduler（使用ScchedulerStrategy来实现）</li><li>LegacyScheduler（实际使用了原来的ExecutionGraph的调度逻辑）</li></ol></li><li><ol><li>作业的生命周期管理（开始调度、挂起、取消）</li><li>作业执行资源的申请、分配、释放</li><li>作业状态的管理（发布过程中的状态变化、作业异常时的FailOver</li><li>作业的信息提供，对外提供作业的详细信息</li></ol></li><li><p>SchedulingStrategy（调度策略）</p></li><li><ul><li>实现</li></ul></li><li><ol><li>EagerSchelingStrategy（该调度策略用来执行流计算作业的调度）</li><li>LazyFromSourceSchedulingStrategy（该调度策略用来执行批处理作业的调度）</li></ol></li><li><ol><li>startScheduling：调度入口，触发调度器的调度行为</li><li>restartTasks：重启执行失败的Task，一般是Task执行异常导致的</li><li>onExecutionStateChange：当Execution的状态发生改变时</li><li>onPartitionConsumable：当IntermediateResultParitititon中的数据可以消费时</li></ol></li><li><p>ScheduleMode（调度模式）</p></li><li><ol><li>Eager调度（该模式适用于流计算。一次性申请需要所有的资源，如果资源不足，则作业启动失败。）</li><li>Lazy_From_Sources分阶段调度（适用于批处理。从Source Task开始分阶段调度，申请资源的时候，一次性申请本阶段所需要的所有资源。上游Task执行完毕后开始调度执行下游的Task，读取上游的数据，执行本阶段的计算任务，执行完毕之后，调度后一个阶段的Task，依次进行调度，直到作业执行完成）</li><li>Lazy_From_Sources_With_Batch_Slot_Request分阶段Slot重用调度（适用于批处理。与分阶段调度基本一样，区别在于该模式下使用批处理资源申请模式，可以在资源不足的情况下执行作业，但是需要确保在本阶段的作业执行中没有Shuffle行为）</li></ol></li></ul><h3 id="关键组件"><a href="#关键组件" class="headerlink" title="关键组件"></a>关键组件</h3><h4 id="JobMaster"><a href="#JobMaster" class="headerlink" title="JobMaster"></a>JobMaster</h4><ol><li><p>调度执行和管理（将JobGraph转化为ExecutionGraph，调度Task的执行，并处理Task的异常）</p></li><li><ul><li>InputSplit 分配</li><li>结果分区跟踪</li><li>作业执行异常</li></ul></li><li><p>作业Slot资源管理</p></li><li><p>检查点与保存点</p></li><li><p>监控运维相关</p></li><li><p>心跳管理</p></li></ol><h4 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h4><p>结构</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141948.png"></p><h3 id="作业调度失败"><a href="#作业调度失败" class="headerlink" title="作业调度失败"></a>作业调度失败</h3><h4 id="失败异常分类"><a href="#失败异常分类" class="headerlink" title="失败异常分类"></a>失败异常分类</h4><ul><li>NonRecoverableError：不可恢复的错误。此类错误意味着即便是重启也无法恢复作业到正常状态，一旦发生此类错误，则作业执行失败，直接退出作业执行</li><li>PartitionDataMissingError：分区数据不可访问错误。下游Task无法读取上游Task产生的数据，需要重启上游的Task</li><li>EnvironmentError：环境的错误。这种错误需要在调度策略上进行改进，如使用黑名单机制，排除有问题的机器、服务，避免将失败的Task重新调度到这些机器上。</li><li>RecoverableError：可恢复的错误</li></ul><h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><h3 id="容错保证语义"><a href="#容错保证语义" class="headerlink" title="容错保证语义"></a>容错保证语义</h3><ul><li>At-Most-Once（最多一次）</li><li>At-Leat-Once（最少一次）</li><li>Exactly-Once（引擎内严格一次）</li><li>End-to-End Exaacly-Once （端到端严格一次）</li></ul><h3 id="保存点恢复"><a href="#保存点恢复" class="headerlink" title="保存点恢复"></a>保存点恢复</h3><ol><li>算子顺序的改变，如果对应的UID没变，则可以恢复，如果对应的UID变了则恢复失败。</li><li>作业中添加了新的算子，如果是无状态算子，没有影响，可以正常恢复，如果是有状态的算子，跟无状态的算子一样处理。</li><li>从作业中删除了一个有状态的算子，默认需要恢复保存点中所记录的所有算子的状态，如果删除了一个有状态的算子，从保存点恢复的时候被删除的OperatorID找不到，所以会报错，可以通过在命令中添加-allowNonRestoredState （short: -n）跳过无法恢复的算子。</li><li>添加和删除无状态的算子，如果手动设置了UID，则可以恢复，保存点中不记录无状态的算子，如果是自动分配的UID，那么有状态算子的UID可能会变（Flink使用一个单调递增的计数器生成UID，DAG改版，计数器极有可能会变），很有可能恢复失败。</li><li>恢复的时候调整并行度，Flink1.2.0及以上版本,如果没有使用作废的API，则没问题；1.2.0以下版本需要首先升级到1.2.0才可以。</li></ol><h3 id="端到端严格一次"><a href="#端到端严格一次" class="headerlink" title="端到端严格一次"></a>端到端严格一次</h3><h4 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h4><ul><li>数据源支持断点读取</li><li>外部存储支持回滚机制或者满足幂等性</li></ul><h3 id="图解-1"><a href="#图解-1" class="headerlink" title="图解"></a>图解</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210142018.png"></p><h4 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h4><p>TwoPhaseCommitSinkFunction</p><ol><li>beginTransaction，开启一个事务，在临时目录中创建一个临时文件，之后写入数据到该文件中。此过程为不同的事务创建隔离，避免数据混淆。</li><li>preCommit。预提交阶段。将缓存数据块写出到创建的临时文件，然后关闭该文件，确保不再写入新数据到该文件，同时开启一个新事务，执行属于下一个检查点的写入操作。</li><li>commit。在提交阶段，以原子操作的方式将上一阶段的文件写入真正的文件目录下。如果提交失败，Flink应用会重启，并调用TwoPhaseCommitSinkFunction#recoverAndCommit方法尝试恢复并重新提交事务。</li><li>abort。一旦终止事务，删除临时文件。</li></ol><h2 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h2><h3 id="关系图-1"><a href="#关系图-1" class="headerlink" title="关系图"></a>关系图</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210142040.png"></p><h2 id="FLINK-API"><a href="#FLINK-API" class="headerlink" title="FLINK API"></a>FLINK API</h2><h3 id="DataStrem-JOIN"><a href="#DataStrem-JOIN" class="headerlink" title="DataStrem JOIN"></a>DataStrem JOIN</h3><h4 id="Window-JOIN"><a href="#Window-JOIN" class="headerlink" title="Window JOIN"></a>Window JOIN</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stream.join(otherStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(&lt;WindowAssigner&gt;)</span><br><span class="line">    .apply(&lt;JoinFunction&gt;)</span><br></pre></td></tr></table></figure><h3 id="Tumbling-Window-Join"><a href="#Tumbling-Window-Join" class="headerlink" title="Tumbling Window Join"></a>Tumbling Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(TumblingEventTimeWindows.of(Time.milliseconds(2)))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><h3 id="Sliding-Window-Join"><a href="#Sliding-Window-Join" class="headerlink" title="Sliding Window Join"></a>Sliding Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(SlidingEventTimeWindows.of(Time.milliseconds(2) /* size */, Time.milliseconds(1) /* slide */))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><h3 id="Session-Window-Join"><a href="#Session-Window-Join" class="headerlink" title="Session Window Join"></a>Session Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(EventTimeSessionWindows.withGap(Time.milliseconds(1)))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><p>知识源于积累,登峰造极源于自律!</p><p>好文章就得收藏慢慢品, 文章转载于: <a href="https://mp.weixin.qq.com/s/44G_siAfCLINOR0bBrun3g">https://mp.weixin.qq.com/s/44G_siAfCLINOR0bBrun3g</a></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;Flink-核心特点&quot;&gt;&lt;a href=&quot;#Flink-核心特点&quot; class=&quot;headerlink&quot; title=&quot;Flink 核心特点&quot;&gt;&lt;/a&gt;Flink 核心特点&lt;/h3&gt;&lt;h4 id=&quot;批流一体&quot;&gt;&lt;a href=&quot;#批流一体&quot; class=&quot;headerlink&quot; title=&quot;批流一体&quot;&gt;&lt;/a&gt;批流一体&lt;/h4&gt;&lt;p&gt;所有的数据都天然带有时间的概念，必然发生在某一个时间点。把事件按照时间顺序排列起来，就形成了一个事件流，也叫作数据流。&lt;strong&gt;「无界数据」&lt;/strong&gt;是持续产生的数据，所以必须持续地处理无界数据流。&lt;strong&gt;「有界数据」&lt;/strong&gt;，就是在一个确定的时间范围内的数据流，有开始有结束，一旦确定了就不会再改变。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>kafka面试常遇问题</title>
    <link href="http://xubatian.cn/kafka%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%81%87%E9%97%AE%E9%A2%98/"/>
    <id>http://xubatian.cn/kafka%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%81%87%E9%97%AE%E9%A2%98/</id>
    <published>2022-02-10T03:16:03.000Z</published>
    <updated>2022-02-10T06:41:01.803Z</updated>
    
    <content type="html"><![CDATA[<ol><li>为什么要用消息队列？为什么选择了kafka?</li><li>kafka的组件与作用(架构)？</li><li>kafka为什么要分区？</li><li>Kafka生产者分区策略？</li><li>kafka的数据可靠性怎么保证？(丢，重)</li><li>kafka的副本机制？</li><li>kafka的消费分区分配策略？</li><li>kafka的offset怎么维护？</li><li>kafka为什么这么快？(高效读写数据)</li><li>Kafka消息数据积压，Kafka消费能力不足怎么处理？</li><li>kafka事务是怎么实现的？</li><li>Kafka中的数据是有序的吗？</li><li>Kafka可以按照时间消费数据？</li><li>Kafka单条日志传输大小？</li><li>Kafka参数优化？</li><li>Kafka适合以下应用场景？</li><li>Exactly Once语义？在流式计算中怎么保持？</li></ol><span id="more"></span><h2 id="解析参考"><a href="#解析参考" class="headerlink" title="解析参考"></a>解析参考</h2><h3 id="为什么要用消息队列"><a href="#为什么要用消息队列" class="headerlink" title="为什么要用消息队列"></a>为什么要用消息队列</h3><ol><li>解耦</li></ol><p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p><ol><li>可恢复性</li></ol><p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p><ol><li>缓冲</li></ol><p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p><ol><li>灵活性与峰值处理能力</li></ol><p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p><ol><li>异步通信</li></ol><p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p><h3 id="为什么选择了kafka"><a href="#为什么选择了kafka" class="headerlink" title="为什么选择了kafka"></a>为什么选择了kafka</h3><ol><li>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒。</li><li>可扩展性：kafka集群支持热扩展。</li><li>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失。</li><li>容错性：允许集群中节点故障（若副本数量为n,则允许n-1个节点故障）。</li><li>高并发：支持数千个客户端同时读写。</li></ol><h3 id="kafka的组件与作用-架构"><a href="#kafka的组件与作用-架构" class="headerlink" title="kafka的组件与作用(架构)"></a>kafka的组件与作用(架构)</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112112.png"></p><ol><li>Producer ：消息生产者，就是向kafka broker发消息的客户端。</li><li>Consumer ：消息消费者，向kafka broker取消息的客户端。</li><li>Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li><li>Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</li><li>Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic。</li><li>Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。</li><li>Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</li><li>leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</li><li>follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。</li></ol><h3 id="kafka为什么要分区"><a href="#kafka为什么要分区" class="headerlink" title="kafka为什么要分区"></a>kafka为什么要分区</h3><ol><li>方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了。</li><li>可以提高并发，因为可以以Partition为单位读写。</li></ol><h3 id="Kafka生产者分区策略"><a href="#Kafka生产者分区策略" class="headerlink" title="Kafka生产者分区策略"></a>Kafka生产者分区策略</h3><ol><li>指明 partition 的情况下，直接将指明的值直接作为partiton值。</li><li>没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到partition值。</li><li>既没有partition值又没有key值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与topic可用的partition总数取余得到partition值，也就是常说的round-robin算法。</li></ol><h3 id="kafka的数据可靠性怎么保证"><a href="#kafka的数据可靠性怎么保证" class="headerlink" title="kafka的数据可靠性怎么保证"></a>kafka的数据可靠性怎么保证</h3><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。所以引出ack机制。</p><p><strong>ack应答机制（可问：造成数据重复和丢失的相关问题）</strong></p><p>Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。acks参数配置：</p><ul><li>0：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据。</li><li>1：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据。</li></ul><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112241.png"></p><ul><li>-1（all）：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。</li></ul><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112315.png"></p><h3 id="副本数据同步策略"><a href="#副本数据同步策略" class="headerlink" title="副本数据同步策略"></a>副本数据同步策略</h3><table><thead><tr><th align="left">方案</th><th align="center">优点</th><th align="right">缺点</th></tr></thead><tbody><tr><td align="left">半数以上完成同步，就发送ack</td><td align="center">延迟低</td><td align="right">选举新的leader时，容忍n台节点的故障，需要2n+1个副本</td></tr><tr><td align="left">全部完成同步，才发送ack</td><td align="center">选举新的leader时，容忍n台节点的故障，需要n+1个副本</td><td align="right">延迟高</td></tr></tbody></table><p>选择最后一个的原因：</p><ol><li>同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</li><li>虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。</li></ol><h3 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h3><p>如果采用全部完成同步，才发送ack的副本的同步策略的话：提出问题：leader收到数据，所有follower都开始同步数据，但有一个follower，因为某种故障，迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步，才能发送ack。这个问题怎么解决呢？</p><p>Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</p><h3 id="故障处理-LEO与HW"><a href="#故障处理-LEO与HW" class="headerlink" title="故障处理(LEO与HW)"></a>故障处理(LEO与HW)</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112418.png"></p><p>LEO：指的是每个副本最大的offset。</p><p>HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。</p><h6 id="follower故障"><a href="#follower故障" class="headerlink" title="follower故障"></a>follower故障</h6><p>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</p><h6 id="leader故障"><a href="#leader故障" class="headerlink" title="leader故障"></a>leader故障</h6><p>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</p><p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p><p>问题纠正:</p><p> (1)ISR包含leader，不只是follower,所有的元数据都是Controller来维护的</p><p> (2)其实不是什么ack不ack的 Follower 发起 Fetcher请求 之后会返回 success ； 这就理解为  Follower向leader回复了ack，容易误解为ack是生产者和borker的关系。还有这句话应该是follow向leader反馈消息</p><h3 id="kafka的副本机制"><a href="#kafka的副本机制" class="headerlink" title="kafka的副本机制"></a>kafka的副本机制</h3><p>参考上一个问题(副本数据同步策略)。</p><h3 id="kafka的消费分区分配策略"><a href="#kafka的消费分区分配策略" class="headerlink" title="kafka的消费分区分配策略"></a>kafka的消费分区分配策略</h3><p>一个consumer group中有多个consumer，一个topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费 Kafka有三种分配策略，一是RoundRobin，一是Range。高版本还有一个StickyAssignor策略 将分区的所有权从一个消费者移到另一个消费者称为重新平衡（rebalance）。当以下事件发生时，Kafka 将会进行一次分区分配：</p><p>同一个 Consumer Group 内新增消费者。</p><p>消费者离开当前所属的Consumer Group，包括shuts down或crashes。</p><h6 id="Range分区分配策略"><a href="#Range分区分配策略" class="headerlink" title="Range分区分配策略"></a>Range分区分配策略</h6><p>Range是对每个Topic而言的（即一个Topic一个Topic分），首先对同一个Topic里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区。假如有10个分区，3个消费者线程，把分区按照序号排列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0，1，2，3，4，5，6，7，8，9</span><br></pre></td></tr></table></figure><p>消费者线程为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C1-0，C2-0，C2-1</span><br></pre></td></tr></table></figure><p>那么用partition数除以消费者线程的总数来决定每个消费者线程消费几个partition，如果除不尽，前面几个消费者将会多消费一个分区。在我们的例子里面，我们有10个分区，3个消费者线程，10/3 = 3，而且除除不尽，那么消费者线程C1-0将会多消费一个分区，所以最后分区分配的结果看起来是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C1-0：0，1，2，3</span><br><span class="line"></span><br><span class="line">C2-0：4，5，6</span><br><span class="line"></span><br><span class="line">C2-1：7，8，9</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果有11个分区将会是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">C1-0：0，1，2，3</span><br><span class="line"></span><br><span class="line">C2-0：4，5，6，7</span><br><span class="line"></span><br><span class="line">C2-1：8，9，10</span><br></pre></td></tr></table></figure><p>假如我们有两个主题T1,T2，分别有10个分区，最后的分配结果将会是这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">C1-0：T1（0，1，2，3） T2（0，1，2，3）</span><br><span class="line"></span><br><span class="line">C2-0：T1（4，5，6） T2（4，5，6）</span><br><span class="line"></span><br><span class="line">C2-1：T1（7，8，9） T2（7，8，9）</span><br></pre></td></tr></table></figure><h6 id="RoundRobinAssignor分区分配策略"><a href="#RoundRobinAssignor分区分配策略" class="headerlink" title="RoundRobinAssignor分区分配策略"></a>RoundRobinAssignor分区分配策略</h6><p>RoundRobinAssignor策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者. 使用RoundRobin策略有两个前提条件必须满足：</p><p>同一个消费者组里面的所有消费者的num.streams（消费者消费线程数）必须相等；每个消费者订阅的主题必须相同。加入按照 hashCode 排序完的topic-partitions组依次为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9</span><br></pre></td></tr></table></figure><p>我们的消费者线程排序为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C1-0, C1-1, C2-0, C2-1</span><br></pre></td></tr></table></figure><p>最后分区分配的结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C1-0 将消费 T1-5, T1-2, T1-6 分区</span><br><span class="line"></span><br><span class="line">C1-1 将消费 T1-3, T1-1, T1-9 分区</span><br><span class="line"></span><br><span class="line">C2-0 将消费 T1-0, T1-4 分区</span><br><span class="line"></span><br><span class="line">C2-1 将消费 T1-8, T1-7 分区</span><br></pre></td></tr></table></figure><h6 id="StickyAssignor分区分配策略"><a href="#StickyAssignor分区分配策略" class="headerlink" title="StickyAssignor分区分配策略"></a>StickyAssignor分区分配策略</h6><p>Kafka从0.11.x版本开始引入这种分配策略，它主要有两个目的：</p><p>分区的分配要尽可能的均匀，分配给消费者者的主题分区数最多相差一个 分区的分配尽可能的与上次分配的保持相同。当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目的，StickyAssignor策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂很多。</p><p>假设消费组内有3个消费者</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C0、C1、C2</span><br></pre></td></tr></table></figure><p>它们都订阅了4个主题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t0、t1、t2、t3</span><br></pre></td></tr></table></figure><p>并且每个主题有2个分区，也就是说整个消费组订阅了</p><p>t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区</p><p>最终的分配结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0、t1p1、t3p0</span><br><span class="line"></span><br><span class="line">消费者C1：t0p1、t2p0、t3p1</span><br><span class="line"></span><br><span class="line">消费者C2：t1p0、t2p1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样初看上去似乎与采用RoundRobinAssignor策略所分配的结果相同</p><p>此时假设消费者C1脱离了消费组，那么消费组就会执行再平衡操作，进而消费分区会重新分配。如果采用RoundRobinAssignor策略，那么此时的分配结果如下：</p><p>消费者C0：t0p0、t1p0、t2p0、t3p0</p><p>消费者C2：t0p1、t1p1、t2p1、t3p1</p><p>如分配结果所示，RoundRobinAssignor策略会按照消费者C0和C2进行重新轮询分配。而如果此时使用的是StickyAssignor策略，那么分配结果为：</p><p>消费者C0：t0p0、t1p1、t3p0、t2p0</p><p>消费者C2：t1p0、t2p1、t0p1、t3p1</p><p>可以看到分配结果中保留了上一次分配中对于消费者C0和C2的所有分配结果，并将原来消费者C1的“负担”分配给了剩余的两个消费者C0和C2，最终C0和C2的分配还保持了均衡。</p><p>如果发生分区重分配，那么对于同一个分区而言有可能之前的消费者和新指派的消费者不是同一个，对于之前消费者进行到一半的处理还要在新指派的消费者中再次复现一遍，这显然很浪费系统资源。StickyAssignor策略如同其名称中的“sticky”一样，让分配策略具备一定的“粘性”，尽可能地让前后两次分配相同，进而减少系统资源的损耗以及其它异常情况的发生。</p><p>到目前为止所分析的都是消费者的订阅信息都是相同的情况，我们来看一下订阅信息不同的情况下的处理。</p><p>举例，同样消费组内有3个消费者：</p><p>C0、C1、C2</p><p>集群中有3个主题：</p><p>t0、t1、t2</p><p>这3个主题分别有</p><p>1、2、3个分区</p><p>也就是说集群中有</p><p>t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0订阅了主题t0</span><br><span class="line"></span><br><span class="line">消费者C1订阅了主题t0和t1</span><br><span class="line"></span><br><span class="line">消费者C2订阅了主题t0、t1和t2</span><br></pre></td></tr></table></figure><p>如果此时采用RoundRobinAssignor策略：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0</span><br><span class="line"></span><br><span class="line">消费者C1：t1p0</span><br><span class="line"></span><br><span class="line">消费者C2：t1p1、t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>如果此时采用的是StickyAssignor策略：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0</span><br><span class="line"></span><br><span class="line">消费者C1：t1p0、t1p1</span><br><span class="line"></span><br><span class="line">消费者C2：t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>此时消费者C0脱离了消费组，那么RoundRobinAssignor策略的分配结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">消费者C1：t0p0、t1p1</span><br><span class="line"></span><br><span class="line">消费者C2：t1p0、t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>StickyAssignor策略，那么分配结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">消费者C1：t1p0、t1p1、t0p0</span><br><span class="line"></span><br><span class="line">消费者C2：t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配：</p><p>t1p0、t1p1、t2p0、t2p1、t2p2。</p><p>从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异，这个策略的代码实现也是异常复杂。</p><h3 id="kafka的offset怎么维护"><a href="#kafka的offset怎么维护" class="headerlink" title="kafka的offset怎么维护"></a>kafka的offset怎么维护</h3><p>Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112614.png"></p><p>从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</p><p>额外补充：实际开发场景中在Spark和Flink中，可以自己手动提交kafka的offset，或者是flink两阶段提交自动提交offset。</p><h3 id="kafka为什么这么快"><a href="#kafka为什么这么快" class="headerlink" title="kafka为什么这么快"></a>kafka为什么这么快</h3><ol><li>Kafka本身是分布式集群，同时采用分区技术，并发度高。</li><li>顺序写磁盘</li></ol><p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。</p><ol><li>零拷贝技术</li></ol><p>零拷贝并不是不需要拷贝，而是减少不必要的拷贝次数。通常是说在IO读写过程中。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112638.png"></p><p>传统IO流程：</p><p>第一次：将磁盘文件，读取到操作系统内核缓冲区。</p><p>第二次：将内核缓冲区的数据，copy到application应用程序的buffer。</p><p>第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)</p><p>第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。</p><p>传统方式，读取磁盘文件并进行网络发送，经过的四次数据copy是非常繁琐的。实际IO读写，需要进行IO中断，需要CPU响应中断(带来上下文切换)，尽管后来引入DMA来接管CPU的中断请求，但四次copy是存在“不必要的拷贝”的。</p><p>重新思考传统IO方式，会注意到实际上并不需要第二个和第三个数据副本。应用程序除了缓存数据并将其传输回套接字缓冲区之外什么都不做。相反，数据可以直接从读缓冲区传输到套接字缓冲区。</p><p>显然，第二次和第三次数据copy 其实在这种场景下没有什么帮助反而带来开销，这也正是零拷贝出现的意义。</p><p>所以零拷贝是指读取磁盘文件后，不需要做其他处理，直接用网络发送出去。</p><h3 id="Kafka消费能力不足怎么处理"><a href="#Kafka消费能力不足怎么处理" class="headerlink" title="Kafka消费能力不足怎么处理"></a>Kafka消费能力不足怎么处理</h3><ol><li>如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）</li><li>如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间&lt;生产速度），使处理的数据小于生产的数据，也会造成数据积压。</li></ol><h3 id="kafka事务是怎么实现的"><a href="#kafka事务是怎么实现的" class="headerlink" title="kafka事务是怎么实现的"></a>kafka事务是怎么实现的</h3><p>Kafka从0.11版本开始引入了事务支持。事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p><h6 id="Producer事务"><a href="#Producer事务" class="headerlink" title="Producer事务"></a>Producer事务</h6><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID。为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p><h6 id="Consumer事务"><a href="#Consumer事务" class="headerlink" title="Consumer事务"></a>Consumer事务</h6><p>对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</p><h3 id="Kafka中的数据是有序的吗"><a href="#Kafka中的数据是有序的吗" class="headerlink" title="Kafka中的数据是有序的吗"></a>Kafka中的数据是有序的吗</h3><p>单分区内有序。</p><p>多分区，分区与分区间无序。</p><h3 id="Kafka可以按照时间消费数据吗"><a href="#Kafka可以按照时间消费数据吗" class="headerlink" title="Kafka可以按照时间消费数据吗"></a>Kafka可以按照时间消费数据吗</h3><p>可以，提供的API方法：</p><p>KafkaUtil.fetchOffsetsWithTimestamp(topic, sTime, kafkaProp)</p><h3 id="Kafka单条日志传输大小"><a href="#Kafka单条日志传输大小" class="headerlink" title="Kafka单条日志传输大小"></a>Kafka单条日志传输大小</h3><p>kafka对于消息体的大小默认为单条最大值是1M但是在我们应用场景中, 常常会出现一条消息大于1M，如果不对kafka进行配置。则会出现生产者无法将消息推送到kafka或消费者无法去消费kafka里面的数据, 这时我们就要对kafka进行以下配置：server.properties</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">replica.fetch.max.bytes: 1048576  broker可复制的消息的最大字节数, 默认为1M</span><br><span class="line">message.max.bytes: 1000012   kafka 会接收单个消息size的最大限制， 默认为1M左右</span><br><span class="line"></span><br><span class="line">message.max.bytes必须小于等于replica.fetch.max.bytes，否则就会导致replica之间数据同步失败</span><br></pre></td></tr></table></figure><h3 id="Kafka参数优化"><a href="#Kafka参数优化" class="headerlink" title="Kafka参数优化"></a>Kafka参数优化</h3><h6 id="Broker参数配置（server-properties）"><a href="#Broker参数配置（server-properties）" class="headerlink" title="Broker参数配置（server.properties）"></a>Broker参数配置（server.properties）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1、日志保留策略配置</span><br><span class="line"># 保留三天，也可以更短 （log.cleaner.delete.retention.ms）</span><br><span class="line">log.retention.hours=72</span><br><span class="line"></span><br><span class="line">2、Replica相关配置</span><br><span class="line">default.replication.factor:1 默认副本1个</span><br><span class="line"></span><br><span class="line">3、网络通信延时</span><br><span class="line">replica.socket.timeout.ms:30000 #当集群之间网络不稳定时,调大该参数</span><br><span class="line">replica.lag.time.max.ms= 600000# 如果网络不好,或者kafka集群压力较大,会出现副本丢失,然后会频繁复制副本,导致集群压力更大,此时可以调大该参数。</span><br></pre></td></tr></table></figure><h6 id="Producer优化（producer-properties）"><a href="#Producer优化（producer-properties）" class="headerlink" title="Producer优化（producer.properties）"></a>Producer优化（producer.properties）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">compression.type:none                 gzip  snappy  lz4  </span><br><span class="line">#默认发送不进行压缩，推荐配置一种适合的压缩算法，可以大幅度的减缓网络压力和Broker的存储压力。</span><br></pre></td></tr></table></figure><h6 id="Kafka内存调整（kafka-server-start-sh）"><a href="#Kafka内存调整（kafka-server-start-sh）" class="headerlink" title="Kafka内存调整（kafka-server-start.sh）"></a>Kafka内存调整（kafka-server-start.sh）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">默认内存1个G，生产环境尽量不要超过6个G。</span><br><span class="line">export KAFKA_HEAP_OPTS=&quot;-Xms4g -Xmx4g&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Kafka适合以下应用场景"><a href="#Kafka适合以下应用场景" class="headerlink" title="Kafka适合以下应用场景"></a>Kafka适合以下应用场景</h3><ol><li>日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer。</li><li>消息系统：解耦生产者和消费者、缓存消息等。</li><li>用户活动跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后消费者通过订阅这些topic来做实时的监控分析，亦可保存到数据库。</li><li>运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；</li><li>流式处理：比如spark和flink。</li></ol><h3 id="Exactly-Once语义"><a href="#Exactly-Once语义" class="headerlink" title="Exactly Once语义"></a>Exactly Once语义</h3><p>将服务器的ACK级别设置为-1，可以保证Producer到Server之间不会丢失数据，即At Least Once语义。相对的，将服务器ACK级别设置为0，可以保证生产者每条消息只会被发送一次，即At Most Once语义。</p><p>At Least Once可以保证数据不丢失，但是不能保证数据不重复；</p><p>相对的，At Least Once可以保证数据不重复，但是不能保证数据不丢失。</p><p>但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即Exactly Once语义。在0.11版本以前的Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11版本的Kafka，引入了一项重大特性：幂等性。</p><p>开启幂等性enable.idempotence=true。</p><p>所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条。幂等性结合At Least Once语义，就构成了Kafka的Exactly Once语义。即：</p><p>At Least Once + 幂等性 = Exactly Once</p><p>Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带Sequence Number。而Broker端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。</p><p>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once。</p><h3 id="补充，在流式计算中怎么Exactly-Once语义？以flink为例"><a href="#补充，在流式计算中怎么Exactly-Once语义？以flink为例" class="headerlink" title="补充，在流式计算中怎么Exactly Once语义？以flink为例"></a>补充，在流式计算中怎么Exactly Once语义？以flink为例</h3><h4 id="souce"><a href="#souce" class="headerlink" title="souce"></a>souce</h4><p>souce使用执行ExactlyOnce的数据源，比如kafka等</p><p>内部使用FlinkKafakConsumer，并开启CheckPoint，偏移量会保存到StateBackend中，并且默认会将偏移量写入到topic中去，即_consumer_offsets Flink设置CheckepointingModel.EXACTLY_ONCE</p><h4 id="sink"><a href="#sink" class="headerlink" title="sink"></a>sink</h4><p>存储系统支持覆盖也即幂等性：如Redis,Hbase,ES等 存储系统不支持覆：需要支持事务(预写式日志或者两阶段提交),两阶段提交可参考Flink集成的kafka sink的实现。</p><p>知识源于积累,登峰造极源于自律!</p><p>好文章就得收藏慢慢品, 文章转载于: <a href="https://mp.weixin.qq.com/s/_bZvPeAgC64ENzhIzydjSA">https://mp.weixin.qq.com/s/_bZvPeAgC64ENzhIzydjSA</a></p>]]></content>
    
    
    <summary type="html">&lt;ol&gt;
&lt;li&gt;为什么要用消息队列？为什么选择了kafka?&lt;/li&gt;
&lt;li&gt;kafka的组件与作用(架构)？&lt;/li&gt;
&lt;li&gt;kafka为什么要分区？&lt;/li&gt;
&lt;li&gt;Kafka生产者分区策略？&lt;/li&gt;
&lt;li&gt;kafka的数据可靠性怎么保证？(丢，重)&lt;/li&gt;
&lt;li&gt;kafka的副本机制？&lt;/li&gt;
&lt;li&gt;kafka的消费分区分配策略？&lt;/li&gt;
&lt;li&gt;kafka的offset怎么维护？&lt;/li&gt;
&lt;li&gt;kafka为什么这么快？(高效读写数据)&lt;/li&gt;
&lt;li&gt;Kafka消息数据积压，Kafka消费能力不足怎么处理？&lt;/li&gt;
&lt;li&gt;kafka事务是怎么实现的？&lt;/li&gt;
&lt;li&gt;Kafka中的数据是有序的吗？&lt;/li&gt;
&lt;li&gt;Kafka可以按照时间消费数据？&lt;/li&gt;
&lt;li&gt;Kafka单条日志传输大小？&lt;/li&gt;
&lt;li&gt;Kafka参数优化？&lt;/li&gt;
&lt;li&gt;Kafka适合以下应用场景？&lt;/li&gt;
&lt;li&gt;Exactly Once语义？在流式计算中怎么保持？&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="kafka" scheme="http://xubatian.cn/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>为什么要知道Hadoop机架感知？</title>
    <link href="http://xubatian.cn/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%9F%A5%E9%81%93Hadoop%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%9F/"/>
    <id>http://xubatian.cn/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%9F%A5%E9%81%93Hadoop%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%9F/</id>
    <published>2022-02-10T02:59:13.000Z</published>
    <updated>2022-02-10T06:41:07.957Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、首先，我为什么聊机架感知"><a href="#一、首先，我为什么聊机架感知" class="headerlink" title="一、首先，我为什么聊机架感知"></a><strong>一、首先，我为什么聊机架感知</strong></h4><p> 在了解hdfs<a href="https://cloud.tencent.com/product/clb?from=10680">负载均衡</a>时，需要获取DataNode情况，包括每个DataNode磁盘使用情况，获取到数据不均衡，就要做负载均衡处理。做负载均衡就要考虑热点数据发送到哪里去，集群服务器配置是否相同，机架使用情况等。</p><p> 机架感知在这里面有3个很重要的原因：</p><p>1、数据扩容，扩容的服务器在新机架上，导致数据不均衡</p><p>2、机架上的服务器磁盘配置不同（至于为什么，先不细聊）</p><p>通过感知机架，方便系统管理员手动操作，从而实现负载均衡</p><p>3、副本策略三副本，同节点、同机架、不同机架（同机房），可以实现保证有效存储时同时最大化安全策略</p><p>​                                                                                                                        </p><span id="more"></span><p><strong>机架图</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210110107.png"></p><h4 id="二、关于机架感知"><a href="#二、关于机架感知" class="headerlink" title="二、关于机架感知"></a><strong>二、关于机架感知</strong></h4><ol><li>Hadoop不能自动获取节点是否分布在多机架上</li><li>Hadoop大规模集群才会存在跨机架</li><li>不同节点之间通信尽量发生在同一个机架（可用性）</li><li>数据块副本策略会跨机架（容错性）</li></ol><h4 id="三、机架感知配置"><a href="#三、机架感知配置" class="headerlink" title="三、机架感知配置"></a><strong>三、机架感知配置</strong></h4><p>1、自定义类实现 DNSToSwitchMapping，重写 resolve() 方法；打为 jar 包，并复制到 NameNode 节点的 /soft/hadoop/shared/hadoop/common/lib 目录下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 机架感知类</span><br><span class="line"> */</span><br><span class="line">public class MyRackAware implements DNSToSwitchMapping &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 根据需求，将不同的主机划分到不同的机架上</span><br><span class="line">     * @param names 数据节点主机的集合</span><br><span class="line">     * @return 机架感知的集合</span><br><span class="line">     */</span><br><span class="line">    public List&lt;String&gt; resolve(List&lt;String&gt; names) &#123;</span><br><span class="line">        List&lt;String&gt; list = new ArrayList&lt;String&gt;();</span><br><span class="line">        try &#123;</span><br><span class="line">            //将原始信息输出到目录，方便查看</span><br><span class="line">            FileWriter fw = new FileWriter(&quot;/home/centos/rackaware.txt&quot;);</span><br><span class="line">            for (String host : names) &#123;</span><br><span class="line">                //将输入的原始host写入文件</span><br><span class="line">                fw.append(host+&quot;/r/n&quot;);</span><br><span class="line"> </span><br><span class="line">                //进行原始的host进行分机架</span><br><span class="line">                // IP形式</span><br><span class="line">                if (host.startsWith(&quot;192&quot;)) &#123;</span><br><span class="line">                    String ipEnd = host.substring(host.lastIndexOf(&quot;.&quot;) + 1);</span><br><span class="line">                    if (Integer.parseInt(ipEnd) &lt;= 103) &#123; //s102,s103 在一个机架</span><br><span class="line">                        list.add(&quot;/rack1/&quot; + ipEnd);</span><br><span class="line">                    &#125; else &#123;                              //s104 在一个机架</span><br><span class="line">                        list.add(&quot;/rack2/&quot; + ipEnd);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //主机名形式</span><br><span class="line">                else if (host.startsWith(&quot;s&quot;)) &#123;</span><br><span class="line">                    String ipEnd = host.substring(1);</span><br><span class="line">                    if (Integer.parseInt(ipEnd) &lt;= 103) &#123; //s102,s103 在一个机架</span><br><span class="line">                        list.add(&quot;/rack1/&quot; + ipEnd);</span><br><span class="line">                    &#125; else &#123;                              //s104 在一个机架</span><br><span class="line">                        list.add(&quot;/rack2/&quot; + ipEnd);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            fw.close();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        return list;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public void reloadCachedMappings() &#123;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public void reloadCachedMappings(List&lt;String&gt; names) &#123;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、配置core-site.xml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;net.topology.node.switch.mapping.impl&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.fresher.hdfs.rackaware.MyRackAware&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>3、重启集群</p><h4 id="四、机架感知（来自官网）"><a href="#四、机架感知（来自官网）" class="headerlink" title="四、机架感知（来自官网）"></a><strong>四、机架感知（来自官网）</strong></h4><p> Hadoop 组件是机架感知的。例如，HDFS 块放置将通过将一个块副本放置在不同的机架上来使用机架感知来实现容错。这在网络交换机故障或集群内分区的情况下提供数据可用性。</p><p> Hadoop 主守护进程通过调用配置文件指定的外部脚本或 java 类来获取集群工作线程的机架 ID。使用 java 类或外部脚本进行拓扑，输出必须遵循 java <strong>org.apache.hadoop.net.DNSToSwitchMapping</strong>接口。接口期望保持一一对应，拓扑信息格式为’/myrack/myhost’，其中’/‘为拓扑分隔符，’myrack’为机架标识，’myhost’为个人主机。假设每个机架有一个 /24 子网，可以使用“/192.168.100.0/192.168.100.5”格式作为唯一的机架-主机拓扑映射。</p><p> 要使用java 类进行拓扑映射，类名由配置文件中的<strong>net.topology.node.switch.mapping.impl</strong>参数指定。一个示例 NetworkTopology.java 包含在 hadoop 发行版中，可由 Hadoop 管理员自定义。使用 Java 类而不是外部脚本具有性能优势，因为当新的工作节点注册自己时，Hadoop 不需要分叉外部进程。</p><p> 如果实现外部脚本，它将在配置文件中使用<strong>net.topology.script.file.name</strong>参数指定。与 java 类不同，外部拓扑脚本不包含在 Hadoop 发行版中，而是由管理员提供。Hadoop 在 fork 拓扑脚本时会向 ARGV 发送多个 IP 地址。发送到拓扑脚本的 IP 地址数由<strong>net.topology.script.number.args</strong>控制，默认为 100。如果将<strong>net.topology.script.number.args</strong>更改为 1，则拓扑脚本将为每个由 DataNodes 和/或 NodeManagers 提交的 IP。</p><p> 如果<strong>net.topology.script.file.name</strong>或<strong>net.topology.node.switch.mapping.impl</strong>未设置，则为任何传递的 IP 地址返回机架 ID ‘/default-rack’。虽然这种行为看起来很可取，但它可能会导致 HDFS 块复制问题，因为默认行为是将一个复制块写到机架外，并且无法这样做，因为只有一个名为“/default-rack”的机架。</p><p><strong>python Example</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python3</span><br><span class="line"># this script makes assumptions about the physical environment.</span><br><span class="line">#  1) each rack is its own layer 3 network with a /24 subnet, which</span><br><span class="line"># could be typical where each rack has its own</span><br><span class="line">#     switch with uplinks to a central core router.</span><br><span class="line">#</span><br><span class="line">#             +-----------+</span><br><span class="line">#             |core router|</span><br><span class="line">#             +-----------+</span><br><span class="line">#            /             \</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   |rack switch|        |rack switch|</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   | data node |        | data node |</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   | data node |        | data node |</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#</span><br><span class="line"># 2) topology script gets list of IP&#x27;s as input, calculates network address, and prints &#x27;/network_address/ip&#x27;.</span><br><span class="line"></span><br><span class="line">import netaddr</span><br><span class="line">import sys</span><br><span class="line">sys.argv.pop(0)                                                  # discard name of topology script from argv list as we just want IP addresses</span><br><span class="line"></span><br><span class="line">netmask = &#x27;255.255.255.0&#x27;                                        # set netmask to what&#x27;s being used in your environment.  The example uses a /24</span><br><span class="line"></span><br><span class="line">for ip in sys.argv:                                              # loop over list of datanode IP&#x27;s</span><br><span class="line">    address = &#x27;&#123;0&#125;/&#123;1&#125;&#x27;.format(ip, netmask)                      # format address string so it looks like &#x27;ip/netmask&#x27; to make netaddr work</span><br><span class="line">    try:</span><br><span class="line">        network_address = netaddr.IPNetwork(address).network     # calculate and print network address</span><br><span class="line">        print(&quot;/&#123;0&#125;&quot;.format(network_address))</span><br><span class="line">    except:</span><br><span class="line">        print(&quot;/rack-unknown&quot;)                                   # print catch-all value if unable to calculate network address</span><br></pre></td></tr></table></figure><p><strong>bash Example</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line"># Here&#x27;s a bash example to show just how simple these scripts can be</span><br><span class="line"># Assuming we have flat network with everything on a single switch, we can fake a rack topology.</span><br><span class="line"># This could occur in a lab environment where we have limited nodes,like 2-8 physical machines on a unmanaged switch.</span><br><span class="line"># This may also apply to multiple virtual machines running on the same physical hardware.</span><br><span class="line"># The number of machines isn&#x27;t important, but that we are trying to fake a network topology when there isn&#x27;t one.</span><br><span class="line">#</span><br><span class="line">#       +----------+    +--------+</span><br><span class="line">#       |jobtracker|    |datanode|</span><br><span class="line">#       +----------+    +--------+</span><br><span class="line">#              \        /</span><br><span class="line">#  +--------+  +--------+  +--------+</span><br><span class="line">#  |datanode|--| switch |--|datanode|</span><br><span class="line">#  +--------+  +--------+  +--------+</span><br><span class="line">#              /        \</span><br><span class="line">#       +--------+    +--------+</span><br><span class="line">#       |datanode|    |namenode|</span><br><span class="line">#       +--------+    +--------+</span><br><span class="line">#</span><br><span class="line"># With this network topology, we are treating each host as a rack.  This is being done by taking the last octet</span><br><span class="line"># in the datanode&#x27;s IP and prepending it with the word &#x27;/rack-&#x27;.  The advantage for doing this is so HDFS</span><br><span class="line"># can create its &#x27;off-rack&#x27; block copy.</span><br><span class="line"># 1) &#x27;echo $@&#x27; will echo all ARGV values to xargs.</span><br><span class="line"># 2) &#x27;xargs&#x27; will enforce that we print a single argv value per line</span><br><span class="line"># 3) &#x27;awk&#x27; will split fields on dots and append the last field to the string &#x27;/rack-&#x27;. If awk</span><br><span class="line">#    fails to split on four dots, it will still print &#x27;/rack-&#x27; last field value</span><br><span class="line"></span><br><span class="line">echo $@ | xargs -n 1 | awk -F &#x27;.&#x27; &#x27;&#123;print &quot;/rack-&quot;$NF&#125;&#x27;</span><br></pre></td></tr></table></figure><h4 id="五、Hadoop集群网络拓扑描述"><a href="#五、Hadoop集群网络拓扑描述" class="headerlink" title="五、Hadoop集群网络拓扑描述"></a><strong>五、Hadoop集群网络拓扑描述</strong></h4><p>Hadoop集群架构通常包含两级网络拓扑，一般来说，各级机架装配30~40个服务器。</p><blockquote><p>一个机架配置一个交换机，一个交换机实际的连接能力取决于交换机的端口数量，交换机的端口数量最多是48个</p></blockquote><p>为了达到Hadoop的最佳性能，配置Hadoop系统以让其了解网络拓扑状况就极为关键。</p><p>如果集群只包含一个机架，无需做什么，就是默认配置。对于多机架的集群来说，描述清楚节点-机架的映射关系，使得Hadoop将MapReduce任务分配到各个节点时，会倾向于执行机架内的数据传输，而非跨机架数据传输。HDFS还能更加智能地防止副本，以uqde性能和弹性的平衡。</p><p>重点！！！</p><p>节点和机架等网络位置以树的形式来表示，从而能够体现出各个位置之间的网络距离。namenode使用网络位置来确定在哪里防止块的副本。MapReduce的调度器根据网络位置来查找最近的副本，将它作为map任务的输入。</p><blockquote><p>比如spark中提到的移动数据不如移动计算也是同理。又比如yarn任务提交流程中，启动多个task，在哪启动的，现在是不是很清楚了。</p></blockquote><p>综上，回头文章开头，为什么要做负载均衡，为什么要了解机架感知，数据和计算是互相影响的。</p><p>文章转载于”大数据最后一公里公众号”, 原址: <a href="https://cloud.tencent.com/developer/article/1856190">https://cloud.tencent.com/developer/article/1856190</a></p><p>知识源于积累,登峰造极源于自律.</p>]]></content>
    
    
    <summary type="html">&lt;h4 id=&quot;一、首先，我为什么聊机架感知&quot;&gt;&lt;a href=&quot;#一、首先，我为什么聊机架感知&quot; class=&quot;headerlink&quot; title=&quot;一、首先，我为什么聊机架感知&quot;&gt;&lt;/a&gt;&lt;strong&gt;一、首先，我为什么聊机架感知&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt; 在了解hdfs&lt;a href=&quot;https://cloud.tencent.com/product/clb?from=10680&quot;&gt;负载均衡&lt;/a&gt;时，需要获取DataNode情况，包括每个DataNode磁盘使用情况，获取到数据不均衡，就要做负载均衡处理。做负载均衡就要考虑热点数据发送到哪里去，集群服务器配置是否相同，机架使用情况等。&lt;/p&gt;
&lt;p&gt; 机架感知在这里面有3个很重要的原因：&lt;/p&gt;
&lt;p&gt;1、数据扩容，扩容的服务器在新机架上，导致数据不均衡&lt;/p&gt;
&lt;p&gt;2、机架上的服务器磁盘配置不同（至于为什么，先不细聊）&lt;/p&gt;
&lt;p&gt;通过感知机架，方便系统管理员手动操作，从而实现负载均衡&lt;/p&gt;
&lt;p&gt;3、副本策略三副本，同节点、同机架、不同机架（同机房），可以实现保证有效存储时同时最大化安全策略&lt;/p&gt;
&lt;p&gt;​                                                                                                                        &lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="hadoop" scheme="http://xubatian.cn/tags/hadoop/"/>
    
    <category term="机架感知" scheme="http://xubatian.cn/tags/%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5/"/>
    
  </entry>
  
  <entry>
    <title>Flink读取无界流数据计算过程演示</title>
    <link href="http://xubatian.cn/Flink%E8%AF%BB%E5%8F%96%E6%97%A0%E7%95%8C%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/"/>
    <id>http://xubatian.cn/Flink%E8%AF%BB%E5%8F%96%E6%97%A0%E7%95%8C%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/</id>
    <published>2022-02-10T02:07:21.000Z</published>
    <updated>2022-02-10T02:25:25.113Z</updated>
    
    <content type="html"><![CDATA[<p>Flink有界流式读取文本数据计算过程演示</p><span id="more"></span><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-10_10-12-09.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink有界流式读取文本数据计算过程演示&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink有界流式读取文本数据计算过程演示</title>
    <link href="http://xubatian.cn/Flink%E6%B5%81%E5%BC%8F%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/"/>
    <id>http://xubatian.cn/Flink%E6%B5%81%E5%BC%8F%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/</id>
    <published>2022-02-07T16:22:27.000Z</published>
    <updated>2022-02-10T02:17:20.844Z</updated>
    
    <content type="html"><![CDATA[<p>Flink流式读取文本数据计算过程演示. 文本数据总有一刻能读的完,所以他是有界的. 无界流读的是kafka的数据.</p><p>Flink是懒加载的,第一遍会检测整体代码.</p><p>并行度设置为1,就是单线程执行,所以Flink是一行一行读取文本数据的, 读一行计算一行. </p><p>sum算子是有状态的. 所以他的历史数据是保存在sum算子里面.sum算子做聚合计算的,他是一个有状态的算子.</p><p>批处理最终是输出一次,而流处理来一条计算一条.所以他保留了状态.方便后面来一条和前面对比进行计算.</p><span id="more"></span><p>源码地址: <a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.14.3-Demo/src/main/java/www/xubatian/cn/FlinkDemo01/Flink_WordCount_Bounded.java">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.14.3-Demo/src/main/java/www/xubatian/cn/FlinkDemo01/Flink_WordCount_Bounded.java</a></p><p>结果演示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210091224.png"></p><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-08_00-18-10.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink流式读取文本数据计算过程演示. 文本数据总有一刻能读的完,所以他是有界的. 无界流读的是kafka的数据.&lt;/p&gt;
&lt;p&gt;Flink是懒加载的,第一遍会检测整体代码.&lt;/p&gt;
&lt;p&gt;并行度设置为1,就是单线程执行,所以Flink是一行一行读取文本数据的, 读一行计算一行. &lt;/p&gt;
&lt;p&gt;sum算子是有状态的. 所以他的历史数据是保存在sum算子里面.sum算子做聚合计算的,他是一个有状态的算子.&lt;/p&gt;
&lt;p&gt;批处理最终是输出一次,而流处理来一条计算一条.所以他保留了状态.方便后面来一条和前面对比进行计算.&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Mybatis介绍之缓存</title>
    <link href="http://xubatian.cn/Mybatis%E4%BB%8B%E7%BB%8D%E4%B9%8B%E7%BC%93%E5%AD%98/"/>
    <id>http://xubatian.cn/Mybatis%E4%BB%8B%E7%BB%8D%E4%B9%8B%E7%BC%93%E5%AD%98/</id>
    <published>2022-02-07T14:25:10.000Z</published>
    <updated>2022-02-07T15:39:35.907Z</updated>
    
    <content type="html"><![CDATA[<p>Mybatis中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存1024条SQL。二级缓存是指可以跨SqlSession的缓存。 </p><p>​    Mybatis中进行SQL查询是通过org.apache.ibatis.executor.Executor接口进行的，总体来讲，它一共有两类实现，一类是BaseExecutor，一类是CachingExecutor。前者是非启用二级缓存时使用的，而后者是采用的装饰器模式，在启用了二级缓存时使用，当二级缓存没有命中时，底层还是通过BaseExecutor来实现的。</p> <span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207233751.png"></p><h1 id="Mybatis介绍之缓存"><a href="#Mybatis介绍之缓存" class="headerlink" title="Mybatis介绍之缓存"></a>Mybatis介绍之缓存</h1><h2 id="一级缓存"><a href="#一级缓存" class="headerlink" title="一级缓存"></a>一级缓存</h2><p> 一级缓存是默认启用的，在BaseExecutor的query()方法中实现，底层默认使用的是PerpetualCache实现，PerpetualCache采用HashMap存储数据。一级缓存会在进行增、删、改操作时进行清除。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ErrorContext.instance().resource(ms.getResource()).activity(<span class="string">&quot;executing a query&quot;</span>).object(ms.getId());</span><br><span class="line">    <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span> &amp;&amp; ms.isFlushCacheRequired()) &#123;</span><br><span class="line">      clearLocalCache();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;E&gt; list;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      queryStack++;</span><br><span class="line">      list = resultHandler == <span class="keyword">null</span> ? (List&lt;E&gt;) localCache.getObject(key) : <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      queryStack--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (DeferredLoad deferredLoad : deferredLoads) &#123;</span><br><span class="line">        deferredLoad.load();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// issue #601</span></span><br><span class="line">      deferredLoads.clear();</span><br><span class="line">      <span class="keyword">if</span> (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123;</span><br><span class="line">        <span class="comment">// issue #482</span></span><br><span class="line">        clearLocalCache();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> list;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>一级缓存的范围有SESSION和STATEMENT两种，默认是SESSION，如果我们不需要使用一级缓存，那么我们可以把一级缓存的范围指定为STATEMENT，这样每次执行完一个Mapper语句后都会将一级缓存清除。如果只是需要对某一条select语句禁用一级缓存，则可以在对应的select元素上加上flushCache=”true”。如果需要更改一级缓存的范围，请在Mybatis的配置文件中，在<settings>下通过localCacheScope指定。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;</span><br></pre></td></tr></table></figure><p>为了验证一级缓存，我们进行如下测试，在testCache1中，我们通过同一个SqlSession查询了两次一样的SQL，第二次不会发送SQL。在testCache2中，我们也是查询了两次一样的SQL，但是它们是不同的SqlSession，结果会发送两次SQL请求。需要注意的是当Mybatis整合Spring后，直接通过Spring注入Mapper的形式，如果不是在同一个事务中每个Mapper的每次查询操作都对应一个全新的SqlSession实例，这个时候就不会有一级缓存的命中，如有需要可以启用二级缓存。而在同一个事务中时共用的就是同一个SqlSession。这块有兴趣的朋友可以去查看MapperFactoryBean的源码，其父类SqlSessionDaoSupport在设置SqlSessionFactory或设置SqlSessionTemplate时的逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 默认是有一级缓存的，一级缓存只针对于使用同一个SqlSession的情况。&lt;br/&gt;</span></span><br><span class="line"><span class="comment">  * 注意：当使用Spring整合后的Mybatis，不在同一个事务中的Mapper接口对应的操作也是没有一级缓存的，因为它们是对应不同的SqlSession。在本示例中如需要下面的第二个语句可使用一级缓存，需要testCache()方法在一个事务中，使用<span class="doctag">@Transactional</span>标注。</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="meta">@Test</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCache</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    PersonMapper mapper = session.getMapper(PersonMapper.class);</span><br><span class="line">    mapper.findById(<span class="number">5L</span>);</span><br><span class="line">    mapper.findById(<span class="number">5L</span>);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="meta">@Test</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCache2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    SqlSession session1 = <span class="keyword">this</span>.sessionFactory.openSession();</span><br><span class="line">    SqlSession session2 = <span class="keyword">this</span>.sessionFactory.openSession();</span><br><span class="line">    session1.getMapper(PersonMapper.class).findById(<span class="number">5L</span>);</span><br><span class="line">    session2.getMapper(PersonMapper.class).findById(<span class="number">5L</span>);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="二级缓存"><a href="#二级缓存" class="headerlink" title="二级缓存"></a>二级缓存</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>二级缓存是默认启用的，如想取消，则可以通过Mybatis配置文件中的<settings>元素下的子元素<setting>来指定cacheEnabled为false。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;settings&gt;</span><br><span class="line">    &lt;setting name=<span class="string">&quot;cacheEnabled&quot;</span> value=<span class="string">&quot;false&quot;</span> /&gt;</span><br><span class="line"> &lt;/settings&gt;</span><br></pre></td></tr></table></figure><p>cacheEnabled默认是启用的，只有在该值为true的时候，底层使用的Executor才是支持二级缓存的CachingExecutor。具体可参考Mybatis的核心配置类org.apache.ibatis.session.Configuration的newExecutor方法实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Executor <span class="title">newExecutor</span><span class="params">(Transaction transaction, ExecutorType executorType)</span> </span>&#123;</span><br><span class="line">   executorType = executorType == <span class="keyword">null</span> ? defaultExecutorType : executorType;</span><br><span class="line">   executorType = executorType == <span class="keyword">null</span> ? ExecutorType.SIMPLE : executorType;</span><br><span class="line">   Executor executor;</span><br><span class="line">   <span class="keyword">if</span> (ExecutorType.BATCH == executorType) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> BatchExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ExecutorType.REUSE == executorType) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> ReuseExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> SimpleExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (cacheEnabled) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> CachingExecutor(executor);</span><br><span class="line">   &#125;</span><br><span class="line">   executor = (Executor) interceptorChain.pluginAll(executor);</span><br><span class="line">   <span class="keyword">return</span> executor;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>要使用二级缓存除了上面一个配置外，我们还需要在我们对应的Mapper.xml文件中定义需要使用的cache，具体可以参考CachingExecutor的以下实现，其中使用的cache就是我们在对应的Mapper.xml中定义的cache。还有一个条件就是需要当前的查询语句是配置了使用cache的，即下面源码的useCache()是返回true的，默认情况下所有select语句的useCache都是true，如果我们在启用了二级缓存后，有某个查询语句是我们不想缓存的，则可以通过指定其useCache为false来达到对应的效果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">  public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span><br><span class="line">      throws SQLException &#123;</span><br><span class="line">    Cache cache = ms.getCache();</span><br><span class="line">    if (cache != null) &#123;</span><br><span class="line">      flushCacheIfRequired(ms);</span><br><span class="line">      if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123;</span><br><span class="line">        ensureNoOutParams(ms, parameterObject, boundSql);</span><br><span class="line">        @SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">        List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key);</span><br><span class="line">        if (list == null) &#123;</span><br><span class="line">          list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">          tcm.putObject(cache, key, list); // issue #578 and #116</span><br><span class="line">        &#125;</span><br><span class="line">        return list;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="cache定义"><a href="#cache定义" class="headerlink" title="cache定义"></a>cache定义</h3><p> 刚刚说了我们要想使用二级缓存，是需要在对应的Mapper.xml文件中定义其中的查询语句需要使用哪个cache来缓存数据的。这有两种方式可以定义，一种是通过cache元素定义，一种是通过cache-ref元素来定义。但是需要注意的是对于同一个Mapper来讲，它只能使用一个Cache，当同时使用了<cache>和<cache-ref>时使用<cache>定义的优先级更高。Mapper使用的Cache是与我们的Mapper对应的namespace绑定的，一个namespace最多只会有一个Cache与其绑定。</p><h3 id="cache元素定义"><a href="#cache元素定义" class="headerlink" title="cache元素定义"></a>cache元素定义</h3><p> 使用cache元素来定义使用的Cache时，最简单的做法是直接在对应的Mapper.xml文件中指定一个空的<cache/>元素，这个时候Mybatis会按照默认配置创建一个Cache对象，准备的说是PerpetualCache对象，更准确的说是LruCache对象（底层用了装饰器模式）。具体可以参考XMLMapperBuilder中的cacheElement()方法中解析cache元素的逻辑。空cache元素定义会生成一个采用最近最少使用算法最多只能存储1024个元素的缓存，而且是可读写的缓存，即该缓存是全局共享的，任何一个线程在拿到缓存结果后对数据的修改都将影响其它线程获取的缓存结果，因为它们是共享的，同一个对象。</p><p>​     cache元素可指定如下属性，每种属性的指定都是针对都是针对底层Cache的一种装饰，采用的是装饰器的模式。</p><p>Ø <strong>blocking</strong>：默认为false，当指定为true时将采用BlockingCache进行封装，blocking，阻塞的意思，使用BlockingCache会在查询缓存时锁住对应的Key，如果缓存命中了则会释放对应的锁，否则会在查询数据库以后再释放锁，这样可以阻止并发情况下多个线程同时查询数据，详情可参考BlockingCache的源码。</p><p>Ø <strong>eviction</strong>：eviction，驱逐的意思。也就是元素驱逐算法，默认是LRU，对应的就是LruCache，其默认只保存1024个Key，超出时按照最近最少使用算法进行驱逐，详情请参考LruCache的源码。如果想使用自己的算法，则可以将该值指定为自己的驱逐算法实现类，只需要自己的类实现Mybatis的Cache接口即可。除了LRU以外，系统还提供了FIFO（先进先出，对应FifoCache）、SOFT（采用软引用存储Value，便于垃圾回收，对应SoftCache）和WEAK（采用弱引用存储Value，便于垃圾回收，对应WeakCache）这三种策略。</p><p>Ø <strong>flushInterval</strong>：清空缓存的时间间隔，单位是毫秒，默认是不会清空的。当指定了该值时会再用ScheduleCache包装一次，其会在每次对缓存进行操作时判断距离最近一次清空缓存的时间是否超过了flushInterval指定的时间，如果超出了，则清空当前的缓存，详情可参考ScheduleCache的实现。</p><p>Ø <strong>readOnly</strong>：是否只读，默认为false。当指定为false时，底层会用SerializedCache包装一次，其会在写缓存的时候将缓存对象进行序列化，然后在读缓存的时候进行反序列化，这样每次读到的都将是一个新的对象，即使你更改了读取到的结果，也不会影响原来缓存的对象，即非只读，你每次拿到这个缓存结果都可以进行修改，而不会影响原来的缓存结果；当指定为true时那就是每次获取的都是同一个引用，对其修改会影响后续的缓存数据获取，这种情况下是不建议对获取到的缓存结果进行更改，意为只读。这是Mybatis二级缓存读写和只读的定义，可能与我们通常情况下的只读和读写意义有点不同。每次都进行序列化和反序列化无疑会影响性能，但是这样的缓存结果更安全，不会被随意更改，具体可根据实际情况进行选择。详情可参考SerializedCache的源码。</p><p>Ø <strong>size</strong>：用来指定缓存中最多保存的Key的数量。其是针对LruCache而言的，LruCache默认只存储最多1024个Key，可通过该属性来改变默认值，当然，如果你通过eviction指定了自己的驱逐算法，同时自己的实现里面也有setSize方法，那么也可以通过cache的size属性给自定义的驱逐算法里面的size赋值。</p><p>Ø <strong>type</strong>：type属性用来指定当前底层缓存实现类，默认是PerpetualCache，如果我们想使用自定义的Cache，则可以通过该属性来指定，对应的值是我们自定义的Cache的全路径名称。</p><h3 id="cache-ref元素定义"><a href="#cache-ref元素定义" class="headerlink" title="cache-ref元素定义"></a>cache-ref元素定义</h3><p>cache-ref元素可以用来指定其它Mapper.xml中定义的Cache，有的时候可能我们多个不同的Mapper需要共享同一个缓存的，是希望在MapperA中缓存的内容在MapperB中可以直接命中的，这个时候我们就可以考虑使用cache-ref，这种场景只需要保证它们的缓存的Key是一致的即可命中，二级缓存的Key是通过Executor接口的createCacheKey()方法生成的，其实现基本都是BaseExecutor，源码如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CacheKey <span class="title">createCacheKey</span><span class="params">(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   CacheKey cacheKey = <span class="keyword">new</span> CacheKey();</span><br><span class="line">   cacheKey.update(ms.getId());</span><br><span class="line">   cacheKey.update(Integer.valueOf(rowBounds.getOffset()));</span><br><span class="line">   cacheKey.update(Integer.valueOf(rowBounds.getLimit()));</span><br><span class="line">   cacheKey.update(boundSql.getSql());</span><br><span class="line"></span><br><span class="line">   List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings();</span><br><span class="line"></span><br><span class="line">   TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry();</span><br><span class="line">   <span class="comment">// mimic DefaultParameterHandler logic</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parameterMappings.size(); i++) &#123;</span><br><span class="line">     ParameterMapping parameterMapping = parameterMappings.get(i);</span><br><span class="line">     <span class="keyword">if</span> (parameterMapping.getMode() != ParameterMode.OUT) &#123;</span><br><span class="line">       Object value;</span><br><span class="line">       String propertyName = parameterMapping.getProperty();</span><br><span class="line">       <span class="keyword">if</span> (boundSql.hasAdditionalParameter(propertyName)) &#123;</span><br><span class="line">         value = boundSql.getAdditionalParameter(propertyName);</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (parameterObject == <span class="keyword">null</span>) &#123;</span><br><span class="line">         value = <span class="keyword">null</span>;</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span>(typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123;</span><br><span class="line">         value = parameterObject;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         MetaObject metaObject = configuration.newMetaObject(parameterObject);</span><br><span class="line">         value = metaObject.getValue(propertyName);</span><br><span class="line">       &#125;</span><br><span class="line">       cacheKey.update(value);</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (configuration.getEnvironment() != <span class="keyword">null</span>) &#123;</span><br><span class="line">     <span class="comment">// issue #176</span></span><br><span class="line">     cacheKey.update(configuration.getEnvironment().getId());</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> cacheKey;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>打个比方我想在PersonMapper.xml中的查询都使用在UserMapper.xml中定义的Cache，则可以通过cache-ref元素的namespace属性指定需要引用的Cache所在的namespace，即UserMapper.xml中的定义的namespace，假设在UserMapper.xml中定义的namespace是com.elim.learn.mybatis.dao.UserMapper，则在PersonMapper.xml的cache-ref应该定义如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;cache-ref namespace=&quot;com.elim.learn.mybatis.dao.UserMapper&quot;/&gt;</span><br></pre></td></tr></table></figure><h3 id="自定义cache"><a href="#自定义cache" class="headerlink" title="自定义cache"></a>自定义cache</h3><p> 前面提到Mybatis的Cache默认会使用PerpetualCache存储数据，如果我们不想按照它的逻辑实现，或者我们想使用其它缓存框架来实现，比如使用Ehcache、Redis等，这个时候我们就可以使用自己的Cache实现，Mybatis是给我们留有对应的接口，允许我们进行自定义的。要想实现自定义的Cache我们必须定义一个自己的类来实现Mybatis提供的Cache接口，实现对应的接口方法。注意，自定义的Cache必须包含一个接收一个String参数的构造方法，这个参数就是Cache的ID，详情请参考Mybatis初始化Cache的过程，对应XMLMapperBuilder的cacheElement()方法。以下是一个简单的MyCache的实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">publicclass MyCache implements Cache &#123;</span><br><span class="line">   <span class="keyword">private</span> String id;</span><br><span class="line">   <span class="keyword">private</span> String name;<span class="comment">//Name，故意加这么一个属性，以方便演示给自定义Cache的属性设值</span></span><br><span class="line">   <span class="keyword">private</span> Map&lt;Object, Object&gt; cache = <span class="keyword">new</span> HashMap&lt;Object, Object&gt;();</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 构造方法。自定义的Cache实现一定要有一个id参数</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">MyCache</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.id = id;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.id;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putObject</span><span class="params">(Object key, Object value)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.cache.put(key, value);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Object <span class="title">getObject</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.get(key);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Object <span class="title">removeObject</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.remove(key);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.cache.clear();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.size();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> ReadWriteLock <span class="title">getReadWriteLock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> the name</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> name;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> name the name to set</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.name = name;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 定义了自己的Cache实现类后我们就可以在需要使用它的Mapper.xml文件中通过<cache>标签的type属性来指定我们需要使用的Cache。如果我们的自定义Cache是需要指定参数的，则可以通过<cache>标签的子标签<property>来指定对应的参数，Mybatis在解析的时候会调用指定属性对应的set方法。针对于上面的自定义Cache，我们的配置如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;cache type=&quot;com.elim.learn.mybatis.cache.MyCache&quot;&gt;</span><br><span class="line">      &lt;property name=&quot;name&quot; value=&quot;调用setName()方法需要传递的参数值&quot;/&gt;</span><br><span class="line">   &lt;/cache&gt;</span><br></pre></td></tr></table></figure><p>圆角矩形：注意：如果我们使用了自定义的Cache，那么cache标签的其它属性，如size、eviction等都不会对自定义的Cache起作用，也就是说不会自动对自定义的Cache进行包装，如果需要使用自定义的Cache，同时又希望使用Mybatis自带的那些Cache包装类，则可以在自定义的Cache中自己进行包装。</p><h3 id="缓存的清除"><a href="#缓存的清除" class="headerlink" title="缓存的清除"></a>缓存的清除</h3><p>二级缓存默认是会在执行update、insert和delete语句时进行清空的，具体可以参考CachingExecutor的update()实现。如果我们不希望在执行某一条更新语句时清空对应的二级缓存，那么我们可以在对应的语句上指定flushCache属性等于false。如果只是某一条select语句不希望使用二级缓存和一级缓存，则也可以在对应的select元素上加上flushCache=”true”。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;insert id=&quot;delete&quot; parameterType=&quot;java.lang.Long&quot;flushCache=&quot;false&quot;&gt;</span><br><span class="line">    delete t_person where id=#&#123;id&#125;</span><br><span class="line"> &lt;/insert&gt;</span><br></pre></td></tr></table></figure><h3 id="自己操作Cache"><a href="#自己操作Cache" class="headerlink" title="自己操作Cache"></a>自己操作Cache</h3><p>Mybatis中创建的二级缓存都会交给Configuration进行管理，Configuration类是Mybatis的核心类，里面包含了各种Mybatis资源的管理，其可以很方便的通过SqlSession、SqlSessionFactory获取，如有需要我们可以直接通过它来操作我们的Cache。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  @Test</span><br><span class="line">   public void testGetCache() &#123;</span><br><span class="line">      Configuration configuration = this.session.getConfiguration();</span><br><span class="line">//    this.sessionFactory.getConfiguration();</span><br><span class="line">      Collection&lt;Cache&gt; caches = configuration.getCaches();</span><br><span class="line">      System.out.println(caches);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>针对二级缓存进行了以下测试，获取两个不同的SqlSession执行两条相同的SQL，在未指定Cache时Mybatis将查询两次数据库，在指定了Cache时Mybatis只查询了一次数据库，第二次是从缓存中拿的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">  public void testCache2() &#123;</span><br><span class="line">     SqlSession session1 = this.sessionFactory.openSession();</span><br><span class="line">     SqlSession session2 = this.sessionFactory.openSession();</span><br><span class="line">     session1.getMapper(PersonMapper.class).findById(5L);</span><br><span class="line">     session1.commit();</span><br><span class="line">     session2.getMapper(PersonMapper.class).findById(5L);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p> 注意在上面的代码中，我在session1执行完对应的SQL后调用了session1的commit()方法，即提交了它的事务，这样我们在第二次查询的时候才会缓存命中，才不会查询数据库，否则就会连着查询两次数据库。这是因为在CachingExecutor中Mybatis在查询的过程中又在原来Cache的基础上包装了TransactionalCache，这个Cache只会在事务提交后才真正的写入缓存，所以在上面的示例中，如果session1执行完SQL后没有马上commit就紧接着用session2执行SQL，虽然session1查询时没有缓存命中，但是此时写入缓存操作还没有进行，session2再查询的时候也就不会缓存命中了。</p><p><strong>参考文档</strong></p><p><a href="http://www.mybatis.org/mybatis-3/zh/sqlmap-xml.html#cache">http://www.mybatis.org/mybatis-3/zh/sqlmap-xml.html#cache</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Mybatis中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存1024条SQL。二级缓存是指可以跨SqlSession的缓存。 &lt;/p&gt;
&lt;p&gt;​    Mybatis中进行SQL查询是通过org.apache.ibatis.executor.Executor接口进行的，总体来讲，它一共有两类实现，一类是BaseExecutor，一类是CachingExecutor。前者是非启用二级缓存时使用的，而后者是采用的装饰器模式，在启用了二级缓存时使用，当二级缓存没有命中时，底层还是通过BaseExecutor来实现的。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="http://xubatian.cn/categories/Java/"/>
    
    
    <category term="Java" scheme="http://xubatian.cn/tags/Java/"/>
    
    <category term="Mybatis" scheme="http://xubatian.cn/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款Mybatis分页插件</title>
    <link href="http://xubatian.cn/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BEMybatis%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6/"/>
    <id>http://xubatian.cn/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BEMybatis%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6/</id>
    <published>2022-02-07T13:52:43.000Z</published>
    <updated>2022-02-07T14:17:20.428Z</updated>
    
    <content type="html"><![CDATA[<p>介绍Mybatis的插件，以及如何通过Mybatis的插件功能实现一个自定义的分页插件。前段时间遇到了一款开源的Mybatis分页插件，叫<code>PageHelper</code>，github地址是 <a href="https://github.com/pagehelper/Mybatis-PageHelper">https://github.com/pagehelper/Mybatis-PageHelper</a>   其原理是通过<code>ThreadLocal</code>来存放分页信息，从而可以做到在Service层实现无侵入性的Mybatis分页。笔者感觉还不错，所以特意发博文记录一下，并推荐给大家。</p><span id="more"></span><h1 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h1><p>以下是使用<code>PageHelper</code>进行分页的一个简单的示例，更多详细的内容，请大家参数上面提供的<a href="https://github.com/pagehelper/Mybatis-PageHelper">github地址</a>。</p><h2 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h2><p>笔者使用的是Maven，添加依赖如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;pagehelper&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;4.1.6&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h2 id="注册Mybatis-Plugin"><a href="#注册Mybatis-Plugin" class="headerlink" title="注册Mybatis Plugin"></a>注册Mybatis Plugin</h2><p>跟其它Mybatis Plugin一样，我们需要在Mybatis的配置文件中注册需要使用的Plugin，<code>PageHelper</code>中对应的Plugin实现类就是<code>com.github.pagehelper.PageHelper</code>自身。顺便说一句，Mybatis的Plugin我们说是Plugin，实际上对应的却是<code>org.apache.ibatis.plugin.Interceptor</code>接口，因为<code>Interceptor</code>的核心是其中的<code>plugin(Object target)</code>方法，而对于<code>plugin(Object target)</code>方法的实现，我们在需要对对应的对象进行拦截时会通过<code>org.apache.ibatis.plugin.Plugin</code>的静态方法<code>wrap(Object target, Interceptor interceptor)</code>返回一个代理对象，而方法入参就是当前的<code>Interceptor</code>实现类。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugins&gt;  </span><br><span class="line">   &lt;plugin interceptor=&quot;com.github.pagehelper.PageHelper&quot;/&gt;  </span><br><span class="line">&lt;/plugins&gt;</span><br></pre></td></tr></table></figure><h2 id="使用PageHelper"><a href="#使用PageHelper" class="headerlink" title="使用PageHelper"></a>使用PageHelper</h2><p><code>PageHelper</code>拦截的是<code>org.apache.ibatis.executor.Executor</code>的<code>query</code>方法，其传参的核心原理是通过<code>ThreadLocal</code>进行的。当我们需要对某个查询进行分页查询时，我们可以在调用Mapper进行查询前调用一次<code>PageHelper.startPage(..)</code>，这样<code>PageHelper</code>会把分页信息存入一个<code>ThreadLocal</code>变量中。在拦截到<code>Executor</code>的<code>query</code>方法执行时会从对应的<code>ThreadLocal</code>中获取分页信息，获取到了，则进行分页处理，处理完了后又会把<code>ThreadLocal</code>中的分页信息清理掉，以便不影响下一次的查询操作。所以当我们使用了<code>PageHelper.startPage(..)</code>后，每次将对最近一次的查询进行分页查询，如果下一次查询还需要进行分页查询，需要重新进行一次<code>PageHelper.startPage(..)</code>。这样就做到了在引入了分页后可以对原来的查询代码没有任何的侵入性。此外，在进行分页查询时，我们的返回结果一般是一个<code>java.util.List</code>，<code>PageHelper</code>分页查询后的结果会变成<code>com.github.pagehelper.Page</code>类型，其继承了<code>java.util.ArrayList</code>，所以不会对我们的方法声明造成影响。<code>com.github.pagehelper.Page</code>中包含有返回结果的分页信息，包括总记录数，总的分页数等信息，所以一般我们需要把返回结果强转为<code>com.github.pagehelper.Page</code>类型。以下是一个简单的使用<code>PageHelper</code>进行分页查询的示例代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">public class PageHelperTest &#123;</span><br><span class="line"></span><br><span class="line">private static SqlSessionFactory sqlSessionFactory;</span><br><span class="line">private SqlSession session;</span><br><span class="line"></span><br><span class="line">@BeforeClass</span><br><span class="line">public static void beforeClass() throws IOException &#123;</span><br><span class="line">InputStream is = Resources.getResourceAsStream(&quot;mybatis-config-single.xml&quot;);</span><br><span class="line">sqlSessionFactory = new SqlSessionFactoryBuilder().build(is);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Before</span><br><span class="line">public void before() &#123;</span><br><span class="line">this.session = sqlSessionFactory.openSession();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@After</span><br><span class="line">public void after() &#123;</span><br><span class="line">this.session.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Test</span><br><span class="line">public void test() &#123;</span><br><span class="line">int pageNum = 2;//页码，从1开始</span><br><span class="line">int pageSize = 10;//每页记录数</span><br><span class="line">PageHelper.startPage(pageNum, pageSize);//指定开始分页</span><br><span class="line">UserMapper userMapper = this.session.getMapper(UserMapper.class);</span><br><span class="line">List&lt;User&gt; all = userMapper.findAll();</span><br><span class="line">Page&lt;User&gt; page = (Page&lt;User&gt;) all;</span><br><span class="line">System.out.println(page.getPages());</span><br><span class="line">System.out.println(page);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上是通过<code>PageHelper.startPage(..)</code>传递分页信息的示例，其实<code>PageHelper</code>还支持Mapper参数传递分页信息等其它用法。关于<code>PageHelper</code>的更多用法和配置信息等请参考该项目的GitHub<a href="https://github.com/pagehelper/Mybatis-PageHelper">官方文档</a>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍Mybatis的插件，以及如何通过Mybatis的插件功能实现一个自定义的分页插件。前段时间遇到了一款开源的Mybatis分页插件，叫&lt;code&gt;PageHelper&lt;/code&gt;，github地址是 &lt;a href=&quot;https://github.com/pagehelper/Mybatis-PageHelper&quot;&gt;https://github.com/pagehelper/Mybatis-PageHelper&lt;/a&gt;   其原理是通过&lt;code&gt;ThreadLocal&lt;/code&gt;来存放分页信息，从而可以做到在Service层实现无侵入性的Mybatis分页。笔者感觉还不错，所以特意发博文记录一下，并推荐给大家。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="http://xubatian.cn/categories/Java/"/>
    
    
    <category term="Java" scheme="http://xubatian.cn/tags/Java/"/>
    
    <category term="Mybatis" scheme="http://xubatian.cn/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>mybatis简介</title>
    <link href="http://xubatian.cn/mybatis%E7%AE%80%E4%BB%8B/"/>
    <id>http://xubatian.cn/mybatis%E7%AE%80%E4%BB%8B/</id>
    <published>2022-02-07T13:41:56.000Z</published>
    <updated>2022-02-07T13:51:26.032Z</updated>
    
    <content type="html"><![CDATA[<p>Mybatis框架简介</p><span id="more"></span><h1 id="MyBatis介绍"><a href="#MyBatis介绍" class="headerlink" title="MyBatis介绍"></a>MyBatis介绍</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>原是apache的一个开源项目iBatis，2010年6月这个项目由apache software foundation 迁移到了google code，随着开发团队转投Google Code旗下，ibatis3.x正式更名为Mybatis ，代码于2013年11月迁移到Github。<br>相对Hibernate和ApacheOJB等“一站式”ORM（Object Mapping）解决方案而言，ibatis 是一种“半自动化”的ORM实现。Relational<br>无论 Hibernate还是Apache OJB，都对数据库结构提供了较为完整的封装，提供了从POJO到数据库表的全套映射机制。程序员往往只需定义好了POJO 到数据库表的映射关系，即可通过 Hibernate或者OJB 提供的方法完成持久层操作。程序员甚至不需要对 SQL 的熟练掌握，Hibernate/OJB 会根据制定的存储逻辑，自动生成对应的 SQL 并调用 JDBC 接口加以执行。</p><h2 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a>官方文档</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207214544.png" alt="博客:www.xubatian.cn"></p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>1）支持自定义SQL、存储过程、及高级映射<br>2）实现自动对SQL的参数设置<br>3）实现自动对结果集进行解析和封装<br>4）通过XML或者注解进行配置和映射，大大减少代码量<br>5）数据源的连接信息通过配置文件进行配置</p><p>可以发现，MyBatis是对JDBC进行了简单的封装，帮助用户进行SQL参数的自动设置，以及结果集与Java对象的自动映射。与Hibernate相比，配置更加简单、灵活、执行效率高。但是正因为此，所以没有实现完全自动化，需要手写SQL，这是优点也是缺点。</p><p>因此，对性能要求较高的电商类项目，一般会使用MyBatis，而对与业务逻辑复杂，不太在乎执行效率的传统行业，一般会使用Hibernate</p><h2 id="Mybaits整体架构"><a href="#Mybaits整体架构" class="headerlink" title="Mybaits整体架构"></a>Mybaits整体架构</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207214710.png" alt="博客:www.xubatian.cn"></p><p>1、配置文件<br>全局配置文件：mybatis-config.xmlhibernate.cfg.xml，作用：配置数据源，引入映射文件<br>映射文件：XxMapper.xmlxx.hbm.xml，作用：配置sql语句、参数、结果集封装类型等</p><p>2、SqlSessionFactory<br>相当于Hibernate的SessionFactory，作用：获取SqlSession<br>通过newSqlSessionFactoryBuilder().build(inputStream)来构建，inputStream：读取配置文件的IO流</p><p>3、SqlSession<br>相当于Hibernate的Session，作用：执行CRUD操作</p><p>4、Executor<br>执行器，SqlSession通过调用它来完成具体的CRUD<br>它是一个接口，提供了两种实现：缓存的实现、数据库的实现</p><p>5、Mapped Statement<br>在映射文件里面配置，包含3部分内容：<br>具体的sql，sql执行所需的参数类型，sql执行结果的封装类型<br>参数类型和结果集封装类型包括3种：<br>HashMap，基本数据类型，pojo</p><p>…….未完待续</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Mybatis框架简介&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="http://xubatian.cn/categories/Java/"/>
    
    
    <category term="Java" scheme="http://xubatian.cn/tags/Java/"/>
    
    <category term="Mybatis" scheme="http://xubatian.cn/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>Flink使用idea将匿名内部类替换为lambda表达会擦除泛型</title>
    <link href="http://xubatian.cn/Flink%E4%BD%BF%E7%94%A8idea%E5%B0%86%E5%8C%BF%E5%90%8D%E5%86%85%E9%83%A8%E7%B1%BB%E6%9B%BF%E6%8D%A2%E4%B8%BAlambda%E8%A1%A8%E8%BE%BE%E4%BC%9A%E6%93%A6%E9%99%A4%E6%B3%9B%E5%9E%8B/"/>
    <id>http://xubatian.cn/Flink%E4%BD%BF%E7%94%A8idea%E5%B0%86%E5%8C%BF%E5%90%8D%E5%86%85%E9%83%A8%E7%B1%BB%E6%9B%BF%E6%8D%A2%E4%B8%BAlambda%E8%A1%A8%E8%BE%BE%E4%BC%9A%E6%93%A6%E9%99%A4%E6%B3%9B%E5%9E%8B/</id>
    <published>2022-02-07T06:12:57.000Z</published>
    <updated>2022-02-07T09:16:00.327Z</updated>
    
    <content type="html"><![CDATA[<p>Flink代码使用IDEA将new匿名内部类替换为lambda表达式运行会报错,因为替换后会擦除泛型</p><p>测试Flink1.12.0没有出现返回值类型报错问题. 不知道是否是Flink高版本结局了此问题还是idea高版本解决了此问题.</p><span id="more"></span><h2 id="源码地址-™"><a href="#源码地址-™" class="headerlink" title="源码地址:™"></a>源码地址:™</h2><p><a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo01/Flink_WordCount_Bounded.java">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo01/Flink_WordCount_Bounded.java</a></p><h2 id="报错类型示例"><a href="#报错类型示例" class="headerlink" title="报错类型示例"></a>报错类型示例</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207141902.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207141937.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207142024.png" alt="博客:www.xubatian.cn"></p><h2 id="返回值类型报错"><a href="#返回值类型报错" class="headerlink" title="返回值类型报错"></a>返回值类型报错</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207142213.png" alt="博客:www.xubatian.cn"></p><h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式:"></a>解决方式:</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207142525.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207144407.png" alt="博客:www.xubatian.cn"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink代码使用IDEA将new匿名内部类替换为lambda表达式运行会报错,因为替换后会擦除泛型&lt;/p&gt;
&lt;p&gt;测试Flink1.12.0没有出现返回值类型报错问题. 不知道是否是Flink高版本结局了此问题还是idea高版本解决了此问题.&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>2022年,二月,你好!</title>
    <link href="http://xubatian.cn/%E4%BA%8C%E6%9C%88-%E4%BD%A0%E5%A5%BD/"/>
    <id>http://xubatian.cn/%E4%BA%8C%E6%9C%88-%E4%BD%A0%E5%A5%BD/</id>
    <published>2022-01-31T23:30:30.000Z</published>
    <updated>2022-02-10T02:54:12.479Z</updated>
    
    <content type="html"><![CDATA[<p>二月了呀! 要加油了…..</p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210105354.png" alt="博客:www.xubatian.cn"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;二月了呀! 要加油了…..&lt;/p&gt;</summary>
    
    
    
    <category term="动态" scheme="http://xubatian.cn/categories/%E5%8A%A8%E6%80%81/"/>
    
    
    <category term="动态" scheme="http://xubatian.cn/tags/%E5%8A%A8%E6%80%81/"/>
    
  </entry>
  
</feed>
