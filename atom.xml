<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>我的梦想是星辰大海</title>
  
  <subtitle>知识源于积累,登峰造极源于自律</subtitle>
  <link href="http://xubatian.cn/atom.xml" rel="self"/>
  
  <link href="http://xubatian.cn/"/>
  <updated>2022-02-14T08:52:56.661Z</updated>
  <id>http://xubatian.cn/</id>
  
  <author>
    <name>xubatian</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink 原理与实现: Flink的状态编程和容错机制之状态一致性</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E7%9A%84%E7%8A%B6%E6%80%81%E7%BC%96%E7%A8%8B%E5%92%8C%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%E4%B9%8B%E7%8A%B6%E6%80%81%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E7%9A%84%E7%8A%B6%E6%80%81%E7%BC%96%E7%A8%8B%E5%92%8C%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%E4%B9%8B%E7%8A%B6%E6%80%81%E4%B8%80%E8%87%B4%E6%80%A7/</id>
    <published>2022-02-14T08:40:53.000Z</published>
    <updated>2022-02-14T08:52:56.661Z</updated>
    
    <content type="html"><![CDATA[<p>当在分布式系统中引入状态时，自然也会导致一系列的问题.如:</p><p>​    一致性问题.</p><p>什么叫一致性问题呢?</p><p><strong>就是不管你这个任务是失败了,还是中间出错了,还是暂停了,还是重复启动了.我要保证所有数据,不管在那种情况下发生,数据都是准确的或者说结果一定是准确的.这就叫所谓的状态一致.</strong></p><p>你要想保证结果准确,首先你就要保证的就是状态一致.所以状态一致就是为了保证最后结果的准确.</p><p>一致性的级别在我们Flink中分为三种.</p><span id="more"></span><h1 id="一致性-级别分为3种"><a href="#一致性-级别分为3种" class="headerlink" title="一致性(级别分为3种)"></a>一致性(级别分为3种)</h1><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164400.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164425.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164506.png"></p><h1 id="端到端（end-to-end）状态一致性"><a href="#端到端（end-to-end）状态一致性" class="headerlink" title="端到端（end-to-end）状态一致性"></a>端到端（end-to-end）状态一致性</h1><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164634.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164658.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164829.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164852.png"></p><p>如下图所示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164911.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214164935.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;当在分布式系统中引入状态时，自然也会导致一系列的问题.如:&lt;/p&gt;
&lt;p&gt;​    一致性问题.&lt;/p&gt;
&lt;p&gt;什么叫一致性问题呢?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;就是不管你这个任务是失败了,还是中间出错了,还是暂停了,还是重复启动了.我要保证所有数据,不管在那种情况下发生,数据都是准确的或者说结果一定是准确的.这就叫所谓的状态一致.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;你要想保证结果准确,首先你就要保证的就是状态一致.所以状态一致就是为了保证最后结果的准确.&lt;/p&gt;
&lt;p&gt;一致性的级别在我们Flink中分为三种.&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink的状态编程和容错机制之算子状态和键控状态</title>
    <link href="http://xubatian.cn/Flink%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0:%20Flink%E7%9A%84%E7%8A%B6%E6%80%81%E7%BC%96%E7%A8%8B%E5%92%8C%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%E4%B9%8B%E7%AE%97%E5%AD%90%E7%8A%B6%E6%80%81%E5%92%8C%E9%94%AE%E6%8E%A7%E7%8A%B6%E6%80%81/"/>
    <id>http://xubatian.cn/Flink%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0:%20Flink%E7%9A%84%E7%8A%B6%E6%80%81%E7%BC%96%E7%A8%8B%E5%92%8C%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%E4%B9%8B%E7%AE%97%E5%AD%90%E7%8A%B6%E6%80%81%E5%92%8C%E9%94%AE%E6%8E%A7%E7%8A%B6%E6%80%81/</id>
    <published>2022-02-14T08:08:20.000Z</published>
    <updated>2022-02-14T08:39:24.246Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Flink的状态编程概述"><a href="#Flink的状态编程概述" class="headerlink" title="Flink的状态编程概述"></a>Flink的状态编程概述</h1><p>​    在我们的Flink中,他默认就是有状态的.他和spark的一个本质的区别.有状态,但是他的状态是如何分布的呢?<br>​            <strong>状态分为两类: 算子状态(operator state)和键控状态(keyed state)</strong></p><p>​    算子状态: </p><p>​            是由Flink每一个子任务自己把任务运行过程中的一些业务或者逻辑或者数据,由自己来保存的或者说由自己来管理的,这样的状态称为算子状态.</p><p>​            所以算子状态的作用范围是限定为当前的算子任务的.</p><p>​            什么叫算子任务啊?</p><span id="more"></span><p>​            比如如下图:<img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214160955.png"></p><p>​            如图所示: sum()就是一个算子.这个算子里面在真正运行的过程中要看你这里写的并行度是多少.假设我这里定义的并行度setParallelism(2)是2.如图所示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214161028.png"></p><p>​        如图所示:图上这句话的意思就是表示,我的这个sum()算子他有两个子任务.因为他有两个并行度.所以他就有两个子任务.这意味着由同一并行任务所处理的所有数据都可以访问到相同的状态，<strong>状态对于同一任务而言是共享的。但是算子状态不能由相同或不同算子的另一个任务访问</strong>。这是什么意思呢?如下图所以:就以下图sum()为例,因为我们知道下图这个sum()一定是用到状态了.</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214161059.png"></p><p>​        如图所示: 如果我给这个sum()的并行度设置为2.就意味着这个sum()这个算子有两个subtask即子任务.他是这样子的: 就是他每一个subtask(子任务)都有各自所管理的算子状态.</p><p>​        就算你这两个subtask(子任务)都属于同一个算子.他也是不能够相互访问的.他是不能访问另外一个的.所以所谓的作用范围其实就是限定当前算子的子任务的.如下图所示:</p><p>​        <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214161121.png"></p><p>而我们这样的<strong>算子状态</strong>呢,他有三种基本数据的存储结构.这所说的是算子管理的这些状态有三个存储方式.</p><p>​        第一种是<strong>列表状态(List state)</strong>:就是说我们的算子状态中的数据是使用列表的方式.是存在一个列表里面的.把整个算子的所有数据以一组列表的方式存储起来.</p><p>​        第二种是<strong>联合列表状态(Union List State)</strong>:他也是以列表来存放算子状态的所有的数据.他和前面列表状态的区别是: 在发生故障时,或者从保存点启动应用程序去恢复数据的时候,他的运行代码不同.</p><p>​        第三种是<strong>广播状态(Broadcast state)</strong>:广播状态的意思就是说.我现在有一个算子.这个算子里面呢,他有一些数据或者说有一些逻辑,这个逻辑呢,其他的算子也是会用得到这个逻辑的.或者说这个数据,其他的算子也会用得到.那怎么办呢? 我们前面讲过,算子和算子之间的任务是不能共享的.这个时候呢,我们可以把这个状态存为一种广播状态,存为广播状态的话,这种情况下,他会把状态数据往其他的子任务上去发.这样的话,其他任务上也会有这个所谓的状态数据了.</p><p>​        不管怎么说,这个算子状态一般情况下是不能由程序员来控制的.(这个我们只需要知道就OK了). 而真正能由程序员控制的状态是键控状态(Keyed state),所谓键控状态(Keyed State)就是说我们这个状态只会依赖于数据中的键来进行维护和存储的.这种称之为键控状态.那我们马上就想到,我们sum()这个算子里面存的每一个单词,存的每一个单词里面的数据,实际上就是一种键控状态.如图所示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214161229.png"></p><p>​        因为他是根据数据流中定义的键来进行维护和管理的,那我们访问的时候也是根据键来进行访问.<strong>Flink为每一个键值维护一个状态实例,让你每次可以修改或者你可以根据键去访问</strong>,<strong>当然删除实际上也是可以删除,删除实际上我们调用一下clear()就可以了.这样的一个键控状态(Keyed state )的数据有点类似于一个分布式的键值对(keyed-value)的map数据结构</strong>.为什么叫分布式的呢?因为我们有很多并行度,每个并行度很有可能一直在多个不同的slot上运行.slot是一个线程.那么这个slot这个线程所在的JVM里面就会保存这个状态信息.保存这个键控状态(Keyed state)的值.键控状态的值是以键值对进行存储的. 你的键就是你数据中定义的那个键. <strong>你这个键在某一个JVM中存放了,他有可能还会在另外一个TaskManager的JVM上再存一个吗? 不会的</strong>.所以,其他的TaskManager上所存放的这些状态是可能有其他的键.那么对整个集群而言就是一个分布式的Key-Value数据结构.而且是惟一的Key.就算是分布式的也是一个唯一的Key.刚才我们已经说了,一个key他只会在某一台TaskManager上的JVM所管理的内存里面存放的.至于这个数据存放,后面会说.</p><p>​        当然,我们的Key-Value(键控状态)也是有所谓的数据结构的.它存储的数据结构呢有这么几种:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214161422.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214161438.png"></p><p>​            <strong>流式计算分为无状态和有状态两种情况</strong>。无状态的计算观察每个独立事件，并根据最后一个事件输出结果。例如，流处理应用程序从传感器接收温度读数，并在温度超过90度时发出警告。有状态的计算则会基于多个事件输出结果。以下是一些例子。</p><p>​            所有类型的窗口。例如，计算过去一小时的平均温度，就是有状态的计算。</p><p>​            所有用于复杂事件处理的状态机。例如，若在一分钟内收到两个相差20度以上的温度读数，则发出警告，这是有状态的计算。</p><p>​            流与流之间的所有关联操作，以及流与静态表或动态表之间的关联操作，都是有状态的计算。</p><p>​            下图展示了无状态流处理和有状态流处理的主要区别。无状态流处理分别接收每条数据记录(图中的黑条)，然后根据最新输入的数据生成输出数据(白条)。有状态流处理会维护状态(根据每条输入记录进行更新)，并基于最新输入的记录和当前的状态值生成输出记录(灰条)。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214161603.png"></p><p>上图中输入数据由黑条表示。无状 态流处理每次只转换一条输入记录，并且仅根据最新的输入记录输出结果(白条)。有状态 流处理维护所有已处理记录的状态值，并根据每条新输入的记录更新状态，因此输出记录(灰条)反映的是综合考虑多个事件之后的结果。</p><p>尽管无状态的计算很重要，但是流处理对有状态的计算更感兴趣。事实上，正确地实现有状态的计算比实现无状态的计算难得多。旧的流处理系统并不支持有状态的计算，而新一代的流处理系统则将状态及其正确性视为重中之重。</p><h1 id="有状态的算子和应用程序"><a href="#有状态的算子和应用程序" class="headerlink" title="有状态的算子和应用程序"></a>有状态的算子和应用程序</h1><p>​        Flink内置的很多算子，数据源source，数据存储sink都是有状态的，流中的数据都是buffer records，会保存一定的元素或者元数据。例如: ProcessWindowFunction会缓存输入流的数据，ProcessFunction会保存设置的定时器信息等等。</p><p>在Flink中，状态始终与特定算子相关联。总的来说，有两种类型的状态：</p><pre><code>     算子状态（operator state）     键控状态（keyed state）</code></pre><h2 id="算子状态（operator-state）"><a href="#算子状态（operator-state）" class="headerlink" title="算子状态（operator state）"></a>算子状态（operator state）</h2><p>​        算子状态的作用范围限定为算子任务。这意味着由同一并行任务所处理的所有数据都可以访问到相同的状态，状态对于同一任务而言是共享的。算子状态不能由相同或不同算子的另一个任务访问。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214161855.png"></p><h2 id="键控状态（keyed-state）"><a href="#键控状态（keyed-state）" class="headerlink" title="键控状态（keyed state）"></a>键控状态（keyed state）</h2><p>​        键控状态是根据输入数据流中定义的键（key）来维护和访问的。Flink为每个键值维护一个状态实例，并将具有相同键的所有数据，都分区到同一个算子任务中，这个任务会维护和处理这个key对应的状态。当任务处理一条数据时，它会自动将状态的访问范围限定为当前数据的key。因此，具有相同key的所有数据都会访问相同的状态。Keyed State很类似于一个分布式的key-value map数据结构，只能用于KeyedStream（keyBy算子处理之后）。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214162021.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214162040.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">val sensorData: DataStream[SensorReading] = ...</span><br><span class="line">val keyedData: KeyedStream[SensorReading, String] = sensorData.keyBy(_.id)</span><br><span class="line">val alerts: DataStream[(String, Double, Double)] = keyedData</span><br><span class="line">.flatMap(new TemperatureAlertFunction(1.7))</span><br><span class="line">class TemperatureAlertFunction(val threshold: Double) extends RichFlatMapFunction[SensorReading, (String, Double, Double)] &#123;</span><br><span class="line">//定义一个值状态</span><br><span class="line">private var lastTempState: ValueState[Double] = _</span><br><span class="line">override def open(parameters: Configuration): Unit = &#123;</span><br><span class="line">val lastTempDescriptor = new ValueStateDescriptor[Double](&quot;lastTemp&quot;, classOf[Double])</span><br><span class="line">lastTempState = getRuntimeContext.getState[Double](lastTempDescriptor)</span><br><span class="line">&#125;</span><br><span class="line">override def flatMap(reading: SensorReading,</span><br><span class="line">out: Collector[(String, Double, Double)]): Unit = &#123;</span><br><span class="line">val lastTemp = lastTempState.value()</span><br><span class="line">val tempDiff = (reading.temperature - lastTemp).abs</span><br><span class="line">if (tempDiff &gt; threshold) &#123;</span><br><span class="line">out.collect((reading.id, reading.temperature, tempDiff))</span><br><span class="line">&#125;</span><br><span class="line">this.lastTempState.update(reading.temperature)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过RuntimeContext注册StateDescriptor。StateDescriptor以状态state的名字和存储的数据类型为参数。</p><p>在open()方法中创建state变量。注意复习之前的RichFunction相关知识。</p><p>接下来我们使用了FlatMap with keyed ValueState的快捷方式flatMapWithState实现以上需求。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">val alerts: DataStream[(String, Double, Double)] = keyedSensorData</span><br><span class="line">  .flatMapWithState[(String, Double, Double), Double] &#123;</span><br><span class="line">    case (in: SensorReading, None) =&gt;</span><br><span class="line">      (List.empty, Some(in.temperature))</span><br><span class="line">    case (r: SensorReading, lastTemp: Some[Double]) =&gt;</span><br><span class="line">      val tempDiff = (r.temperature - lastTemp.get).abs</span><br><span class="line">      if (tempDiff &gt; 1.7) &#123;</span><br><span class="line">        (List((r.id, r.temperature, tempDiff)), Some(r.temperature))</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        (List.empty, Some(r.temperature))</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Flink的状态编程概述&quot;&gt;&lt;a href=&quot;#Flink的状态编程概述&quot; class=&quot;headerlink&quot; title=&quot;Flink的状态编程概述&quot;&gt;&lt;/a&gt;Flink的状态编程概述&lt;/h1&gt;&lt;p&gt;​    在我们的Flink中,他默认就是有状态的.他和spark的一个本质的区别.有状态,但是他的状态是如何分布的呢?&lt;br&gt;​            &lt;strong&gt;状态分为两类: 算子状态(operator state)和键控状态(keyed state)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    算子状态: &lt;/p&gt;
&lt;p&gt;​            是由Flink每一个子任务自己把任务运行过程中的一些业务或者逻辑或者数据,由自己来保存的或者说由自己来管理的,这样的状态称为算子状态.&lt;/p&gt;
&lt;p&gt;​            所以算子状态的作用范围是限定为当前的算子任务的.&lt;/p&gt;
&lt;p&gt;​            什么叫算子任务啊?&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink的ProcessFunction API（底层API）</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E7%9A%84ProcessFunction-API%EF%BC%88%E5%BA%95%E5%B1%82API%EF%BC%89/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E7%9A%84ProcessFunction-API%EF%BC%88%E5%BA%95%E5%B1%82API%EF%BC%89/</id>
    <published>2022-02-14T07:44:22.000Z</published>
    <updated>2022-02-14T08:05:53.264Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Flink底层API概述"><a href="#Flink底层API概述" class="headerlink" title="Flink底层API概述"></a>Flink底层API概述</h1><p>ProcessFunction API是属于Flink三层API中最底层的一层API.最底层的API意味着什么呢?</p><p>​        顾名思义就是我们可以做任何你想要做的任何事情.你可以理解为底层的API我们想要处理一些细腻化的操作,或者要处理一些特殊的业务.我如果使用高级的API ,DataStream API已经搞定不了的情况下.最后呢,我们就可以是用ProcessFunction API. ProcessFunction API是属于我们Flink里面最底层的转换算子.在这个最底层的转换算子中.我们可以有很多的工作可以做.或者有很多的功能可以完成.可以访问时间戳.那我们访问的时间戳是什么时间戳呢?是处理的时间戳.也可以是当前进来的那条数据的时间戳.那么当前进来的时间戳和处理的时间戳我们不是可以使用system.currenttimemillis()吗?但是这个时候我们使用这个是不准确的.<strong>你要想访问准确的时间的话.我们就可以使用底层的API.他就给我们提供了一个方法.我们可以访问watermark,还可以查看当前的水位线.水位线实际上是这样的,就是他每个两百毫秒调用一次.是需要更新这个水位线的.因为水位线有两种.</strong></p><p>一种是周期性的水位线.<br>还有一种是间断性的水位线.</p><p>周期性的水位线就是说我每隔多长时间来更新一下或者设置一下这个新的水位线.就是这个意思.那么当前<strong>最新的水位线是多少我们都可以通过在底层API中去拿到</strong>.甚至我们还可以<strong>注册定时的事件.</strong></p><p>什么叫注册定时的事件呢?</p><p>​    比如说:我们到达某一个条件之后我想触发一个事件.触发一个新的事件.这个事件我规定你在三秒钟之后你给我执行.那么在三秒钟还没到的时候我就有必要把这个事件注册一下.注册之后,从现在开始到三秒钟之后他会自动触发.所以你可以理解为定义,我们定义一个马上过一段时间要触发的一个事件.</p><p>​        还可以输出一个特定的一些事件.比如说超时的一些事件.什么意思呢?比如说我们现在正在处理数据.假设处理数据的时候我们发现可能某一个条件还没成熟.那么没关系,我们可以在几秒钟之后设置一个超时时间.在几秒钟之后我们再进行处理.这就是所谓的超时时间.</p><p><strong>实际上几秒钟之后再处理的话,也是需要注册一个定时事件的</strong>.因为你要注册一个处理的时间,多长时间之后再进行处理.这些都是原来我们的API所无法做到的.那我们就可以通过ProcessFunction API这个底层的API来进行处理.</p><span id="more"></span><p><strong>Flink给我们提供了8中ProcessFunction API.</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214154851.png"></p><p>这些窗口函数说白了就是一个个的对象,看着像函数,实际上他是对象.或者说就是一个类.那我们要用的话是声明一个匿名方法吗?不是的,是声明一个匿名函数吗?不是的.而是你需要写一个类去继承这8个ProcessFunction.他是我们真正的窗口函数类.如果你要把前面的知识点串联起来的话.</p><p>Flink里面我们提供了三种函数类</p><p>匿名函数不好</p><p>一个是普通的函数类.</p><p>第二个是富函数类.</p><p>第三个是底层处理的函数类.</p><p>所以我们有三种函数类.这块儿函数类有一个特点,他不是说你要声明写一个匿名函数就可以了.而是你必须要写一个类去继承他.</p><p>这里最常用的是ProcessFunction和KeyedProcessFunction.</p><p>下面以KeyedProcessFunction举例子.</p><p>​        我们之前学习的转换算子是无法访问事件的时间戳信息和水位线信息的。而这在一些应用场景下，极为重要。例如MapFunction这样的map转换算子就无法访问时间戳或者当前事件的事件时间。<br>​        基于此，DataStream API提供了一系列的Low-Level(底层的)转换算子。可以访问时间戳、watermark以及注册定时事件。还可以输出特定的一些事件，例如超时事件等。Process Function用来构建事件驱动的应用以及实现自定义的业务逻辑(使用之前的window函数和转换算子无法实现)。例如，Flink SQL就是使用Process Function实现的。<br>Flink提供了8个Process Function：<br>ProcessFunction<br>KeyedProcessFunction<br>CoProcessFunction<br>ProcessJoinFunction<br>BroadcastProcessFunction<br>KeyedBroadcastProcessFunction<br>ProcessWindowFunction<br>ProcessAllWindowFunction</p><h1 id="KeyedProcessFunction"><a href="#KeyedProcessFunction" class="headerlink" title="KeyedProcessFunction"></a>KeyedProcessFunction</h1><p><strong>这里以KeyedProcessFunction举例,因为他用的最多.上面的这8个ProcessFunction API即底层API,都是按照下面连个案例去操作的.</strong></p><p>​        以下例子说明,就是你可以通过这个Process Function中,拿到你想要拿到的任何东西,包括你对侧输出流的管理,包括你对当前的运行时间还有当前的watermark,当前的TimerService(时间服务),TimerService里面又可以注册一个触发器,并且还可以删除一个触发器.总之一句话,就是底层的ProcessFunction提供了所有你想要拿到的东西.都可以在底层的ProcessFunction API里面拿</p><p>​        KeyedProcessFunction是专门用来操作KeyedStream的.只会操作KeyedStream.</p><p>​        KeyedProcessFunction他会处理我们流的每一个元素.可以输出多个元素.也可以输出0个,也可以输出1个.这个我们之前说的DataStream API里面的处理函数或者转换函数不一样的.比如我们在DataStream中说的FlatMap这个处理函数(注意:处理函数就是所谓的转换函数),这里FlatMap他是把一条数据变成n条数据,即把一个元素转换成多个元素.还有一个,比如说map算子,map算子就是把一条数据通过map输出一条数据.我们可不可以用map算子来把一条数输出0条数据呢?(0个元素就代表不输出的意思.) 请问可以这样做吗?不可以的.那为什么我们后面不能输出null呢?输出null不就是代表不输出了呢?因为null也是等于0的呀!因为我们的map是要申明类型的,一个输入类型,一个输出类型.那我们写代码的时候输出一个null不就行了嘛?你什么代码也不写,这是不行的,因为这个代码是必须有返回值的.你这个方法声明的返回值你却没有返回任何东西的话,你的语法就通不过,然后他的编译也通不过.那什么都不输出的话编译不通过,那我就输出个null不行吗?不行,输出null的话,在执行过程中是会报错的.为什么?因为他要把输出的数据还要反序列化一下.在我们Flink中,流的处理,尤其在后面写到Sink里面他要进行序列化的.也就是说,他会造成后面的算子报错的现象.可能你这个map算子不会报错,但是会造成后面的算子报错.因为后面的算子他要反序列化你这个map算子输出的对象.那这个时候因为你为null,那他就会报一个空指针异常的错误.所以说,他做不到.</p><p>​        但是我们当前的底层API即KeyedProcessFunction这个底层API他就可以做到,他可以不输出.因为它里面的方法是没有返回值的.他既然没有返回值,我不输出,我不写代码就可以了.他可以输出1个元素也可以输出0个元素.他是非常灵活的.这就是所谓的底层API.当然,灵活归灵活,只不过代码写的稍微多一点.以前是调一个函数就ok了.现在我们用底层API我们还得写一个类.去继承这个父类.然后重写父类的所有抽象方法.而且我们所有的ProcessFunction都继承自RichFunction接口.RichFunction接口的特点是,有生命周期的管理.你可以知道我们这个subtask,就是我们这算子所对应的subtask在什么时候初始化,什么时候关闭.什么时候初始化的回调方法就是Open()方法.什么时候关闭的回调方法就是close()方法.这就是所谓的声明周期.还可以的到当前运行的上下文环境getRuntimeContext().这个上下文环境以后是要用的.为什么呢?因为我们前面说,我们的底层API可以访问时间,可以访问watermark(水位线),可以注册事件.那么可以通过谁来注册事件呢?就是通过我们运行时的上下环境,就是getRuntimeContext()来进行注册事件.</p><p>​        归纳总结: 我们整个Flink学了三种函数类.普通的函数类.富函数类和底层处理的函数类.那我们是不是可以认为底层处理的函数类可以做前面两种所有能做的事情.除此之外,我们的底层处理的函数还能做额外的一些事情,比如说注册新的事件,访问时间戳等等.或者说底层处理的函数类,就是我们所谓的写代码过程中发现一个业务数据做不到的我们就可以放大招了,使用我们底层处理的函数类来完成我们想要的需求.那如果底层处理的函数类都搞定不了的话,那就是我们技术选型有问题了.我们就不该选用Flink了.</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214155410.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214155648.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214160025.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214160123.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214160218.png"></p><h1 id="时间服务-TimerService-和-定时器（Timers）"><a href="#时间服务-TimerService-和-定时器（Timers）" class="headerlink" title="时间服务 (TimerService )和 定时器（Timers）"></a>时间服务 (TimerService )和 定时器（Timers）</h1><p>Context和OnTimerContext所持有的TimerService对象拥有以下方法:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214160312.png"></p><p>当定时器timer触发时，会执行回调函数onTimer()。注意定时器timer只能在keyed streams上面使用。</p><p>下面举个例子说明KeyedProcessFunction如何操作KeyedStream。</p><p>需求：监控温度传感器的温度值，如果温度值在一秒钟之内(processing time)连续上升，则报警。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val warnings = readings</span><br><span class="line">.keyBy(_.id)</span><br><span class="line">.process(new TempIncreaseAlertFunction)</span><br></pre></td></tr></table></figure><p>看一下TempIncreaseAlertFunction如何实现, 程序中使用了ValueState这样一个状态变量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">class TempIncreaseAlertFunction extends KeyedProcessFunction[String, SensorReading, String] &#123;</span><br><span class="line">  // 保存上一个传感器温度值</span><br><span class="line">  lazy val lastTemp: ValueState[Double] = getRuntimeContext.getState(</span><br><span class="line">    new ValueStateDescriptor[Double](&quot;lastTemp&quot;, Types.of[Double])</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  // 保存注册的定时器的时间戳</span><br><span class="line">  lazy val currentTimer: ValueState[Long] = getRuntimeContext.getState(</span><br><span class="line">    new ValueStateDescriptor[Long](&quot;timer&quot;, Types.of[Long])</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  override def processElement(r: SensorReading,</span><br><span class="line">                          ctx: KeyedProcessFunction[String, SensorReading, String]#Context,</span><br><span class="line">                          out: Collector[String]): Unit = &#123;</span><br><span class="line">    // 取出上一次的温度</span><br><span class="line">    val prevTemp = lastTemp.value()</span><br><span class="line">    // 将当前温度更新到上一次的温度这个变量中</span><br><span class="line">    lastTemp.update(r.temperature)</span><br><span class="line"></span><br><span class="line">    val curTimerTimestamp = currentTimer.value()</span><br><span class="line">    if (prevTemp == 0.0 || r.temperature &lt; prevTemp) &#123;</span><br><span class="line">      // 温度下降或者是第一个温度值，删除定时器</span><br><span class="line">      ctx.timerService().deleteProcessingTimeTimer(curTimerTimestamp)</span><br><span class="line">      // 清空状态变量</span><br><span class="line">      currentTimer.clear()</span><br><span class="line">    &#125; else if (r.temperature &gt; prevTemp &amp;&amp; curTimerTimestamp == 0) &#123;</span><br><span class="line">      // 温度上升且我们并没有设置定时器</span><br><span class="line">      val timerTs = ctx.timerService().currentProcessingTime() + 1000</span><br><span class="line">      ctx.timerService().registerProcessingTimeTimer(timerTs)</span><br><span class="line"></span><br><span class="line">      currentTimer.update(timerTs)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def onTimer(ts: Long,</span><br><span class="line">                    ctx: KeyedProcessFunction[String, SensorReading, String]#OnTimerContext,</span><br><span class="line">                    out: Collector[String]): Unit = &#123;</span><br><span class="line">    out.collect(&quot;传感器id为: &quot; + ctx.getCurrentKey + &quot;的传感器温度值已经连续1s上升了。&quot;)</span><br><span class="line">    currentTimer.clear()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="侧输出流（SideOutput）【注意：测输出流是用来替代Split算子的。Split算子已经过时了。】"><a href="#侧输出流（SideOutput）【注意：测输出流是用来替代Split算子的。Split算子已经过时了。】" class="headerlink" title="侧输出流（SideOutput）【注意：测输出流是用来替代Split算子的。Split算子已经过时了。】"></a>侧输出流（SideOutput）【注意：测输出流是用来替代Split算子的。Split算子已经过时了。】</h1><p>​        侧输出流是用来替代Split算子的,split算子实际上已经过时了.侧输出流的意思就是说,我们把一条流分成多个流.这个侧输出流可以这样子的.就是一条主流两个测流.或者一条主流,三个测流.这就根据你自己的意思来决定.但是有一个特点就是你的类型必须相同.那么,如果你输出侧输出流的话.你必须需要用到我们的底层,也需要用到底层的function才行的.所以这个侧输出流他也是属于我们的ProcessFunction API里面的.就是底层API里面的.<br>​        由于我们可以输出多条测流,那么每一个测流呢,我们可以定义一个OutputTag[X]对象来区分.其中的X就是他每条测流里面的每个元素的类型.所以需要在前面就得定义一个OutputTag[X].有多少个侧输出流,你就需要定义多少个OutputTag[X].实际上你可以理解为就是我当前测流的一个标记.或者我当前测流的一个标签.到时候你去拿我这个测流的时候,你也是根据这个标签去拿.</p><p>​        大部分的DataStream API的算子的输出是单一输出，也就是某种数据类型的流。除了split算子，可以将一条流分成多条流，这些流的数据类型也都相同。process function的side outputs功能可以产生多条流，并且这些流的数据类型可以不一样。一个side output可以定义为OutputTag[X]对象，X是输出流的数据类型。process function可以通过Context对象发射一个事件到一个或者多个side outputs。</p><p>下面是一个示例程序:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">val monitoredReadings: DataStream[SensorReading] = readings</span><br><span class="line">  .process(new FreezingMonitor)</span><br><span class="line"></span><br><span class="line">monitoredReadings</span><br><span class="line">  .getSideOutput(new OutputTag[String](&quot;freezing-alarms&quot;))</span><br><span class="line">  .print()</span><br><span class="line"></span><br><span class="line">readings.print()</span><br></pre></td></tr></table></figure><p>接下来我们实现FreezingMonitor函数，用来监控传感器温度值，将温度值低于32F的温度输出到side output。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class FreezingMonitor extends ProcessFunction[SensorReading, SensorReading] &#123;</span><br><span class="line">  // 定义一个侧输出标签</span><br><span class="line">  lazy val freezingAlarmOutput: OutputTag[String] =</span><br><span class="line">    new OutputTag[String](&quot;freezing-alarms&quot;)</span><br><span class="line"></span><br><span class="line">  override def processElement(r: SensorReading,</span><br><span class="line">                              ctx: ProcessFunction[SensorReading, SensorReading]#Context,</span><br><span class="line">                              out: Collector[SensorReading]): Unit = &#123;</span><br><span class="line">    // 温度在32F以下时，输出警告信息</span><br><span class="line">    if (r.temperature &lt; 32.0) &#123;</span><br><span class="line">      ctx.output(freezingAlarmOutput, s&quot;Freezing Alarm for $&#123;r.id&#125;&quot;)</span><br><span class="line">    &#125;</span><br><span class="line">    // 所有数据直接常规输出到主流</span><br><span class="line">    out.collect(r)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="CoProcessFunction-这是将两条流汇成一个流的"><a href="#CoProcessFunction-这是将两条流汇成一个流的" class="headerlink" title="CoProcessFunction(这是将两条流汇成一个流的)"></a>CoProcessFunction(这是将两条流汇成一个流的)</h1><p>CoProcessFunction,这个是将两个流汇成一个流的.CoProcessFunction和我们之前讲的两个底层的函数不一样.它里面有两个需要实现的方法.如果你需要把两条流汇成一个流的话.你就要分别处理,所以要<strong>重写CoProcessFunction里面的两个方法:ProcessElement1()和ProcessElement2().那如果我想要将他汇成一个流的话,我只需要在这两个方法中用同样的代码去删除就可以了.</strong></p><p>对于两条输入流，DataStream API提供了CoProcessFunction这样的low-level操作。CoProcessFunction提供了操作每一个输入流的方法: processElement1()和processElement2()。</p><p>类似于ProcessFunction，这两种方法都通过Context对象来调用。这个Context对象可以访问事件数据，定时器时间戳，TimerService，以及side outputs。CoProcessFunction也提供了onTimer()回调函数。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Flink底层API概述&quot;&gt;&lt;a href=&quot;#Flink底层API概述&quot; class=&quot;headerlink&quot; title=&quot;Flink底层API概述&quot;&gt;&lt;/a&gt;Flink底层API概述&lt;/h1&gt;&lt;p&gt;ProcessFunction API是属于Flink三层API中最底层的一层API.最底层的API意味着什么呢?&lt;/p&gt;
&lt;p&gt;​        顾名思义就是我们可以做任何你想要做的任何事情.你可以理解为底层的API我们想要处理一些细腻化的操作,或者要处理一些特殊的业务.我如果使用高级的API ,DataStream API已经搞定不了的情况下.最后呢,我们就可以是用ProcessFunction API. ProcessFunction API是属于我们Flink里面最底层的转换算子.在这个最底层的转换算子中.我们可以有很多的工作可以做.或者有很多的功能可以完成.可以访问时间戳.那我们访问的时间戳是什么时间戳呢?是处理的时间戳.也可以是当前进来的那条数据的时间戳.那么当前进来的时间戳和处理的时间戳我们不是可以使用system.currenttimemillis()吗?但是这个时候我们使用这个是不准确的.&lt;strong&gt;你要想访问准确的时间的话.我们就可以使用底层的API.他就给我们提供了一个方法.我们可以访问watermark,还可以查看当前的水位线.水位线实际上是这样的,就是他每个两百毫秒调用一次.是需要更新这个水位线的.因为水位线有两种.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一种是周期性的水位线.&lt;br&gt;还有一种是间断性的水位线.&lt;/p&gt;
&lt;p&gt;周期性的水位线就是说我每隔多长时间来更新一下或者设置一下这个新的水位线.就是这个意思.那么当前&lt;strong&gt;最新的水位线是多少我们都可以通过在底层API中去拿到&lt;/strong&gt;.甚至我们还可以&lt;strong&gt;注册定时的事件.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;什么叫注册定时的事件呢?&lt;/p&gt;
&lt;p&gt;​    比如说:我们到达某一个条件之后我想触发一个事件.触发一个新的事件.这个事件我规定你在三秒钟之后你给我执行.那么在三秒钟还没到的时候我就有必要把这个事件注册一下.注册之后,从现在开始到三秒钟之后他会自动触发.所以你可以理解为定义,我们定义一个马上过一段时间要触发的一个事件.&lt;/p&gt;
&lt;p&gt;​        还可以输出一个特定的一些事件.比如说超时的一些事件.什么意思呢?比如说我们现在正在处理数据.假设处理数据的时候我们发现可能某一个条件还没成熟.那么没关系,我们可以在几秒钟之后设置一个超时时间.在几秒钟之后我们再进行处理.这就是所谓的超时时间.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际上几秒钟之后再处理的话,也是需要注册一个定时事件的&lt;/strong&gt;.因为你要注册一个处理的时间,多长时间之后再进行处理.这些都是原来我们的API所无法做到的.那我们就可以通过ProcessFunction API这个底层的API来进行处理.&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink 的时间语义与Wartermark(水位线)机制</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink-%E7%9A%84%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E4%B8%8EWartermark-%E6%B0%B4%E4%BD%8D%E7%BA%BF-%E6%9C%BA%E5%88%B6/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink-%E7%9A%84%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E4%B8%8EWartermark-%E6%B0%B4%E4%BD%8D%E7%BA%BF-%E6%9C%BA%E5%88%B6/</id>
    <published>2022-02-14T07:05:57.000Z</published>
    <updated>2022-02-14T07:33:17.678Z</updated>
    
    <content type="html"><![CDATA[<h1 id="时间语义与Wartermark-水位线-阐述"><a href="#时间语义与Wartermark-水位线-阐述" class="headerlink" title="时间语义与Wartermark(水位线)阐述:"></a>时间语义与Wartermark(水位线)阐述:</h1><p>用到了时间语义和watermark,所以Flink和sparkStreaming是有一定的区别的.</p><p><strong>Flink中的时间语义有三种:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Event Time(事件触发的时间或者是事件创建的时间),</span><br><span class="line"></span><br><span class="line">Ingestion Time(进入Flink的时间),</span><br><span class="line"></span><br><span class="line">Processing Time(Flink在处理这条数据的时间),</span><br></pre></td></tr></table></figure><span id="more"></span>        <p>​        在生产环境中,大多数我们都关心Event Time,我们可能会把Event Time来作为我们开窗的时间参数.就是说我们任何一个开窗都会有一个开窗时间,我们的开窗时间是基于这三个时间的哪一种呢?他是基于Event Time这一种的.但是默认情况下,他的时间语义是基于Processing Time这种的.这是所谓的Flink中的时间语义.所以,如果我们不使用Flink默认的时间语义的话,而是使用Event Time的话,我首先还得想清楚,如何去引入这个Event Time.引入Event Time的两行代码,第一行时先声明,告诉我们的Flink,我不用processing Time,我想要使用Event Time. 如下所示:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val env = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line">// 从调用时刻开始给env创建的每一个stream追加时间特征</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br></pre></td></tr></table></figure><p>​        第二行代码就是说,到底我们的每一条数据中的哪一个属性,数据中的哪一个小段,数据中的哪一个字段,他是属于Event Time的,或者说,具体的Event Time的值是多少,你得告诉我.所以第二行代码,如上图所示.</p><p>​        但是具体的Event Time的值是多少呢？ <strong>这个时候我还要你考虑一下,是否我们的数据严格按照我的Event Time的顺序进来呢,还是按照我的Event Time无序(乱序)的进来.所以我们必须考虑这两种情况</strong>.我们的开窗函数事实上在以后的业务中很有可能会考虑这两种情况.无<strong>论你是按照Event Time还是按照Processing Time,我们很有可能都需要考虑这两种情况</strong>.第一种情况就是我的数据是严格按照某一个时间语义升序进来的.还有一种情况就是按照某一个时间语义乱序进来的.升序进来的话就比较简单,但是如果是乱序进来的话.就需要考虑一个延迟的问题了.为了保证我们延迟的时候,可以再固定的时间触发.或者说在某一个条件下去触发,那我们就需要引入一个叫watermark(水位线)</p><p>​        <strong>watermark的作用其实只有两个作用: 一个是规定我们延迟之后(因为我们每一个窗口都要做延迟,为何要延迟?因为数据是乱序的)我到底在什么条件下去触发呢?那是由watermark来决定的.第二个作用是,watermark还可以确定,我们在触发的时候有哪些时间的数据已经进到我们的窗口里面来了.这就是watermark的两个具体的作用.</strong> </p><h1 id="Flink中的时间语义"><a href="#Flink中的时间语义" class="headerlink" title="Flink中的时间语义"></a>Flink中的时间语义</h1><p>在Flink的流式处理中，会涉及到时间的不同概念，如下图所示(Flink时间概念)：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214150638.png"></p><p><strong>Event Time</strong>：是事件创建的时间。它通常由事件中的时间戳描述，例如采集的日志数据中，每一条日志都会记录自己的生成时间，Flink通过时间戳分配器访问事件时间戳。</p><p><strong>Ingestion Time</strong>：是数据进入Flink的时间。</p><p><strong>Processing Time</strong>：是每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是Processing Time。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214151213.png"></p><p>一个例子——电影《星球大战》：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214151321.png"></p><p>例如，一条日志进入Flink的时间为2017-11-12 10:00:00.123，到达Window的系统时间为2017-11-12 10:00:01.234，日志的内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2017-11-02 18:37:15.624 INFO Fail over to rm2</span><br></pre></td></tr></table></figure><p>对于业务来说，要统计1min内的故障日志个数，哪个时间是最有意义的？—— eventTime，因为我们要根据日志的生成时间进行统计。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214151401.png"></p><h1 id="EventTime的引入"><a href="#EventTime的引入" class="headerlink" title="EventTime的引入"></a>EventTime的引入</h1><p>​        在Flink的流式处理中，绝大部分的业务都会使用eventTime，一般只在eventTime无法使用时，才会被迫使用ProcessingTime或者IngestionTime。<br>​        如果要使用EventTime，那么需要引入EventTime的时间属性，引入方式如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">val env = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line">// 从调用时刻开始给env创建的每一个stream追加时间特征</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line"></span><br><span class="line">解析:</span><br><span class="line">其实这TimeCharacteristic.EventTime整个是一个常量,里面有三种常量对应着三种时间.</span><br><span class="line">这句话的意思就是说,未来我要采用eventTime作为我真正要计算的时间.但是问题是你的具体的某一条数据中(这里,假设我们定义的sessionRead使我们的某一条具体数据),但是问题是,我这个eventTime在我sessionRead这条数据中,是哪个属性才是eventTime呢?你还没告诉我,所以这一行代码很明显还是不够的,我们肯定还有明确的代码,告诉我们的Flink, 到底具体的时间是哪一个时间.这里只是告诉你,你如果要用,你必须首先申明.</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line">这行代码你可以理解为,申明告诉我们的Flink,我未来要使用不是Processing Time而是EventTime.至于EventTime中的哪一个,在后面慢慢详解.</span><br></pre></td></tr></table></figure><h1 id="Watermark"><a href="#Watermark" class="headerlink" title="Watermark"></a>Watermark</h1><p>​        Watermark翻译成中文叫做水位线.他就是用来规定,什么样的数据算是迟到的数据.他就是定义一个标准,低于这个标准了,我们就认为是迟到的数据.这个就是所谓的水位线.这个水位线一般来说就是处理乱序的数据,这里我们得清楚,是基于哪一个时间乱序.在第七章我们探讨的是基于Event Time乱序.因为处理时间是不肯定乱序的.因为我是实时处理,所以我们严格按照时间的顺序来进行处理的.但是我进来的数据,他是有可能根据我们事件产生的时间产生一个乱序的行为.这个乱序我们如何处理呢?这就需要定义一个watermark.不但要定义一个Watermark,还要让这个watermark实时的,或者隔一段时间或者达到什么样的条件.他的水位线要跟着变化.但是一般情况下这个水位线是单调递增还是单调递减呢?还是保持不变呢?</p><p>​        你想一下,数据源源不断的从一个管道里面进来,这个数据总体上我们一般认为他是有序的.他不可能总体上无序,比如说我要处理1999年到2020年的数据,最后发现,1999年的数据最后再来.等我全部处理完成之后再来.那这个总体上就无序了.那如果我要处理1999年到2020年数据,这数据有一点乱序的,什么叫有一点乱序呀?就是1999年的某一天,假设是1月1号的某一天.有可能是10:05分的数据来了,05分的数据来了之后,又来了03分的数据.那发现这个数据就不对了,顺序变了.这种情况不止一处的话,说明总体上还是有序的,细节上还是不对的.</p><p>​        但是我的数据总体上完全乱序的,这个就不在我们的watermark的处理范围之内.</p><p>​        Watermark的具体的机制是:<strong>Watermark可以理解成一个延迟触发机制，我们可以设置Watermark的延时时长t，每次系统会校验已经到达的数据中最大的maxEventTime，然后认定eventTime小于maxEventTime - t的所有数据都已经到达，如果有窗口的停止时间等于maxEventTime – t，那么这个窗口被触发执行。</strong></p><p>​        我们设置watermark的一个延时的时长为T,这个T实际上是我们根据数据的特点来设置的.什么叫数据的特点呢?就是数据是进入窗口是乱序进来的,你这数据乱到什么程度.根据你数据乱到什么程度来确定我的T该设置为多少.比如说:本来按道理说是进来的是9:05分的数据了,可是你还进来的是8:05分的数据.这就很明显延迟了1个小时.那么,既然我的数据延迟了一个小时了,所以我的T也应该是要延迟一个小时.这就是所谓的根据你数据的乱序程度.</p><p>​        但是如果我数据应该进来了9:05分,可是呢.我进来的确是9:00的数据,那只是延迟5秒就可以了.所以这个T就要设置为5秒.实际上T是根据你数据乱序的特点来确定我T设置为多少.当你确定好T之后,我们的系统会校验已经到达的数据中最大的Event Time,然后认定我们的eventTime是否小于maxEventTime - t,如果我们的Evnet Time小于我们的maxEventTime-t,那这就说明我们所有的数据都已经到达.这个时候我们就要开始触发了.触发的时候需要判断我们窗口的停止时间是不是小于等于maxEventTime-t,窗口的停止时间就是窗口的结束时间.</p><p>​        我们窗口的起始时间和结束时间是有一个时间范围的.只要是范围的话我们就要考虑一个问题.就是到底是左闭右开,还是左开右闭,或者左闭右也是闭合的,或者包头不包尾的呢?</p><p>​        其实我们的时间范围就是包头不包尾的.啥意思呢?就是包括了起始时间,不包括结束时间.比如说的起始时间是9:00分到9:05分,那结束时间就是9:05分,比如说我现在有一条数据,他就是属于9:00的,那么请问这条数据是不是属于我当前这个窗口的呢?是的.那如果我这条数据是9:05分的数据呢?那他就不属于我们当前这个窗口的了,因为包头不包尾.他应该是属于下一个窗口的.所以我的窗口的起始时间小于等于maxEventTime-t那么我这个窗口就会被触发.</p><p>​        这样的话就有一个watermark这么一个机制来控制我的延迟触发的问题. </p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>​        我们知道，流处理从事件产生，到流经source，再到operator，中间是有一个过程和时间的，虽然大部分情况下，流到operator的数据都是按照事件产生的时间顺序来的，但是也不排除由于网络、分布式等原因，导致乱序的产生，所谓乱序，就是指Flink接收到的事件的先后顺序不是严格按照事件的Event Time顺序排列的。</p><h3 id="数据的乱序图-示"><a href="#数据的乱序图-示" class="headerlink" title="数据的乱序图 示:"></a><strong>数据的乱序图 示:</strong></h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214151816.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">那么此时出现一个问题，一旦出现乱序，如果只根据eventTime决定window的运行，我们不能明确数据是否全部到位，但又不能无限期的等下去，此时必须要有个机制来保证一个特定的时间后，必须触发window去进行计算了，这个特别的机制，就是Watermark。</span><br><span class="line">Watermark是一种衡量Event Time进展的机制。</span><br><span class="line">Watermark是用于处理乱序事件的，而正确的处理乱序事件，通常用Watermark机制结合window来实现。</span><br><span class="line">数据流中的Watermark用于表示timestamp小于Watermark的数据，都已经到达了，因此，window的执行也是由Watermark触发的。</span><br><span class="line">Watermark可以理解成一个延迟触发机制，我们可以设置Watermark的延时时长t，每次系统会校验已经到达的数据中最大的maxEventTime，然后认定eventTime小于maxEventTime - t的所有数据都已经到达，如果有窗口的停止时间等于maxEventTime – t，那么这个窗口被触发执行。</span><br></pre></td></tr></table></figure><h3 id="有序流的Watermarker如下图所示："><a href="#有序流的Watermarker如下图所示：" class="headerlink" title="有序流的Watermarker如下图所示："></a>有序流的Watermarker如下图所示：</h3><p><strong>Watermark设置为0</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214151946.png"></p><h3 id="乱序流的Watermarker如下图所示："><a href="#乱序流的Watermarker如下图所示：" class="headerlink" title="乱序流的Watermarker如下图所示："></a>乱序流的Watermarker如下图所示：</h3><p><strong>Watermark设置为2</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214152129.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214152151.png"></p><p>​        当Flink接收到数据时，会按照一定的规则去生成Watermark，这条Watermark就等于当前所有到达数据中的maxEventTime - 延迟时长，也就是说，Watermark是由数据携带的，一旦数据携带的Watermark比当前未触发的窗口的停止时间要晚，那么就会触发相应窗口的执行。由于Watermark是由数据携带的，因此，如果运行过程中无法获取新的数据，那么没有被触发的窗口将永远都不被触发。</p><p>​        上图中，我们设置的允许最大延迟到达时间为2s，所以时间戳为7s的事件对应的Watermark是5s，时间戳为12s的事件的Watermark是10s，如果我们的窗口1是1s<del>5s，窗口2是6s</del>10s，那么时间戳为7s的事件到达时的Watermarker恰好触发窗口1，时间戳为12s的事件到达时的Watermark恰好触发窗口2。</p><pre><code>     Watermark 就是触发前一窗口的“关窗时间”，一旦触发关门那么以当前时刻为准在窗口范围内的所有所有数据都会收入窗中。</code></pre><p>只要没有达到水位那么不管现实中的时间推进了多久都不会触发关窗。</p><h2 id="Watermark的引入"><a href="#Watermark的引入" class="headerlink" title="Watermark的引入"></a>Watermark的引入</h2><h3 id="水位线有两种-周期性水位线和间断性的水位线"><a href="#水位线有两种-周期性水位线和间断性的水位线" class="headerlink" title="水位线有两种:周期性水位线和间断性的水位线"></a><strong>水位线有两种:周期性水位线和间断性的水位线</strong></h3><p>watermark的引入很简单，对于乱序数据，最常见的引用方式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//上面只说了要引入EventTime,但是没说到底什么时候引入eventTime. 这里就告诉你到底什么时候引入Event</span><br><span class="line">dataStream.assignTimestampsAndWatermarks( new BoundedOutOfOrdernessTimestampExtractor[SensorReading](Time.milliseconds(1000)) &#123;</span><br><span class="line">  override def extractTimestamp(element: SensorReading): Long = &#123;</span><br><span class="line">    element.timestamp * 1000    //EventTime一定要设置毫秒为单位的</span><br><span class="line">  &#125;</span><br><span class="line">&#125; )</span><br></pre></td></tr></table></figure><p>​        Event Time的使用一定要<strong>指定数据源中的时间戳</strong>。否则程序无法知道事件的事件时间是什么(数据源里的数据没有时间戳的话，就只能使用Processing Time了)。</p><p>​        我们看到上面的例子中创建了一个看起来有点复杂的类，这个类实现的其实就是分配时间戳的接口。Flink暴露了TimestampAssigner接口供我们实现，使我们可以自定义如何从事件数据中抽取时间戳。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">val env = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">// 从调用时刻开始给env创建的每一个stream追加时间特性</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line"></span><br><span class="line">val readings: DataStream[SensorReading] = env</span><br><span class="line">        .addSource(new SensorSource)</span><br><span class="line">        .assignTimestampsAndWatermarks(new MyAssigner())</span><br></pre></td></tr></table></figure><h3 id="MyAssigner有两种类型"><a href="#MyAssigner有两种类型" class="headerlink" title="MyAssigner有两种类型"></a>MyAssigner有两种类型</h3><p>​            AssignerWithPeriodicWatermarks   按照周期来设置分配水位线<br>​            AssignerWithPunctuatedWatermarks  根据间断的特点来分配水位线<br>以上两个接口都继承自TimestampAssigner。</p><h4 id="Assigner-with-periodic-watermarks-根据周期来设置分配水位线"><a href="#Assigner-with-periodic-watermarks-根据周期来设置分配水位线" class="headerlink" title="Assigner with periodic watermarks(根据周期来设置分配水位线)"></a>Assigner with periodic watermarks(根据周期来设置分配水位线)</h4><p>Assigner with periodic watermarks 这是一个接口,一定要自己写一个类去实现这个接口,这是一种复杂的代码写法</p><p>如果你想要通过周期性来生成我的watermark的话,实际上你得告诉我周期的间隔时间.默认情况下,周期的时间是200毫秒.也就是说没隔200毫秒会插入水位线.会在数据流中插入水位线.插入一次一定就是调用一个方法去插入.如果我肯定要写一个类去实现AssignerWithPeriodicWatermarks(根据周期来设置分配水位线)这个接口.</p><p>当然这个200毫秒我也可以自己设置,在ExecutionConfig.setAutoWatermark<br>Interval()这个方法中,我可以指定一个时间.那么这个时间就是由我来设置这个周期性.这叫周期性的水位线.就是隔一段时间我给你水位线加上去,隔一段时间我就给你水位线加上去.</p><p>水位线有两个作用:</p><p>第一个作用是,我可以判断小于等于当前水位线的数据已经来了.</p><p>第二个作用是,我可以用他来判断他在什么时候应该触发我们window的function的执行.</p><p>周期性的生成watermark：系统会周期性的将watermark插入到流中(水位线也是一种特殊的事件!)。默认周期是200毫秒。可以使用ExecutionConfig.setAutoWatermarkInterval()方法进行设置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val env = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line"></span><br><span class="line">// 每隔5秒产生一个watermark</span><br><span class="line">env.getConfig.setAutoWatermarkInterval(5000)</span><br></pre></td></tr></table></figure><p>​        产生watermark的逻辑：每隔5秒钟，Flink会调用</p><p>AssignerWithPeriodicWatermarks的getCurrentWatermark()方法。如果方法返回一个时间戳大于之前水位的时间戳，新的watermark会被插入到流中。这个检查保证了水位线是单调递增的。如果方法返回的时间戳小于等于之前水位的时间戳，则不会产生新的watermark。</p><p>例子，自定义一个周期性的时间戳抽取：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class PeriodicAssigner extends AssignerWithPeriodicWatermarks[SensorReading] &#123;</span><br><span class="line">val bound: Long = 60 * 1000 // 延时为1分钟</span><br><span class="line">var maxTs: Long = Long.MinValue // 观察到的最大时间戳</span><br><span class="line">//返回当前的水位线</span><br><span class="line">override def getCurrentWatermark: Watermark = &#123;</span><br><span class="line">new Watermark(maxTs - bound)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">override def extractTimestamp(r: SensorReading, previousTS: Long) = &#123;</span><br><span class="line">maxTs = maxTs.max(r.timestamp)</span><br><span class="line">r.timestamp</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​        一种简单的特殊情况是，如果我们事先得知数据流的时间戳是单调递增的，也就是说没有乱序，那我们可以使用assignAscendingTimestamps，这个方法会直接使用数据的时间戳生成watermark。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val stream: DataStream[SensorReading] = ...</span><br><span class="line">val withTimestampsAndWatermarks = stream</span><br><span class="line">.assignAscendingTimestamps(e =&gt; e.timestamp)</span><br><span class="line"></span><br><span class="line">&gt;&gt; result:  E(1), W(1), E(2), W(2), ...</span><br></pre></td></tr></table></figure><p>​        而对于乱序数据流，如果我们能大致估算出数据流中的事件的最大延迟时间，就可以使用如下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">val stream: DataStream[SensorReading] = ...</span><br><span class="line">val withTimestampsAndWatermarks = stream.assignTimestampsAndWatermarks(</span><br><span class="line">new SensorTimeAssigner</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">class SensorTimeAssigner extends BoundedOutOfOrdernessTimestampExtractor[SensorReading](Time.seconds(5)) &#123;</span><br><span class="line">// 抽取时间戳</span><br><span class="line">override def extractTimestamp(r: SensorReading): Long = r.timestamp</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&gt;&gt; relust:  E(10), W(0), E(8), E(7), E(11), W(1), ...</span><br></pre></td></tr></table></figure><h4 id="Assigner-with-punctuated-watermarks-间断式的生产水位线"><a href="#Assigner-with-punctuated-watermarks-间断式的生产水位线" class="headerlink" title="Assigner with punctuated watermarks(间断式的生产水位线)"></a>Assigner with punctuated watermarks(间断式的生产水位线)</h4><p>​        什么叫间断式的生产watermark(水位线)呢?本质上来说就是根据你指定的条件,他不是按照时间来的,而是让你来决定.你觉得可以加上一个watermark(水位线)了,那你就加.就是你写代码到达某一个条件了你就加一个水位线.当然你写代码时也可以判断时间.比如说你到达某一个时间,你加一个水位线.当然也可以不以时间为判断.比如说我判断你的键值对.键值对中的某一个键等于某个值的时候,我给你加个水位线.或者你的值等于什么什么的时候.我给你加一个水位线.所以,这叫健壮式的生产watermark(水位线).说白了这个所谓的健壮式的watermark(水位线),就是不以这个时间周期性来生成的.就是由我自己根据业务查询,自己根据条件去设置.</p><p>​        </p><p>​    间断式地生成watermark。和周期性生成的方式不同，这种方式不是固定时间的，而是可以根据需要对每条数据进行筛选和处理。直接上代码来举个例子，我们只给sensor_1的传感器的数据流插入watermark：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class PunctuatedAssigner extends AssignerWithPunctuatedWatermarks[SensorReading] &#123;</span><br><span class="line">val bound: Long = 60 * 1000</span><br><span class="line"></span><br><span class="line">override def checkAndGetNextWatermark(r: SensorReading, extractedTS: Long): Watermark = &#123;</span><br><span class="line">if (r.id == &quot;sensor_1&quot;) &#123;</span><br><span class="line">new Watermark(extractedTS - bound)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">null</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">override def extractTimestamp(r: SensorReading, previousTS: Long): Long = &#123;</span><br><span class="line">r.timestamp</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="EvnetTime在window中的使用"><a href="#EvnetTime在window中的使用" class="headerlink" title="EvnetTime在window中的使用"></a>EvnetTime在window中的使用</h1><h2 id="滚动窗口（TumblingEventTimeWindows）"><a href="#滚动窗口（TumblingEventTimeWindows）" class="headerlink" title="滚动窗口（TumblingEventTimeWindows）"></a>滚动窗口（TumblingEventTimeWindows）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    //  环境</span><br><span class="line">    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line">    env.setParallelism(1)</span><br><span class="line"></span><br><span class="line">    val dstream: DataStream[String] = env.socketTextStream(&quot;localhost&quot;,7777)</span><br><span class="line"></span><br><span class="line">    val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map &#123; text =&gt;</span><br><span class="line">      val arr: Array[String] = text.split(&quot; &quot;)</span><br><span class="line">      (arr(0), arr(1).toLong, 1)</span><br><span class="line">    &#125;</span><br><span class="line">    val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) &#123;</span><br><span class="line">      override def extractTimestamp(element: (String, Long, Int)): Long = &#123;</span><br><span class="line"></span><br><span class="line">       return  element._2</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)</span><br><span class="line">    textKeyStream.print(&quot;textkey:&quot;)</span><br><span class="line"></span><br><span class="line">    val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(TumblingEventTimeWindows.of(Time.seconds(2)))</span><br><span class="line"></span><br><span class="line">    val groupDstream: DataStream[mutable.HashSet[Long]] = windowStream.fold(new mutable.HashSet[Long]()) &#123; case (set, (key, ts, count)) =&gt;</span><br><span class="line">      set += ts</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    groupDstream.print(&quot;window::::&quot;).setParallelism(1)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果是按照Event Time的时间窗口计算得出的，而无关系统的时间（包括输入的快慢）</p><h2 id="滑动窗口（SlidingEventTimeWindows）"><a href="#滑动窗口（SlidingEventTimeWindows）" class="headerlink" title="滑动窗口（SlidingEventTimeWindows）"></a>滑动窗口（SlidingEventTimeWindows）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">def main(args: Array[String]): Unit = &#123;</span><br><span class="line">  //  环境</span><br><span class="line">  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line">  env.setParallelism(1)</span><br><span class="line"></span><br><span class="line">  val dstream: DataStream[String] = env.socketTextStream(&quot;localhost&quot;,7777)</span><br><span class="line"></span><br><span class="line">  val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map &#123; text =&gt;</span><br><span class="line">    val arr: Array[String] = text.split(&quot; &quot;)</span><br><span class="line">    (arr(0), arr(1).toLong, 1)</span><br><span class="line">  &#125;</span><br><span class="line">  val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) &#123;</span><br><span class="line">    override def extractTimestamp(element: (String, Long, Int)): Long = &#123;</span><br><span class="line"></span><br><span class="line">     return  element._2</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)</span><br><span class="line">  textKeyStream.print(&quot;textkey:&quot;)</span><br><span class="line"></span><br><span class="line">  val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(SlidingEventTimeWindows.of(Time.seconds(2),Time.milliseconds(500)))</span><br><span class="line"></span><br><span class="line">  val groupDstream: DataStream[mutable.HashSet[Long]] = windowStream.fold(new mutable.HashSet[Long]()) &#123; case (set, (key, ts, count)) =&gt;</span><br><span class="line">    set += ts</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  groupDstream.print(&quot;window::::&quot;).setParallelism(1)</span><br><span class="line"></span><br><span class="line">  env.execute()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="会话窗口（EventTimeSessionWindows）"><a href="#会话窗口（EventTimeSessionWindows）" class="headerlink" title="会话窗口（EventTimeSessionWindows）"></a>会话窗口（EventTimeSessionWindows）</h2><p>​        相邻两次数据的EventTime的时间差超过指定的时间间隔就会触发执行。如果加入Watermark， 会在符合窗口触发的情况下进行延迟。到达延迟水位再进行窗口触发。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    //  环境</span><br><span class="line">    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line">    env.setParallelism(1)</span><br><span class="line"></span><br><span class="line">    val dstream: DataStream[String] = env.socketTextStream(&quot;localhost&quot;,7777)</span><br><span class="line"></span><br><span class="line">    val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map &#123; text =&gt;</span><br><span class="line">      val arr: Array[String] = text.split(&quot; &quot;)</span><br><span class="line">      (arr(0), arr(1).toLong, 1)</span><br><span class="line">    &#125;</span><br><span class="line">    val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) &#123;</span><br><span class="line">      override def extractTimestamp(element: (String, Long, Int)): Long = &#123;</span><br><span class="line"></span><br><span class="line">       return  element._2</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)</span><br><span class="line">    textKeyStream.print(&quot;textkey:&quot;)</span><br><span class="line"></span><br><span class="line">    val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(EventTimeSessionWindows.withGap(Time.milliseconds(500)) )</span><br><span class="line"></span><br><span class="line">    windowStream.reduce((text1,text2)=&gt;</span><br><span class="line">      (  text1._1,0L,text1._3+text2._3)</span><br><span class="line">    )  .map(_._3).print(&quot;windows:::&quot;).setParallelism(1)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;时间语义与Wartermark-水位线-阐述&quot;&gt;&lt;a href=&quot;#时间语义与Wartermark-水位线-阐述&quot; class=&quot;headerlink&quot; title=&quot;时间语义与Wartermark(水位线)阐述:&quot;&gt;&lt;/a&gt;时间语义与Wartermark(水位线)阐述:&lt;/h1&gt;&lt;p&gt;用到了时间语义和watermark,所以Flink和sparkStreaming是有一定的区别的.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Flink中的时间语义有三种:&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Event Time(事件触发的时间或者是事件创建的时间),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Ingestion Time(进入Flink的时间),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Processing Time(Flink在处理这条数据的时间),&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink中的Window API</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%B8%AD%E7%9A%84Window-API/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%B8%AD%E7%9A%84Window-API/</id>
    <published>2022-02-14T06:26:50.000Z</published>
    <updated>2022-02-14T07:00:18.604Z</updated>
    
    <content type="html"><![CDATA[<p>附录算子俯瞰图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214142001.png"></p><span id="more"></span><h1 id="TimeWindow-时间窗口"><a href="#TimeWindow-时间窗口" class="headerlink" title="TimeWindow(时间窗口)"></a>TimeWindow(时间窗口)</h1><p><strong>时间窗口有三种:滚动窗口,滑动窗口, 会话窗口</strong></p><p>​        <strong>TimeWindow是将指定时间范围内的所有数据组成一个window，一次对一个window里面的所有数据进行计算。</strong></p><p>​        注意：timeWindow函数必须在keyBy之后，timeWindowAll则不需要</p><p><strong>不管你是三种窗口中的哪一种，如果你的窗口函数的后面没有加All的话，那就是基于我们的keyedStream的，加了All就是基于我们的DataStream的.</strong></p><h2 id="1-滚动窗口（Tumbling-Window）"><a href="#1-滚动窗口（Tumbling-Window）" class="headerlink" title="1.滚动窗口（Tumbling Window）"></a>1.滚动窗口（Tumbling Window）</h2><p>Flink默认的时间窗口根据Processing Time 进行窗口的划分，将Flink获取到的数据根据进入Flink的时间划分到不同的窗口中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val minTempPerWindow = dataStream</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .timeWindow(Time.seconds(15))</span><br><span class="line">  .reduce((r1, r2) =&gt; (r1._1, r1._2.min(r2._2)))</span><br></pre></td></tr></table></figure><p>注意:</p><p>​        滚动窗口一定要在keyBy之后去调用.keyBy之后调用的话,由于它是滚动窗口.我们只需要传一个参数,就是窗口的长度就可以了.<br>​        如果你仔细想的话,你发现有一个问题:  就是假设我窗口的长度为15秒,那么当前某一个窗口他的起始的时间是怎么算的?是不是就是把你当前的时间除以15呀.直接除以15取模,取模之后的到一个什么?</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214143417.png"></p><p>​            时间间隔可以通过<strong>Time.milliseconds(x)毫秒，Time.seconds(x)秒，Time.minutes(x)分钟</strong>,等其中的一个来指定。</p><p>​            TimeWindow()实际上就是设置我们的窗口.窗口设置好之后,要么做聚合要么做其他操做,一般来说就是做聚合.</p><h2 id="2-滑动窗口（SlidingEventTimeWindows）"><a href="#2-滑动窗口（SlidingEventTimeWindows）" class="headerlink" title="2.滑动窗口（SlidingEventTimeWindows）"></a>2.滑动窗口（SlidingEventTimeWindows）</h2><p>​        <strong>滑动窗口和滚动窗口的函数名是完全一致的</strong>，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。</p><p>​        下面代码中的sliding_size设置为了5s，也就是说，窗口每5s就计算一次，每一次计算的window范围是15s内的所有元素。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val minTempPerWindow: DataStream[(String, Double)] = dataStream</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .timeWindow(Time.seconds(15), Time.seconds(5))</span><br><span class="line">  .reduce((r1, r2) =&gt; (r1._1, r1._2.min(r2._2)))</span><br><span class="line">.window(EventTimeSessionWindows.withGap(Time.minutes(10))</span><br></pre></td></tr></table></figure><p><strong>时间间隔可以通过Time.milliseconds(x)，Time.seconds(x)，Time.minutes(x)等其中的一个来指定。</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214143631.png"></p><h1 id="CountWindow-计数窗口"><a href="#CountWindow-计数窗口" class="headerlink" title="CountWindow(计数窗口)"></a>CountWindow(计数窗口)</h1><p>​        **CountWindow(计数窗口)**也有所谓的滚动窗口和滑动窗口,但是他只有这两个,没有所谓的会话窗口</p><p>​        CountWindow根据窗口中相同key元素的数量来触发执行，执行时只计算元素数量达到窗口大小的key对应的结果。</p><p>​        注意：CountWindow的window_size指的是相同Key的元素的个数，不是输入的所有元素的总数。</p><h2 id="1-滚动窗口（Tumbling-Window）-1"><a href="#1-滚动窗口（Tumbling-Window）-1" class="headerlink" title="1.滚动窗口（Tumbling Window）"></a>1.滚动窗口（Tumbling Window）</h2><p>​       <strong>默认的CountWindow是一个滚动窗口，只需要指定窗口大小即可，当元素数量达到窗口大小时，就会触发窗口的执行。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val minTempPerWindow: DataStream[(String, Double)] = dataStream</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .countWindow(5)</span><br><span class="line">  .reduce((r1, r2) =&gt; (r1._1, r1._2.max(r2._2)))</span><br></pre></td></tr></table></figure><h2 id="2-滑动窗口（SlidingEventTimeWindows）-1"><a href="#2-滑动窗口（SlidingEventTimeWindows）-1" class="headerlink" title="2.滑动窗口（SlidingEventTimeWindows）"></a>2.滑动窗口（SlidingEventTimeWindows）</h2><p>​        滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。</p><p>​        下面代码中的sliding_size设置为了2，也就是说，每收到两个相同key的数据就计算一次，每一次计算的window范围是5个元素。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val keyedStream: KeyedStream[(String, Int), Tuple] = dataStream.map(r =&gt; (r.id, r.temperature)).keyBy(0)</span><br><span class="line">//每当某一个key的个数达到2的时候,触发计算，计算最近该key最近10个元素的内容</span><br><span class="line">val windowedStream: WindowedStream[(String, Int), Tuple, GlobalWindow] = keyedStream.countWindow(10,2)</span><br><span class="line">val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</span><br></pre></td></tr></table></figure><h1 id="window-function-窗口函数"><a href="#window-function-窗口函数" class="headerlink" title="window function(窗口函数)"></a>window function(窗口函数)</h1><p> <strong>window function(窗口函数) :  这里面有增量聚合函数和全窗口函数</strong></p><p>​        <strong>window function 定义了要对窗口中收集的数据做的计算操作，主要可以分为两类：</strong></p><h2 id="1-增量聚合函数（incremental-aggregation-functions）"><a href="#1-增量聚合函数（incremental-aggregation-functions）" class="headerlink" title="1.增量聚合函数（incremental aggregation functions）"></a>1.增量聚合函数（incremental aggregation functions）</h2><p>​                        每条数据到来就进行计算，保持一个简单的状态。典型的增量聚合函数有ReduceFunction, AggregateFunction。</p><h2 id="2-全窗口函数（full-window-functions）"><a href="#2-全窗口函数（full-window-functions）" class="headerlink" title="2.全窗口函数（full window functions）"></a>2.全窗口函数（full window functions）</h2><p>​                        先把窗口所有数据收集起来，等到计算的时候会遍历所有数据。</p><p>​                        ProcessWindowFunction和ProcessAllWindowFunction就是一个全窗口函数。</p><p>​                        Apply也是全量的.</p><h1 id="其它可选API"><a href="#其它可选API" class="headerlink" title="其它可选API"></a>其它可选API</h1><p><strong>.trigger() —— 触发器</strong></p><p>定义 window 什么时候关闭，触发计算并输出结果</p><p><strong>.evitor() —— 移除器</strong></p><p>定义移除某些数据的逻辑</p><p><strong>.allowedLateness()</strong> —— 允许处理迟到的数据</p><p><strong>.sideOutputLateData()</strong> —— 将迟到的数据放入侧输出流</p><p><strong>.getSideOutput()</strong> —— 获取侧输出流</p><h2 id="什么叫允许处理迟到的数据"><a href="#什么叫允许处理迟到的数据" class="headerlink" title="什么叫允许处理迟到的数据?"></a>什么叫允许处理迟到的数据?</h2><p>这个时候就得考虑,我们的开窗的规则.他到底是按照什么时间来确定的.如果你开窗的规则不是按照执行时间,而是按照数据生成的时间.那就有可能出现所谓迟到的数据.举例:假设我数据的产生是在2:05分产生的.产生数据之后通过kafka再到我们的flink里面.中间是不是有一个过程呀?中间可能隔离一分钟等时间.然后到了我们的FlinkJob里面之后,Flink Job默认情况下他不是探讨你的数据生成的时间,而是探讨执行时间.执行时间肯定是按照顺序来的.但有没有可能是2:05产生的数据先来,下一条数据是2:04分生成的数据呢?当然有可能.所以假设以后要做这个流处理,要严格按照这个数据的生成时间,那这个时候就会出现所谓的迟到的数据.比如说2:05分的数据来了之后发现2:04分的数据还没来.他是真正执行完之后可能下一个窗口才来.那这个就叫所谓的迟到的数据.如果你要严格按照时间顺序的话,你就需要将2:05分的数据等一下.就要想办法让2:04分的这个迟到的数据放到2:05分的数据之前处理.那有什么解决办法呢?</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214145930.png"></p><p>**这三个操作就是其中一个解决方法.就是把迟到的数据单独放到一个分支流数据中.叫侧输出流.放到侧输出流中,我们还得取到侧输出流中的数据.这就是一个不太好的办法.**这个实际上也没法做到实时性.而且你也不知道到底哪个是迟到的数据.什么样的数据才算做迟到的数据.没有一个标准.所以这种处理迟到数据的办法不是最好的.只是他是其中一种.当然还有其他的一些参数,这里只介绍到这里.</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214150000.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;附录算子俯瞰图:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214142001.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink中的Window</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%B8%AD%E7%9A%84Window/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%B8%AD%E7%9A%84Window/</id>
    <published>2022-02-14T06:03:51.000Z</published>
    <updated>2022-02-14T06:22:43.400Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Window主要分为哪几种?</strong><br>window主要分为<br><strong>CountWindow</strong>:  计数窗口:按照指定的数据条数生成一个Window，与时间无关。</p><p><strong>TimeWindow</strong>:    时间窗口:按照指定的数据条数生成一个Window，与时间无关。</p><p>而我们最关心的就是<strong>TimeWindow</strong>,因为他和时间有关系.<br><strong>TimeWindow又分为三种: 滑动窗口,滚动窗口,会话窗口.</strong></p><p>滚动窗口和滑动窗口有一个特点,就是他们的时间是对齐的.</p><p>所谓的时间对齐是什么意思呢?</p><span id="more"></span><p>就是你不管是哪一个并行度,里面所有的时间是对齐的.对齐说的是数据的时间对齐.比如说我这窗口的起始时间是10:05分,那我所有的,只要是10:05分的数据,都属于我接下来这新开的窗口.因为我假设我开窗的起始时间,实际上说的就是 我的开窗时间是10:05分的话,那么我不管你是哪个组的,也不管你是哪个分区的.我们的数据只要到达10:05分,就属于当前我们这个窗口.这就叫所谓的时间对齐.滚动窗口是没有滑动步长的,只有滑动窗口才有滑动步长.</p><p>​    如果我们在选择窗口开窗的时候,还需要对窗口里面的数据进行处理.对数据进行处理的话,我们称之为windowFunction,也称之为窗口函数.<br>​    <strong>WindowFunction(窗口函数)分为两类,一类叫增量聚合函数,另一种叫全窗口函数</strong><br>​    增量聚合函数的意思就是说,在窗口里面,因为一个窗口是一个起始时间到结束时间.这个时间段内,源源不断的会有数据过来.那么你来一条数据我就处理一条数据,来一条数据我就处理一条数据.这是一种情况.还有一种情况就是全窗口函数,等这个窗口结束了,所有数据都来了,我一次性处理.这两种处理方式就是所谓的增量聚合函数和全窗口函数.在大多数的</p><p>​    生产环境中,我们使用增量聚合函数比较合适.因为假设你后面一个窗口里面数据量特别多的话.你如果一次性全部处理的话,你处理时间是比较长的.但是如果我数据量很多,我来一条就处理一条,来一条就处理一条,那我事实上我就把我处理的时间均匀的分散到这个很长的时间段里面去了.所以他实际上比不会耽误我们的时间.</p><p>所以我们重点关心增量聚合函数.他有两大类,<br><strong>一个叫ReduceFunction,另一个叫AggregateFunction,都是属于增量聚合函数.</strong></p><h1 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h1><p>Window开窗,开往窗口之后怎么办?是由windowFunctions来决定的</p><p><strong>Window就是把无限的流，按照时间或者条数或者会话切成有限的流。本来你的流是无限的,我们按照一定规则切成一段一段的有限的流.而每一小段就是一段窗口(window)</strong></p><h2 id="Window概述"><a href="#Window概述" class="headerlink" title="Window概述"></a>Window概述</h2><p>​        Spark streaming流式计算是一种被设计用于处理无限数据集的数据处理引擎，而无限数据集是指一种不断增长的本质上无限的数据集，而<strong>window是一种切割无限数据为有限块进行处理的手段</strong>。</p><p>​        Window是无限数据流处理的核心，Window将一个无限的stream拆分成有限大小的”buckets”桶，我们可以在这些桶上做计算操作。</p><h2 id="Window类型"><a href="#Window类型" class="headerlink" title="Window类型"></a>Window类型</h2><p><strong>Window可以分成两类</strong>：<br>        CountWindow(计数窗口)：按照指定的数据条数生成一个Window，与时间无关。<br>        TimeWindow(时间窗口)：按照时间生成Window。<br>对于TimeWindow，可以根据窗口实现原理的不同分成三类：<strong>滚动窗口（Tumbling Window）、滑动窗口（Sliding Window）和会话窗口(Session Window）。</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141018.png"></p><p><strong>滑动窗口有可能有某两条数据进到第一个窗口同时又进入到第二个窗口</strong></p><p><strong>滚动窗口只要设置窗口的长度就可以了.</strong></p><h3 id="1-滚动窗口（Tumbling-Windows）"><a href="#1-滚动窗口（Tumbling-Windows）" class="headerlink" title="1.滚动窗口（Tumbling Windows）"></a>1.滚动窗口（Tumbling Windows）</h3><p>将数据依据固定的窗口长度对数据进行切片。<br><strong>特点：时间对齐，窗口长度固定，没有重叠。</strong></p><p><strong>时间对齐是啥意思?什么情况下时间对齐?如果你的窗口没有加ALL的话</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141145.png"></p><p>​        我们的窗口是基于KeyedStream的.就是分完组之后再使用窗口函数.你既然是KeyedStream那就是有很多一组一组的数据.如下图所示: user1,user2,user3你可以理解为三个组.这三个组他的时间一定是一致的.所以称之为时间对齐.就是说,如果Window1的时间是2019年11月11日11点11分11秒的话,那么window2,window3,window4等等所有的滑动窗口的组都是这个时间.所以说是时间对齐.窗口长度固定,没有重叠.没有重叠就是说任何一条数据不可能重复进入到两个窗口.随意说,我们定义这样的一个滚动窗口只需要定义窗口长度就可以了.</p><p>滚动窗口分配器将每个元素分配到一个指定窗口大小的窗口中，滚动窗口有一个固定的大小，并且不会出现重叠。例如：如果你指定了一个5分钟大小的滚动窗口，窗口的创建如下图所示：</p><p><strong>滚动窗口</strong>示例图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141305.png"></p><p><strong>适用场景</strong>：适合做BI统计等（做每个时间段的聚合计算）。</p><h3 id="2-滑动窗口（Sliding-Windows）"><a href="#2-滑动窗口（Sliding-Windows）" class="headerlink" title="2.滑动窗口（Sliding Windows）"></a>2.滑动窗口（Sliding Windows）</h3><p>滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成。</p><p><strong>特点：时间对齐，窗口长度固定,增加滑动步长，可以有重叠。</strong></p><p>​    由于他增加了滑动步长,所以说,他可以出现数据的重叠.<br>​    滑动窗口分配器将元素分配到固定长度的窗口中，与滚动窗口类似，窗口的大小由窗口大小参数来配置，另一个窗口滑动参数控制滑动窗口开始的频率。因此，滑动窗口如果滑动参数小于窗口大小的话，窗口是可以重叠的，在这种情况下元素会被分配到多个窗口中。<br>​    例如，你有10分钟的窗口和5分钟的滑动，那么每个窗口中5分钟的窗口里包含着上个10分钟产生的数据，如下图所示：</p><p><strong>滑动窗口</strong>示例图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141539.png"></p><p><strong>适用场景</strong>：对最近一个时间段内的统计（求某接口最近5min的失败率来决定是否要报警）。</p><h3 id="3-会话窗口（Session-Windows）"><a href="#3-会话窗口（Session-Windows）" class="headerlink" title="3.会话窗口（Session Windows）"></a>3.会话窗口（Session Windows）</h3><p>​        会话窗口就是说在<strong>某一个你指定的时间长度内.没有数据来了.假设我规定这个时间长度为5秒.那么上一个窗口结束之后5秒内都没有数据来.5秒钟之后,到第六秒开始有数据来了.那么我们就认为,从第六秒开始,就是一个新的窗口了</strong>.所以他中间有一个时间的间隙.这就称之为会话窗口.为什么称之为会话窗口呢?因为你发现没有,既然他有时间的间隙的话,就好比一次一次的会话一样.</p><p>​        假如你开发了一个web项目跑在Tomcat里面的话.默认情况下,会话的超时时间是多少?半小时.所谓默认的会话超时时间是什么意思?他这个半小时是从什么时刻开始算的?是从你这个会话的最后一次访问的时间开始算的.半个小时之后你这个会话就超时了. 会话超时的话,说白了你这个会话就结束了.那么以后来的数据就是另外一个会话.或者以后来的请求就是另外一个会话.这里我们的timeout就是所谓的会话超时时间.这个会话超时时间假设你设定为5秒.那么这5秒从哪里开始算呢?就是从window1的最后一条数据进来的时间开始算.5秒钟之后,如果你还是没有数据来.那么就会产生一个窗口2;但是假设你这5秒钟内还一直有数据来呢?有数据来还是属于window1.而这个window1的边界就开始往后延伸.因为他是严格按照会话的超时时间来进行切割window.来切割widow的话,这个特点就是他这个时间没有对齐的.</p><p>​        很明显时间没有对齐呀!因为很有可能某一个window他的数据量比较大,且时间跨度比较长.那么下一个窗口的量比较大,时间跨度比较短,这也是有可能的.所以时间无对齐的. </p><p>​         所以会话窗口（Session Windows）由一系列事件组合一个指定时间长度的timeout间隙组成，类似于web应用的session，也就是一段时间没有接收到新数据就会生成新的窗口。</p><p>​        特点：时间无对齐。</p><p>​        session窗口分配器通过session活动来对元素进行分组，session窗口跟滚动窗口和滑动窗口相比，不会有重叠和固定的开始时间和结束时间的情况，相反，当它在一个固定的时间周期内不再收到元素，即非活动间隔产生，那个这个窗口就会关闭。一个session窗口通过一个session间隔来配置，这个session间隔定义了非活跃周期的长度，当这个非活跃周期产生，那么当前的session将关闭并且后续的元素将被分配到新的session窗口中去。</p><p><strong>会话窗口</strong>示例图</p><p>​    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214141811.png"></p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220214142001.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Window主要分为哪几种?&lt;/strong&gt;&lt;br&gt;window主要分为&lt;br&gt;&lt;strong&gt;CountWindow&lt;/strong&gt;:  计数窗口:按照指定的数据条数生成一个Window，与时间无关。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TimeWindow&lt;/strong&gt;:    时间窗口:按照指定的数据条数生成一个Window，与时间无关。&lt;/p&gt;
&lt;p&gt;而我们最关心的就是&lt;strong&gt;TimeWindow&lt;/strong&gt;,因为他和时间有关系.&lt;br&gt;&lt;strong&gt;TimeWindow又分为三种: 滑动窗口,滚动窗口,会话窗口.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;滚动窗口和滑动窗口有一个特点,就是他们的时间是对齐的.&lt;/p&gt;
&lt;p&gt;所谓的时间对齐是什么意思呢?&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>YARN调度器【capacity-scheduler.xml】默认配置</title>
    <link href="http://xubatian.cn/Hadoop%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/YARN%E8%B0%83%E5%BA%A6%E5%99%A8%E3%80%90capacity-scheduler-xml%E3%80%91%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE/"/>
    <id>http://xubatian.cn/Hadoop%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/YARN%E8%B0%83%E5%BA%A6%E5%99%A8%E3%80%90capacity-scheduler-xml%E3%80%91%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE/</id>
    <published>2022-02-12T10:11:21.000Z</published>
    <updated>2022-02-12T10:20:31.134Z</updated>
    
    <content type="html"><![CDATA[<p>Hadoop版本：3.1.3</p><pre><code>1、三种常见调度器    1.1、先进先出调度器    1.2、容量调度器    1.3、公平调度器2、容量调度器 多队列配置3、单词4、默认配置【capacity-scheduler.xml】</code></pre><span id="more"></span><h1 id="1、三种常见调度器"><a href="#1、三种常见调度器" class="headerlink" title="1、三种常见调度器"></a>1、三种常见调度器</h1><h2 id="1-1、先进先出调度器"><a href="#1-1、先进先出调度器" class="headerlink" title="1.1、先进先出调度器"></a>1.1、先进先出调度器</h2><pre><code>first-in first-out schedulerFIFO Scheduler后入队的任务 要等待 前入队的任务 出队</code></pre><p>可配置：<br>    1、每个用户的最大资源占比，防止单个用户把资源占满<br>    2、限制哪些用户可以提交应用到本队列 </p><h2 id="1-2、容量调度器"><a href="#1-2、容量调度器" class="headerlink" title="1.2、容量调度器"></a>1.2、容量调度器</h2><pre><code>Capacity Scheduler相当于 多个 FIFO Scheduler不同队列上的任务可以并行（比如 3个队列就可以并行3个任务）相同队列上的任务不能并行</code></pre><p>可配置：<br>    1、默认容量占比：各个队列占据一定百分比的资源<br>    （如：a队列40% b队列60%）<br>    2、最大容量占比：队列占据的资源百分比的最大值<br>    （如：a队列最大70%，当超出40%时，可以借b队列的空闲资源，最多借30%） </p><pre><code>划分方式：按业务划分（更常用）：下单、支付、物流…按技术划分：HIVE、Spark、Flink…</code></pre><h2 id="1-3、公平调度器"><a href="#1-3、公平调度器" class="headerlink" title="1.3、公平调度器"></a>1.3、公平调度器</h2><pre><code>Fair Scheduler和Capacity Scheduler类似，可以多队列配置；不同的是，叶子队列不是FIFO的在同一条叶子队列上，所有作业可以并发；资源分配的依据：时间尺度、优先级、资源缺额…</code></pre><p>在时间尺度上获得公平的资源</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220212181307.png"></p><p>最大最小公平分配算法</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220212181328.png"></p><h1 id="2、容量调度器-多队列配置"><a href="#2、容量调度器-多队列配置" class="headerlink" title="2、容量调度器 多队列配置"></a>2、容量调度器 多队列配置</h1><h2 id="1、编辑配置文件"><a href="#1、编辑配置文件" class="headerlink" title="1、编辑配置文件"></a>1、编辑配置文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim $HADOOP_HOME/etc/hadoop/capacity-scheduler.xml</span><br></pre></td></tr></table></figure><h2 id="2、修改根队列下面的叶队列名称，逗号分隔（此处新增队列名称为hive）"><a href="#2、修改根队列下面的叶队列名称，逗号分隔（此处新增队列名称为hive）" class="headerlink" title="2、修改根队列下面的叶队列名称，逗号分隔（此处新增队列名称为hive）"></a>2、修改<strong>根队列</strong>下面的<strong>叶队列</strong>名称，逗号分隔（此处新增队列名称为<code>hive</code>）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;default,hive&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;在根队列下设置叶队列名称&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h2 id="3、修改-名为default的队列-的容量占比"><a href="#3、修改-名为default的队列-的容量占比" class="headerlink" title="3、修改 名为default的队列 的容量占比"></a>3、修改 名为default的队列 的容量占比</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;40&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;设置root下名为default队列的容量占比&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h2 id="4、给新队列配置"><a href="#4、给新队列配置" class="headerlink" title="4、给新队列配置"></a>4、给新队列配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;60&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;root下名为hive的队列 的 容量占比&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.user-limit-factor&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;每个用户可以占据该队列资源占比的上限（防止某用户把资源占满）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.maximum-capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;80&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;该队列的最大容量占比（可外借80-60=20）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.state&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;RUNNING&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;该队列状态（RUNNING或STOPPED）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.acl_submit_applications&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;访问控制列表：限定哪些用户 能访问该队列&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.acl_administer_queue&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;访问控制列表：限定哪些用户 可以管理该队列上的作业&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.acl_application_max_priority&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.maximum-application-lifetime&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;提交到该队列的应用 的 最大生存时间（-1表示无限时间）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.hive.default-application-lifetime&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;提交到该队列的应用 的 默认生存时间（-1表示无限时间；要求小于最大生存时间）&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h2 id="5、分发配置"><a href="#5、分发配置" class="headerlink" title="5、分发配置"></a>5、分发配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync.py $HADOOP_HOME/etc/hadoop/capacity-scheduler.xml</span><br></pre></td></tr></table></figure><h2 id="6、查看浏览器，端口8088"><a href="#6、查看浏览器，端口8088" class="headerlink" title="6、查看浏览器，端口8088"></a>6、查看浏览器，端口<code>8088</code></h2><p><img src="https://img-blog.csdnimg.cn/20210423104042285.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1llbGxvd19weXRob24=,size_16,color_FFFFFF,t_70"></p><p>7、提交到指定队列</p><ul><li>Java代码的<code>org.apache.hadoop.conf.Configuration</code></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">configuration.set(&quot;mapred.job.queuename&quot;, &quot;hive&quot;);</span><br></pre></td></tr></table></figure><ul><li>HIVE</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapred.job.queue.name=hive</span><br></pre></td></tr></table></figure><h1 id="3、单词"><a href="#3、单词" class="headerlink" title="3、单词"></a>3、单词</h1><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220212181655.png"></p><h1 id="4、默认配置【capacity-scheduler-xml】"><a href="#4、默认配置【capacity-scheduler-xml】" class="headerlink" title="4、默认配置【capacity-scheduler.xml】"></a>4、默认配置【capacity-<a href="https://so.csdn.net/so/search?q=scheduler&spm=1001.2101.3001.7020">scheduler</a>.xml】</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 容量调度器中 挂起和运行的应用程序 的 最大数量 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.maximum-applications&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;10000&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Maximum number of applications that can be pending and running.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 可以用来运行【Application Masters】的最大资源占比 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.maximum-am-resource-percent&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;0.1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Maximum percent of resources in the cluster which can be used to run </span><br><span class="line">application masters i.e. controls number of concurrent running applications.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 容量调度器中的【资源计算器】，它用来 比较资源，默认比较资源的内存，</span><br><span class="line">另外可以选择别的资源计算器，从资源的多个维度（不仅内存，还有CPU等）来比较 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.resource-calculator&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">The ResourceCalculator implementation to be used to compare Resources in the scheduler.</span><br><span class="line">The default i.e. DefaultResourceCalculator only uses Memory while</span><br><span class="line">DominantResourceCalculator uses dominant-resource to compare </span><br><span class="line">multi-dimensional resources such as Memory, CPU etc.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 在 名为root的队列 下 设置队列名称（默认default一条队列，可设置多队列） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;default&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;The queues at the this level (root is the root queue).&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- root下名为default的队列 的 容量占比 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;100&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Default queue target capacity.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 每个用户可以占据该队列资源占比的上限（防止某用户把资源占满） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.user-limit-factor&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Default queue user limit a percentage from 0.0 to 1.0.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 该队列的最大容量占比 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.maximum-capacity&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;100&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 该队列状态（RUNNING or STOPPED） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.state&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;RUNNING&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 访问控制列表：限定哪些用户 能访问该队列 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.acl_submit_applications&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 访问控制列表：限定哪些用户 可以管理该队列上的作业 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.acl_administer_queue&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;The ACL of who can administer jobs on the default queue.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.acl_application_max_priority&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">The ACL of who can submit applications with configured priority.</span><br><span class="line">For e.g, [user=&#123;name&#125; group=&#123;name&#125; max_priority=&#123;priority&#125; default_priority=&#123;priority&#125;]</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 提交到该队列的应用 的 最大生存时间（-1表示无限时间） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.maximum-application-lifetime&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Maximum lifetime of an application which is submitted to a queue</span><br><span class="line">in seconds. Any value less than or equal to zero will be considered as disabled.</span><br><span class="line">This will be a hard time limit for all applications in this</span><br><span class="line">queue. If positive value is configured then any application submitted</span><br><span class="line">to this queue will be killed after exceeds the configured lifetime.</span><br><span class="line">User can also specify lifetime per application basis in</span><br><span class="line">application submission context. But user lifetime will be</span><br><span class="line">overridden if it exceeds queue maximum lifetime. It is point-in-time</span><br><span class="line">configuration.</span><br><span class="line">Note : Configuring too low value will result in killing application</span><br><span class="line">sooner. This feature is applicable only for leaf queue.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 提交到该队列的应用 的 默认生存时间（-1表示无限时间；要求小于最大生存时间） --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.root.default.default-application-lifetime&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Default lifetime of an application which is submitted to a queue</span><br><span class="line">in seconds. Any value less than or equal to zero will be considered as</span><br><span class="line">disabled.</span><br><span class="line">If the user has not submitted application with lifetime value then this</span><br><span class="line">value will be taken. It is point-in-time configuration.</span><br><span class="line">Note : Default lifetime can&#x27;t exceed maximum lifetime. This feature is</span><br><span class="line">applicable only for leaf queue.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.node-locality-delay&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;40&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Number of missed scheduling opportunities after which the CapacityScheduler </span><br><span class="line">attempts to schedule rack-local containers.</span><br><span class="line">When setting this parameter, the size of the cluster should be taken into account.</span><br><span class="line">We use 40 as the default value, which is approximately the number of nodes in one rack.</span><br><span class="line">Note, if this value is -1, the locality constraint in the container request</span><br><span class="line">will be ignored, which disables the delay scheduling.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.rack-locality-additional-delay&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;-1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Number of additional missed scheduling opportunities over the node-locality-delay</span><br><span class="line">ones, after which the CapacityScheduler attempts to schedule off-switch containers,</span><br><span class="line">instead of rack-local ones.</span><br><span class="line">Example: with node-locality-delay=40 and rack-locality-delay=20, the scheduler will</span><br><span class="line">attempt rack-local assignments after 40 missed opportunities, and off-switch assignments</span><br><span class="line">after 40+20=60 missed opportunities.</span><br><span class="line">When setting this parameter, the size of the cluster should be taken into account.</span><br><span class="line">We use -1 as the default value, which disables this feature. In this case, the number</span><br><span class="line">of missed opportunities for assigning off-switch containers is calculated based on</span><br><span class="line">the number of containers and unique locations specified in the resource request,</span><br><span class="line">as well as the size of the cluster.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.queue-mappings&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">A list of mappings that will be used to assign jobs to queues</span><br><span class="line">The syntax for this list is [u|g]:[name]:[queue_name][,next mapping]*</span><br><span class="line">Typically this list will be used to map users to queues,</span><br><span class="line">for example, u:%user:%user maps all users to queues with the same name</span><br><span class="line">as the user.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.queue-mappings-override.enable&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">If a queue mapping is present, will it override the value specified</span><br><span class="line">by the user? This can be used by administrators to place jobs in queues</span><br><span class="line">that are different than the one specified by the user.</span><br><span class="line">The default is false.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.per-node-heartbeat.maximum-offswitch-assignments&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Controls the number of OFF_SWITCH assignments allowed</span><br><span class="line">during a node&#x27;s heartbeat. Increasing this value can improve</span><br><span class="line">scheduling rate for OFF_SWITCH containers. Lower values reduce</span><br><span class="line">&quot;clumping&quot; of applications on particular nodes. The default is 1.</span><br><span class="line">Legal values are 1-MAX_INT. This config is refreshable.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.application.fail-fast&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">Whether RM should fail during recovery if previous applications&#x27;</span><br><span class="line">queue is no longer valid.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220212181909.png"></p><p>知识源于积累,登峰造极源于自律!</p><p>好文章就得收藏慢慢品, 文章转载于: <a href="https://blog.csdn.net/Yellow_python/article/details/116021592">https://blog.csdn.net/Yellow_python/article/details/116021592</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Hadoop版本：3.1.3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1、三种常见调度器
    1.1、先进先出调度器
    1.2、容量调度器
    1.3、公平调度器
2、容量调度器 多队列配置
3、单词
4、默认配置【capacity-scheduler.xml】
&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="hadoop" scheme="http://xubatian.cn/tags/hadoop/"/>
    
    <category term="yarn" scheme="http://xubatian.cn/tags/yarn/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之并行度（Parallelism）</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E5%B9%B6%E8%A1%8C%E5%BA%A6%EF%BC%88Parallelism%EF%BC%89/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E5%B9%B6%E8%A1%8C%E5%BA%A6%EF%BC%88Parallelism%EF%BC%89/</id>
    <published>2022-02-11T05:04:57.000Z</published>
    <updated>2022-02-11T05:13:29.938Z</updated>
    
    <content type="html"><![CDATA[<p>Flink程序的执行具有并行、分布式的特性。<br>在执行过程中，一个流（stream）包含一个或多个分区（stream partition），而每一个算子（operator）可以包含一个或多个子任务（operator subtask），这些子任务在不同的线程、不同的物理机或不同的容器中彼此互不依赖地执行。</p><pre><code>一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。streamEnv.setParallelism(1)//加在ENV上表示默认所有的算子平行度都是1</code></pre><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130627.png"></p><p>Stream在算子之间传输数据的形式可以是one-to-one(forwarding)的模式也可以是redistributing的模式，具体是哪一种形式，取决于算子的种类。</p><p>​        <strong>One-to-one</strong>：stream(比如在source和map operator之间)维护着分区以及元素的顺序。那意味着map 算子的子任务看到的元素的个数以及顺序跟source 算子的子任务生产的元素的个数、顺序相同，map、fliter、flatMap等算子都是one-to-one的对应关系。</p><p>​        <strong>类似于spark中的窄依赖</strong></p><p>​        <strong>Redistributing</strong>：stream(map()跟keyBy/window之间或者keyBy/window跟sink之间)的分区会发生改变。每一个算子的子任务依据所选择的transformation发送数据到不同的目标任务。例如，keyBy() 基于hashCode重分区、broadcast和rebalance会随机重新分区，这些算子都会引起redistribute(重新分配过程)过程，而redistribute过程就<strong>类似于Spark中的shuffle过程</strong>。</p><p>​        <strong>类似于spark中的宽依赖</strong></p><h2 id="博主解析"><a href="#博主解析" class="headerlink" title="博主解析:"></a>博主解析:</h2><p>​        <strong>并行度就是在执行过程中,尤其是我们Flink的Job执行过程中,一个流(Stream)包含一个或者多个分区.由于他包含一个或多个分区,从而就造成了一个算子他就包含一个或者多个子任务</strong>.实际上这流(Stream)和算子,这两个是因果关系.就因为你这流包含了一个或者两个或者多个分区.从而造成流所对应的算子就会出现一个或者多个子任务.这些子任务在不同的Slot上运行.而且也可能是不同的物理机.或者是不同的不同的容器,彼此之间相互互不依赖地执行.但是实际上他们有依赖关系吗?实际上他们也有依赖关系的.完全没有依赖关系是不可能的,因为我们还有一个数据的依赖.因为我们的数据一定是从上一个子任务到下一个子任务的.</p><p>​        一个特定的算子它到底有多少个子任务呢?就是由我们这个并行度来决定的.而并行度就是由我们parallelism来设置的.我们可以在代码的后面通过setParallelism()方法来设置并行度.也可以统一的在ENV,来设置算子的并行度.在ENV上设置算子的并行度就是所谓默认的.由于我们设置了并行度,所以就造成了两种情况.就是造成了我们的Stream和Stream之间有两种关系存在.</p><p>​        <strong>一种是One-to-one(一对一对应关系),还有一种就是Redistributing(重新分配)</strong></p><p>​        One-to-one:就是一个对应一个.什么情况下才是一个对应一个呢?</p><p>如图所示:</p><p>​        <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211131006.png"></p><p>​            <strong>Redistribute</strong>:重新分配的意思,实际上就是变了.本来可能是只有一个并行度,通过一个算子之后变成了两个或者三个等并行度了</p><p>如图所示:</p><p>​    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211131056.png"></p><h2 id="目前Flink的dataStream支持8种物理分区策略"><a href="#目前Flink的dataStream支持8种物理分区策略" class="headerlink" title="目前Flink的dataStream支持8种物理分区策略"></a>目前Flink的dataStream支持8种物理分区策略</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">①GlobalPartitioner(全局分区)： 数据会被分发到下游算子的第一个实例中进行处理。</span><br><span class="line">②ShufflePartitioner(shuffle分区) ：数据会被随机分发到下游算子的每一个实例中进行。</span><br><span class="line">③RebalancePartitioner(重新平衡分区)： 数据会被循环发送到下游的每一个实例中进行处理。</span><br><span class="line">④RescalePartitioner (重新调节分区)：这种分区器会根据上下游算子的并行度，循环的方式输出到下游算子的每个实例。这里有点难以理解，假设上游并行度为 2，编号为 A 和 B。下游并行度为 4，编号为 1，2，3，4。那么 A 则把数据循环发送给 1 和 2，B 则把数据循环发送给 3 和 4。假设上游并行度为 4，编号为 A，B，C，D。下游并行度为 2，编号为 1，2。那么 A 和 B 则把数据发送给 1，C 和 D 则把数据发送给 2。</span><br><span class="line">⑤BroadcastPartitioner (广播分区) ：广播分区会将上游数据输出到下游算子的每个实例中。适合于大数据集和小数据集做Jion的场景。</span><br><span class="line">⑥ForwardPartitioner (forward分区)：用于将记录输出到下游本地的算子实例。它要求上下游算子并行度一样。简单的说，ForwardPartitioner用来做数据的控制台打印。</span><br><span class="line">⑦KeyGroupStreamPartitioner ：Hash 分区器。会将数据按Key的Hash值输出到下游算子实例中。​​​​</span><br><span class="line">⑧CustomPartitionerWrapper：用户自定义分区器。需要用户自己实现 Partitioner 接口，来定义自己的分区逻辑。</span><br><span class="line">static class CustomPartitioner implements Partitioner&lt;String&gt; &#123; </span><br><span class="line">    @Override </span><br><span class="line">    public int partition(String key, int numPartitions) &#123; </span><br><span class="line">        switch (key)&#123; </span><br><span class="line">            case &quot;1&quot;: return 1;</span><br><span class="line">            case &quot;2&quot;: return 2;</span><br><span class="line">            case &quot;3&quot;: return 3;</span><br><span class="line">            default : return 4;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211131134.png"></p><h2 id="Flink8种传输数据操作"><a href="#Flink8种传输数据操作" class="headerlink" title="Flink8种传输数据操作"></a>Flink8种传输数据操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">KeyBy: 按照key的hash值分区, 相同的key一定会分到相同的分区.即相同的key进入相同的并行度,也就是说进入同一个子任务.</span><br><span class="line">Shuffle: 随机分的.</span><br><span class="line">Rebalance: 全局轮询,即上游的所有并行度都对下游所有并行度轮询.</span><br><span class="line">Rescale: 局部轮询,也就是说上游两个,下游四个.我上游两个在两个里面轮询了,一个人在两个里面轮询.</span><br><span class="line">Global: 所有数据发送到下游同一个并行度.</span><br><span class="line">Broadcast:所有数据发送到下游所有并行度.</span><br><span class="line">Forward:要求并行度相同,因为他是一对一的.</span><br><span class="line">Customer: 自定义.</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211131309.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink程序的执行具有并行、分布式的特性。&lt;br&gt;在执行过程中，一个流（stream）包含一个或多个分区（stream partition），而每一个算子（operator）可以包含一个或多个子任务（operator subtask），这些子任务在不同的线程、不同的物理机或不同的容器中彼此互不依赖地执行。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。
streamEnv.setParallelism(1)//加在ENV上表示默认所有的算子平行度都是1
&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之执行图（ExecutionGraph）</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E6%89%A7%E8%A1%8C%E5%9B%BE%EF%BC%88ExecutionGraph%EF%BC%89/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E6%89%A7%E8%A1%8C%E5%9B%BE%EF%BC%88ExecutionGraph%EF%BC%89/</id>
    <published>2022-02-11T04:56:45.000Z</published>
    <updated>2022-02-11T05:03:45.814Z</updated>
    
    <content type="html"><![CDATA[<p>​        由Flink程序直接映射成的数据流图是StreamGraph，也被称为逻辑流图，因为它们表示的是计算逻辑的高级视图。为了执行一个流处理程序，Flink需要将逻辑流图转换为物理数据流图（也叫执行图），详细说明程序的执行方式。</p><p>​        <strong>Flink 中的执行图可以分成四层：StreamGraph(数据流图) -&gt; JobGraph(工作图) -&gt; ExecutionGraph (执行图)-&gt; 物理执行图。</strong></p><p>​        </p><p>​        <strong>StreamGraph</strong>：(数据流图)是根据用户通过 Stream API 编写的代码生成的最初的图。用来表示程序的拓扑结构有效。</p><p>​        <strong>JobGraph</strong>：StreamGraph经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。</p><p>​        <strong>ExecutionGraph</strong>：JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。</p><p>​        <strong>物理执行图</strong>：JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构</p><span id="more"></span><h2 id="四个流图的转换过程"><a href="#四个流图的转换过程" class="headerlink" title="四个流图的转换过程"></a>四个流图的转换过程</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130057.png"></p><p>​        StreamGraph称之为数据流图,数据流图是根据用户通过API的编程,尤其是通过dataStream API的编程,编程就是你写好的代码.就是根据你写好的代码来生成一个最初的图,这个图用来描述你代码或者说你程序的拓扑结构,这样的图就称之为StreamGraph(数据流图)</p><p>​        举例:如图所示:</p><p>​        <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130206.png"></p><p>​        假设我写的代码里面第一个写的是Source读数据,读完数据之后调用FlatMap,接下来调用第三个Map算子;这些完全是根据自己的代码而定的.我这里先不管代码中我Map算子设置的并行度是几或者我的FlatMap中设置的并行度是几.我就把我写好的代码根据算子调用的顺序得到上面这张图,这张图就称之为数据流图.这张数据流图就是用来展示你写的代码的拓扑结构.这张数据流图是我们看不到的,因为Web-UI界面是不会给我展示这张图的.当然,自己写代码的人自己心里面是有这样图的.然后根据我的数据流图,优化之后的到一个JobGraph,这个我们称之为工作图.</p><p>​        JobGraph是什么意思呢?</p><p>​        他实际上是将前面的StreamGraph(数据流图)进行优化,优化之后呢.他会把多个符合条件的节点,通过operatorChain(任务链)连在一起.他时通过任务链把多个符合条件的节点连在一起.如下图所示:</p><p>​    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130241.png"></p><p>​            上面两个图都是在客户端完成的,客户端完成之后就要开始要提交了.客户端提交给JobManager,JobManager在接收到你提交过来的Job之后,他首先会根据你提交过来的图,将这个图变成执行图.执行图里面有什么特点呢?</p><p>​            他是根据你这个执行图看看你有几个管道,找到你有几个管道,每个管道之间的数据通信是什么样子的.这就是所谓的执行图.变成执行图之后,每个管道还要得到不同的任务,因为你已经得到管道了,得到管道之后你就可以得到各个不同的任务.这个每个任务在哪个Slot上运行.后面这个图就叫物理执行图了.因为物理执行图就是实施去哪个TaskManager上的Slot去运行的.所以这四个图是这么来的.</p><pre><code>    Flink 中的执行图可以分成四层：    StreamGraph(数据流图) -&gt; JobGraph(工作图) -&gt; ExecutionGraph (执行图)-&gt; 物理执行图</code></pre><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211130331.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;​        由Flink程序直接映射成的数据流图是StreamGraph，也被称为逻辑流图，因为它们表示的是计算逻辑的高级视图。为了执行一个流处理程序，Flink需要将逻辑流图转换为物理数据流图（也叫执行图），详细说明程序的执行方式。&lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;Flink 中的执行图可以分成四层：StreamGraph(数据流图) -&amp;gt; JobGraph(工作图) -&amp;gt; ExecutionGraph (执行图)-&amp;gt; 物理执行图。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​        &lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;StreamGraph&lt;/strong&gt;：(数据流图)是根据用户通过 Stream API 编写的代码生成的最初的图。用来表示程序的拓扑结构有效。&lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;JobGraph&lt;/strong&gt;：StreamGraph经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。&lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;ExecutionGraph&lt;/strong&gt;：JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。&lt;/p&gt;
&lt;p&gt;​        &lt;strong&gt;物理执行图&lt;/strong&gt;：JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之TaskManger与Slots</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8BTaskManger%E4%B8%8ESlots/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8BTaskManger%E4%B8%8ESlots/</id>
    <published>2022-02-11T04:45:08.000Z</published>
    <updated>2022-02-11T04:50:06.695Z</updated>
    
    <content type="html"><![CDATA[<p>​        在Flink job的运行过程中,Flink Job中每一个worker(TaskManager)都是一个JVM进程，它可能会在独立的Slot(线程)上执行一个或多个subtask(子任务)。为了控制一个worker能接收多少个task，worker通过task slot来进行控制（一个worker至少有一个task slot）。</p><p>​        每个task slot表示TaskManager拥有资源的一个固定大小的子集。假如一个TaskManager有三个slot，那么它会将其管理的内存分成三份给各个slot。资源slot化意味着一个subtask将不需要跟来自其他job的subtask竞争被管理的内存，取而代之的是它将拥有一定数量的内存储备。需要注意的是，这里不会涉及到CPU的隔离，slot目前仅仅用来隔离task的受管理的内存。</p><p>​        通过调整task slot的数量，允许用户定义subtask之间如何互相隔离。如果一个TaskManager一个slot，那将意味着每个task group运行在独立的JVM中（该JVM可能是通过一个特定的容器启动的），而一个TaskManager多个slot意味着更多的subtask可以共享同一个JVM。而在同一个JVM进程中的task将共享TCP连接（基于多路复用）和心跳消息。它们也可能共享数据集和数据结构，因此这减少了每个task的负载。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124632.png"></p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124731.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124817.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124840.png"></p><p>默认情况下，Flink允许子任务共享slot，即使它们是不同任务的子任务（前提是它们来自同一个job）。 这样的结果是，一个slot可以保存作业的整个管道。<br><strong>Task Slot是静态的概念，是指TaskManager具有的并发执行能力</strong>，可以通过参数taskmanager.numberOfTaskSlots进行配置；<strong>而并行度parallelism是动态概念</strong>，即TaskManager运行程序时实际使用的并发能力，可以通过参数parallelism.default进行配置。<br>也就是说，假设一共有3个TaskManager，每一个TaskManager中的分配3个TaskSlot，也就是每个TaskManager可以接收3个task，一共9个TaskSlot，如果我们设置parallelism.default=1，即运行程序默认的并行度为1，9个TaskSlot只用了1个，有8个空闲，因此，设置合适的并行度才能提高效率。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124935.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124954.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;​        在Flink job的运行过程中,Flink Job中每一个worker(TaskManager)都是一个JVM进程，它可能会在独立的Slot(线程)上执行一个或多个subtask(子任务)。为了控制一个worker能接收多少个task，worker通过task slot来进行控制（一个worker至少有一个task slot）。&lt;/p&gt;
&lt;p&gt;​        每个task slot表示TaskManager拥有资源的一个固定大小的子集。假如一个TaskManager有三个slot，那么它会将其管理的内存分成三份给各个slot。资源slot化意味着一个subtask将不需要跟来自其他job的subtask竞争被管理的内存，取而代之的是它将拥有一定数量的内存储备。需要注意的是，这里不会涉及到CPU的隔离，slot目前仅仅用来隔离task的受管理的内存。&lt;/p&gt;
&lt;p&gt;​        通过调整task slot的数量，允许用户定义subtask之间如何互相隔离。如果一个TaskManager一个slot，那将意味着每个task group运行在独立的JVM中（该JVM可能是通过一个特定的容器启动的），而一个TaskManager多个slot意味着更多的subtask可以共享同一个JVM。而在同一个JVM进程中的task将共享TCP连接（基于多路复用）和心跳消息。它们也可能共享数据集和数据结构，因此这减少了每个task的负载。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211124632.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink任务调度原理概念</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%E6%A6%82%E5%BF%B5/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%E6%A6%82%E5%BF%B5/</id>
    <published>2022-02-11T04:33:07.000Z</published>
    <updated>2022-02-11T04:36:00.355Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211123327.png"></p><span id="more"></span><p>​        客户端不是运行时和程序执行的一部分，但它用于准备并发送dataflow(JobGraph)给Master(JobManager)，然后，客户端断开连接或者维持连接以等待接收计算结果。</p><p>​        当 Flink 集群启动后，首先会启动一个 JobManger 和一个或多个的 TaskManager。由 Client 提交任务给 JobManager，JobManager 再调度任务到各个 TaskManager 去执行，然后 TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述三者均为独立的 JVM 进程.</p><p>​        <strong>Client</strong> 为提交 Job 的客户端，可以是运行在任何机器上（与 JobManager 环境连通即可）。提交 Job 后，Client 可以结束进程（Streaming的任务），也可以不结束并等待结果返回。</p><p>​        <strong>JobManager</strong> 主要负责调度 Job 并协调 Task 做 checkpoint，职责上很像 Storm 的 Nimbus。从 Client 处接收到 Job 和 JAR 包等资源后，会生成优化后的执行计划，并以 Task 的单元调度到各个 TaskManager 去执行。</p><p>​        <strong>TaskManager</strong> 在启动的时候就设置好了槽位数（Slot），每个 slot 能启动一个 Task，Task 为线程。从 JobManager 处接收需要部署的 Task，部署启动后，与自己的上游建立 Netty 连接，接收数据并处理。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211123327.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink任务提交流程</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/</id>
    <published>2022-02-11T04:27:14.000Z</published>
    <updated>2022-02-11T04:33:57.133Z</updated>
    
    <content type="html"><![CDATA[<p>当一个应用提交执行时，Flink的各个组件是如何交互协作的?</p><p>任务提交和组件交互流程图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211122757.png"></p><span id="more"></span><p>上图是从一个较为高层级的视角，来看应用中各组件的交互协作。如果部署的集群环境不同（例如YARN，Mesos，Kubernetes，standalone等），其中一些步骤可以被省略，或是有些组件会运行在同一个JVM进程中。</p><p>具体地，如果我们将Flink集群部署到YARN上，那么就会有如下的提交流程(Yarn模式任务提交流程图)：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211122847.png"></p><p>Flink任务提交后，Client向HDFS上传Flink的Jar包和配置，之后向Yarn ResourceManager提交任务，ResourceManager分配Container资源并通知对应的NodeManager启动ApplicationMaster，ApplicationMaster启动后加载Flink的Jar包和配置构建环境，然后启动JobManager，之后ApplicationMaster向ResourceManager申请资源启动TaskManager，ResourceManager分配Container资源后，由ApplicationMaster通知资源所在节点的NodeManager启动TaskManager，NodeManager加载Flink的Jar包和配置构建环境并启动TaskManager，TaskManager启动后向JobManager发送心跳包，并等待JobManager向其分配任务.</p><h2 id="博主解析任务提交流程"><a href="#博主解析任务提交流程" class="headerlink" title="博主解析任务提交流程:"></a>博主解析任务提交流程:</h2><p>这个提交流程就是我写好的一个Flink的job或者写好的一个Flink的程序program.现在我要提交到Flink集群中去运行了.提交有两种提交方式:<br>第一种是通过Web-UI进行提交,这个很秀,因为spark就没有这个功能,Web-UI中首先上传了一个jar包,然后在jar包中指定我要运行那个主类,传什么样的参数,等等,然后点击提交(Submit).一点击提交,就会把我们的Application或者说我们的Flink Job提交给JobManager了.JobManager马上去ResourceManager中申请资源即去ResourceManager中申请Slot.假设我只需要三个Slot就ok了,这个时候他就找到一个对应的TaskManager,因为我们一个TaskManager默认情况下我们设置的是三个Slot.(当然这三个是我们设置的,原始的配置文件默认只有一个;当然在真正生产环境下不可能一个TaskManager只有一个Slot的,至少是三的几倍).启动相应的TaskManager,然后开始注册我们的Slot,注册Slot就表示我这个Slot开始要运行了,然后发出提供Slot的指令,然后开始提供Slot来运行.真正我们的Task是在Slot中运行的,运行的时候他还会把运行的状态信息提供给TaskManager和JobManager.如果有多个TaskManager,在TaskManager之间他是可以交换数据的.为什么可以交换数据呢?为什么TaskManager之间可以交换数据呢?如果有多个TaskManager的话,TaskManager之间是可以交换数据的.不单单是多个TaskManager,你如果是一个TaskManager和多个Slot之间也是可以交换数据的.为什么呢?<br>因为假设其中一个Slot运行一个Source    ,source运行完成之后把数据要给谁呢?是要把数据给转换算子,这个转换算子有可能在另外一个Slot中.那么数据是不是就得给他呢.<br>那么,有没有一种可能就是,你的转换算子的任务是运行在另外一个TaskManager上的Slot中,那我是不是需要把数据给他呢. 当然,这就属于跨机器了.所以要交换数据.<br>当然,这些都是属于站在上帝的视角看的.</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211123026.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211123052.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;当一个应用提交执行时，Flink的各个组件是如何交互协作的?&lt;/p&gt;
&lt;p&gt;任务提交和组件交互流程图:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220211122757.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink运行时的组件</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9A%84%E7%BB%84%E4%BB%B6/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9A%84%E7%BB%84%E4%BB%B6/</id>
    <published>2022-02-11T04:20:15.000Z</published>
    <updated>2022-02-11T04:33:53.821Z</updated>
    
    <content type="html"><![CDATA[<p>Flink运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作：作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager），以及分发器（Dispatcher）。因为Flink是用Java和Scala实现的，所以所有组件都会运行在Java虚拟机上。每个组件的职责如下</p><span id="more"></span><h2 id="作业管理器（JobManager）"><a href="#作业管理器（JobManager）" class="headerlink" title="作业管理器（JobManager）"></a>作业管理器（JobManager）</h2><p>控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager所控制执行。JobManager会先接收到要执行的应用程序，这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的JAR包。JobManager会把JobGraph转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。JobManager会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上。而在运行过程中，JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</p><h3 id="博主解析"><a href="#博主解析" class="headerlink" title="博主解析:"></a>博主解析:</h3><p>JobManager是控制整个Flink Job运行的,所谓的控制就是,<br>①他负责监控②他负责Slot的分配或者Slot的调度.<br>这个Task在哪个Slot上运行,他给你分配好,这就是所谓的控制,JobManager就一句话,就是用来控制Flink Job的主进程的运行.<br>什么叫控制?控制的意思就是说你整个Job分成好几个任务,那么我这几个任务我需要把他分配到哪些Task Manager的哪些Slot上,这个Slot就表示资源的意思,同时还负责监控</p><h2 id="资源管理器（ResourceManager）"><a href="#资源管理器（ResourceManager）" class="headerlink" title="资源管理器（ResourceManager）"></a>资源管理器（ResourceManager）</h2><p>主要负责管理任务管理器（TaskManager）的插槽（slot），TaskManger插槽是Flink中定义的处理资源单元。Flink为不同的环境和资源管理工具提供了不同资源管理器，比如YARN、Mesos、K8s，以及standalone部署。当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager分配给JobManager。如果ResourceManager没有足够的插槽来满足JobManager的请求，它还可以向资源提供平台发起会话，以提供启动TaskManager进程的容器。另外，ResourceManager还负责终止空闲的TaskManager，释放计算资源。</p><h3 id="博主解析-1"><a href="#博主解析-1" class="headerlink" title="博主解析:"></a>博主解析:</h3><p>ResourceManager如果是yarn模式的话,这个在hadoop就讲过了.但是如果是Standalone模式的话.这个ResourceManager实际上就和我们的JobManager在一个进程里面,这点需要注意.<br>但是如果是yarn模式的话,ResourceManager是独立的,是yarn里面的主节点,主要负责资源的管理,管理所有Task Manager上的Slot.<br>这里面有个迷糊的地方,这个ResourceManager早就在hadoop上学过了,但是为什么说他是管理所以Task Manager的Slot呢?问题是,你这个Task Manager是属于你的Flink的.原来我们学Hadoop的时候说的是,ResourceManager是管理NodeManager上的资源的.可是,现在我们又说是管理Task Manager上的资源.这两句话难道是一样的吗?其实,这两句话本质上是一样的.为什么呢?因为,请问,在yarn模式下,这个TaskManager这个节点会运行在哪些节点上呢?是运行在NodeManager节点上呢?还是在ResourceManager节点上?还是运行在与NodeManager和ResourceManager都没关系的其他节点上呢?其实,他一定是运行在NodeManager上,并且他只能运行在NodeManager上,他是在NodeManager上去启动TaskManager.那如果是这样的话.你在NodeManager上启动TaskManager的话,你不就是申请NodeManager上的资源嘛.申请了NodeManager上的资源你才能够启动对应的TaskManager.所以说,我们之前学的ResourceManager就是来管理和分配NodeManager上的资源的.这句话是对的.由于你NodeManager上有资源,所以他可以在某一个NodoManager上去启动Flink Job需要运行的TaskManager.假设在hadoop102上的NodeManager上启动了一个TaskManager,他之所以能够启动,一定是他有空余的资源才能够启动.假设他有空余一个G的资源,那启动了一个TaskManager.(为什么这里说是一个G呢?因为我们配置文件中指定了默认情况下TaskManager占用内存是一个G,所以这和Flink的配置文件是关联起来的).所以,假设是启动一个G,这一个G是给TaskManager用的,并且你指定了TaskManager上的Slot数量是3,那么他会把这一个G的资源均匀的切成三份,分给这三个Slot.由于在我们Flink这个框架里面,我们的资源是在TaskManager上的Slot的,所以我们也可以用另外一句话来描述,就是说,我们ResourceManager来负责管理和分配TaskManager上的Slot.</p><h2 id="任务管理器（TaskManager）"><a href="#任务管理器（TaskManager）" class="headerlink" title="任务管理器（TaskManager）"></a>任务管理器（TaskManager）</h2><p>Flink中的工作进程。通常在Flink中会有多个TaskManager运行，每一个TaskManager都包含了一定数量的插槽（slots）。插槽的数量限制了TaskManager能够执行的任务数量。启动之后，TaskManager会向资源管理器(ResourceManager)注册它的插槽；收到资源管理器的指令后，TaskManager就会将一个或者多个插槽提供给JobManager调用。JobManager就可以向插槽分配任务（tasks）来执行了。在执行过程中，一个TaskManager可以跟其它运行同一应用程序的TaskManager交换数据。</p><h3 id="博主解析-2"><a href="#博主解析-2" class="headerlink" title="博主解析:"></a>博主解析:</h3><p>TaskManager是在Flink job运行过程中,是他的工作进程.TaskManager一定是一个进程.每一个TaskManager包含一定数量的Slot.这个Slot的数量就限制了你这个TaskManager的并行执行任务的数量.<br>那Slot的数量是在哪里设置的呢? 就是在你的配置文件中设置的.也可以在命令中设置.这个命令是yarn-session -s…略…(这个-s 里面就是你的Slot数量)<br>上面详细说过,这Slot是共享整个TaskManager上的内存资源的.如果你这个TaskManager是一个G,那么我三个Slot都共享这一个G.<br>还有一点就是,在yarn模式下,这个TaskManager是在你的Flink Job 提交之后,根据你这个Job的资源的需求情况来启动这个TaskManager的.当前,前提条件是基于你的yarn模式,不是基于standalone模式的.<br>所以,这个TaskManager在yarn模式中是这样的.就是你这Job一提交,ResourceManager根据你提交的Job运行时候的执行图,确定你需要多少Slot.假设你需要三个Slot,ResourceManager发现你需要三个Slot,那ResourceManager就只需要启动一个TaskManager就可以了.因为一个TaskManager上就有三个Slot(配置文件上指定的),够用了.尽管其他的NodeManager上也可以启动TaskManager,但是这就没必要启动了.这就是Flink的特点.Flink和MapReduce和Spark不一样.他不是在Job没提交之前就将所有改启动的都先启动了.因为这样有些东西的浪费的.比如Work进程里面的executor,他尽管没有运行executor,他也运行在哪里,这就很浪费.<br>所以,当假设你需要三个Slot,那我就给你启动一个TaskManager,这时候你肯定还有其他空闲的资源,这时候,我用户还可以提交一个新的Flink Job进来.新的Flink job也是一样,ResourceManager根据你这个新的Flink job运行的资源,需求情况,又给你去启动对应的TaskManager.<br>新问题: 假设我写的task任务(即task job)运行的时候需要的Slot比较多.我需要九个Slot.如果你资源有的情况下,他一定会给你启动三个TaskManager.反正他启动的TaskManager一定是够你这个task Job用的.除非我ResourceManager所管理的资源已经没有了,那就没办法了,只能等待.因为他已经没有资源给你运行了</p><h2 id="分发器（Dispatcher）"><a href="#分发器（Dispatcher）" class="headerlink" title="分发器（Dispatcher）"></a>分发器（Dispatcher）</h2><p>可以跨作业运行，它为应用提交提供了REST接口。当一个应用被提交执行时，分发器就会启动并将应用移交给一个JobManager。由于是REST接口，所以Dispatcher可以作为集群的一个HTTP接入点，这样就能够不受防火墙阻挡。Dispatcher也会启动一个Web UI，用来方便地展示和监控作业执行的信息。Dispatcher在架构中可能并不是必需的，这取决于应用提交运行的方式。</p><h3 id="博主解析-3"><a href="#博主解析-3" class="headerlink" title="博主解析:"></a>博主解析:</h3><p>什么是分发器呢?如果我通过谷歌访问Flink的web-UI界面,访问的端口号是默认的是8081,这个就是Dispatcher(分发器).<br>在Flink自带的standalone模式下也是有Dispatcher(分发器)的.在Yarn模式下也是有的.那个Dispatcher是在哪里呢?其实他是在JobManager里面的.<br>实际上,在实际操作中我们先打开了8088这个hadoop的yarn的页面,在8088这个页面看到了Application,Application这一行的最右面有一个ApplicationMaster的超链接,点击这个ApplicationMaster就打开了我们的Dispatcher(分发器)了.<br>所以Dispatcher实际上就是给我们提供的一个restful的一个接口.restful接口实际上就是可以通过HTTP来接入的.<br>要知道,在standalone和yarn模式下都有Dispatcher的.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作：作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager），以及分发器（Dispatcher）。因为Flink是用Java和Scala实现的，所以所有组件都会运行在Java虚拟机上。每个组件的职责如下&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之任务链</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E4%BB%BB%E5%8A%A1%E9%93%BE/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E4%BB%BB%E5%8A%A1%E9%93%BE/</id>
    <published>2022-02-10T14:15:46.000Z</published>
    <updated>2022-02-12T09:30:30.801Z</updated>
    
    <content type="html"><![CDATA[<h3 id="好记性-烂笔头"><a href="#好记性-烂笔头" class="headerlink" title="好记性,烂笔头:"></a>好记性,烂笔头:</h3><p>①socket不能多并行度消费. 而kafka是可以多并行度消费的. kafka有多个分区.   </p><p>②keyby不是一个算子,他是决定我们的数据进入到下游的哪一个并行度里面的.他自己没有并行度的.他不会对数据做任何的操作.数据可能从一个并行度来的. 进过keyby之后,可能把他发到好多个并行度里面去了.</p><p>8种数据传输的方式:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">KeyBy: 按照key的hash值分区, 相同的key一定会分到相同的分区.即相同的key进入相同的并行度,也就是说进入同一个子任务.</span><br><span class="line">Shuffle: 随机分的.</span><br><span class="line">Rebalance: 全局轮询,即上游的所有并行度都对下游所有并行度轮询.</span><br><span class="line">Rescale: 局部轮询,也就是说上游两个,下游四个.我上游两个在两个里面轮询了,一个人在两个里面轮询.</span><br><span class="line">Global: 所有数据发送到下游同一个并行度.</span><br><span class="line">Broadcast:所有数据发送到下游所有并行度.</span><br><span class="line">Forward:要求并行度相同,因为他是一对一的.</span><br><span class="line">Customer: 自定义.</span><br></pre></td></tr></table></figure><span id="more"></span><h3 id="正文"><a href="#正文" class="headerlink" title="正文:"></a>正文:</h3><p>任务链的意思就是说,我们把两个算子按照一定的条件连接在一起.形成一个统一的Task<br>这就是所谓的任务链.并且我们可以在图上可以看到,如下图所示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210221830.png"></p><p>任务链可以当做Spark中的stage理解. 但是他比stage灵活. spark中根据宽依赖划分stage. 所以Flink保留此特点. 如果你是重分区的操作.他就一定会划分到两个不同的任务链里面来. 除此之外Flink的任务链还要看并行度. </p><p>这个任务链有一定的条件,首先他们的<strong>①并行度要相同</strong>.所谓的并行度相同就是One-to-one,One-to-one不是说他们只有一个,而是指他们的并行度相同.第二个条件就是他们<strong>②中间没有shuffle</strong>.中间没有shuffle才会通过任务链把他们合在一起.这个任务链不用我们去做的.不过呢,我们可以设置让所有的算子之间完全隔离.就算你有条件来通过这个任务链来进行合并,我们也不让你构建一个任务链.我们只要加一个disableOperatorChaining(禁用这个任务链),禁用这个任务链之后,就算你符合条件,他也不把你这两个task链在一起,形成一个统一的Task.<br>但是这两种那个更好呢?<strong>当然是有任务链的更好.有任务链可以提高吞吐,减少IO操作</strong>.<br>所以,大多数情况下,我这一行代码(streamEnv.disableOperatorChaining)不应该做.</p><p><strong>③共享组不同也不能形成任务链</strong> 共享组的作用就是把同一个任务放在同一个slot里面</p><p>相同并行度的one to one操作，Flink这样相连的算子链接在一起形成一个task，原来的算子成为里面的一部分。将算子链接成task是非常有效的优化：它能减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。链接的行为可以在编程API中进行指定。<br>streamEnv.disableOperatorChaining:表示所有操作算子都不构建任务链<br>.disableChaining() 加在其中一个算子中，表示：该算子和其他算子不一起构建任务链。它是独立的</p><p>图 task与operator chains:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210222115.png"></p><p>任务链案例代码地址:</p><p><a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo02/Flink01_WordCount_Chain.java">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo02/Flink01_WordCount_Chain.java</a></p><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-11_12-04-16.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;好记性-烂笔头&quot;&gt;&lt;a href=&quot;#好记性-烂笔头&quot; class=&quot;headerlink&quot; title=&quot;好记性,烂笔头:&quot;&gt;&lt;/a&gt;好记性,烂笔头:&lt;/h3&gt;&lt;p&gt;①socket不能多并行度消费. 而kafka是可以多并行度消费的. kafka有多个分区.   &lt;/p&gt;
&lt;p&gt;②keyby不是一个算子,他是决定我们的数据进入到下游的哪一个并行度里面的.他自己没有并行度的.他不会对数据做任何的操作.数据可能从一个并行度来的. 进过keyby之后,可能把他发到好多个并行度里面去了.&lt;/p&gt;
&lt;p&gt;8种数据传输的方式:&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;KeyBy: 按照key的hash值分区, 相同的key一定会分到相同的分区.即相同的key进入相同的并行度,也就是说进入同一个子任务.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Shuffle: 随机分的.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Rebalance: 全局轮询,即上游的所有并行度都对下游所有并行度轮询.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Rescale: 局部轮询,也就是说上游两个,下游四个.我上游两个在两个里面轮询了,一个人在两个里面轮询.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Global: 所有数据发送到下游同一个并行度.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Broadcast:所有数据发送到下游所有并行度.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Forward:要求并行度相同,因为他是一对一的.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Customer: 自定义.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink总结速览</title>
    <link href="http://xubatian.cn/Flink%E6%80%BB%E7%BB%93%E9%80%9F%E8%A7%88/"/>
    <id>http://xubatian.cn/Flink%E6%80%BB%E7%BB%93%E9%80%9F%E8%A7%88/</id>
    <published>2022-02-10T06:11:48.000Z</published>
    <updated>2022-02-10T06:40:53.045Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Flink-核心特点"><a href="#Flink-核心特点" class="headerlink" title="Flink 核心特点"></a>Flink 核心特点</h3><h4 id="批流一体"><a href="#批流一体" class="headerlink" title="批流一体"></a>批流一体</h4><p>所有的数据都天然带有时间的概念，必然发生在某一个时间点。把事件按照时间顺序排列起来，就形成了一个事件流，也叫作数据流。<strong>「无界数据」</strong>是持续产生的数据，所以必须持续地处理无界数据流。<strong>「有界数据」</strong>，就是在一个确定的时间范围内的数据流，有开始有结束，一旦确定了就不会再改变。</p><span id="more"></span><h4 id="可靠的容错能力"><a href="#可靠的容错能力" class="headerlink" title="可靠的容错能力"></a>可靠的容错能力</h4><ul><li><p>集群级容错</p></li><li><ul><li>集群管理器集成（Hadoop YARN、Mesos或Kubernetes）</li><li>高可用性设置（HA模式基于ApacheZooKeeper）</li></ul></li><li><p>应用级容错（ Checkpoint）</p></li><li><ul><li>一致性（其本身支持Exactly-Once 语义）</li><li>轻量级（检查点的执行异步和增量检查点）</li></ul></li><li><p>高吞吐、低延迟</p></li></ul><h4 id="运行时架构"><a href="#运行时架构" class="headerlink" title="运行时架构"></a>运行时架构</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141319.png"></p><ul><li><p>Flink 客户端</p></li><li><ul><li>提交Flink作业到Flink集群</li><li>Stream Graph 和 Job Graph构建</li></ul></li><li><p>JobManager</p></li><li><ul><li>资源申请</li><li>任务调度</li><li>应用容错</li></ul></li><li><p>TaskManager</p></li><li><ul><li>接收JobManager 分发的子任务，管理子任务</li><li>任务处理（消费数据、处理数据）</li></ul></li></ul><h2 id="Flink-应用"><a href="#Flink-应用" class="headerlink" title="Flink 应用"></a>Flink 应用</h2><h4 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h4><h5 id="DataStream-体系"><a href="#DataStream-体系" class="headerlink" title="DataStream 体系"></a>DataStream 体系</h5><ol><li><p>DataStream(每个DataStream都有一个Transformation对象)</p></li><li><p>DataStreamSource（DataStream的起点）</p></li><li><p>DataStreamSink（DataStream的输出）</p></li><li><p>KeyedStream（表示根据指定的Key记性分组的数据流）</p></li><li><p>WindowdeStream &amp; AllWindowedStream（根据key分组且基于WindowAssigner切分窗口的数据流）</p></li><li><p>JoinedStreams &amp; CoGroupedStreams</p></li><li><ol><li>JoinedStreams底层使用CoGroupedStreams来实现</li><li>CoGrouped侧重的是Group，对数据进行分组，是对同一个key上的两组集合进行操作</li><li>Join侧重的是数据对，对同一个key的每一对元素进行操作</li></ol></li><li><p>ConnectedStreams（表示两个数据流的组合）</p></li><li><p>BroadcastStream &amp; BroadcastConnectedStream（DataStream的广播行为）</p></li><li><p>IterativeStream（包含IterativeStream的Dataflow是一个有向有环图）</p></li><li><p>AsyncDataStream（在DataStream上使用异步函数的能力）</p></li></ol><h5 id="处理数据API"><a href="#处理数据API" class="headerlink" title="处理数据API"></a>处理数据API</h5><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141359.png"></p><h2 id="核心抽象"><a href="#核心抽象" class="headerlink" title="核心抽象"></a>核心抽象</h2><h3 id="环境对象"><a href="#环境对象" class="headerlink" title="环境对象"></a>环境对象</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141427.png"></p><h3 id="数据流元素"><a href="#数据流元素" class="headerlink" title="数据流元素"></a>数据流元素</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141448.png"></p><ol><li><p>StreamRecord（数据流中的一条记录｜事件）</p></li><li><ol><li>数据的值本身</li><li>时间戳（可选）</li></ol></li><li><p>LatencyMarker（用来近似评估延迟）</p></li><li><ol><li>周期性的在数据源算子中创造出来的时间戳</li><li>算子编号</li><li>数据源所在的Task编号</li></ol></li><li><p>Watemark（是一个时间戳，用来告诉算子所有时间早于等于Watermark的事件或记录都已经到达，不会再有比Watermark更早的记录，算子可以根据Watermark触发窗口的计算、清理资源等）</p></li><li><p>StreamStatus（用来通知Task是否会继续接收到上游的记录或者Watermark）</p></li><li><ol><li>空闲状态（IDLE）。</li><li>活动状态（ACTIVE）。</li></ol></li></ol><h3 id="Flink-异步IO"><a href="#Flink-异步IO" class="headerlink" title="Flink 异步IO"></a>Flink 异步IO</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141557.png"></p><p>顺序输出模式（先收到的数据元素先输出，后续数据元素的异步函数调用无论是否先完成，都需要等待）</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141620.png"></p><p>无序输出模式（先处理完的数据元素先输出，不保证消息顺序）</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141640.png"></p><h3 id="数据分区"><a href="#数据分区" class="headerlink" title="数据分区"></a>数据分区</h3><ul><li>ForwardPartitioner（用于在同一个OperatorChain中上下游算子之间的数据转发，实际上数据是直接传递给下游的）</li><li>ShufflePartitioner（随机将元素进行分区，可以确保下游的Task能够均匀地获得数据）</li><li>ReblancePartitioner（以Round-robin的方式为每个元素分配分区，确保下游的Task可以均匀地获得数据，避免数据倾斜）</li><li>RescalingPartitioner（用Round-robin选择下游的一个Task进行数据分区，如上游有2个Source，下游有6个Map，那么每个Source会分配3个固定的下游Map，不会向未分配给自己的分区写入数据）</li><li>BroadcastPartitioner（将该记录广播给所有分区）</li><li>KeyGroupStreamPartitioner（KeyedStream根据KeyGroup索引编号进行分区，该分区器不是提供给用户来用的）</li></ul><h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141709.png"></p><ul><li><p>WindowAssigner（用来决定某个元素被分配到哪个/哪些窗口中去）</p></li><li><p>WindowTrigger（决定一个窗口何时能够呗计算或清除，每一个窗口都拥有一个属于自己的Trigger）</p></li><li><p>WindowEvictor（窗口数据的过滤器，可在Window Function 执行前或后，从Window中过滤元素）</p></li><li><ul><li>CountEvictor：计数过滤器。在Window中保留指定数量的元素，并从窗口头部开始丢弃其余元素</li><li>DeltaEvictor：阈值过滤器。丢弃超过阈值的数据记录</li><li>TimeEvictor：时间过滤器。保留最新一段时间内的元素</li></ul></li></ul><h3 id="Watermark-（水印）"><a href="#Watermark-（水印）" class="headerlink" title="Watermark （水印）"></a>Watermark （水印）</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>用于处理乱序事件，而正确地处理乱序事件，通常用Watermark机制结合窗口来实现</p><h4 id="DataStream-Watermark-生成"><a href="#DataStream-Watermark-生成" class="headerlink" title="DataStream Watermark 生成"></a>DataStream Watermark 生成</h4><ol><li><p>Source Function 中生成Watermark</p></li><li><p>DataStream API 中生成Watermark</p></li><li><ol><li>AssingerWithPeriodicWatermarks （周期性的生成Watermark策略，不会针对每个事件都生成）</li><li>AssingerWithPunctuatedWatermarks （对每个事件都尝试进行Watermark的生成，如果生成的结果是null 或Watermark小于之前的，则不会发往下游）</li></ol></li></ol><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><h3 id="自主内存管理"><a href="#自主内存管理" class="headerlink" title="自主内存管理"></a>自主内存管理</h3><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><ol><li><p>JVM内存管理的不足</p></li><li><ol><li>有效数据密度低</li><li>垃圾回收（大数据场景下需要消耗大量的内存，更容易触发Full GC ）</li><li>OOM 问题影响稳定性</li><li>缓存未命中问题（Java对象在堆上存储时并不是连续的）</li></ol></li><li><p>自主内存管理</p></li><li><ol><li>堆上内存的使用、监控、调试简单，堆外内存出现问题后的诊断则较为复杂</li><li>Flink有时需要分配短生命周期的MemorySegment，在堆外内存上分配比在堆上内存开销更高。</li><li>在Flink的测试中，部分操作在堆外内存上会比堆上内存慢</li><li>大内存（上百GB）JVM的启动需要很长时间，Full GC可以达到分钟级。使用堆外内存，可以将大量的数据保存在堆外，极大地减小堆内存，避免GC和内存溢出的问题。</li><li>高效的IO操作。堆外内存在写磁盘或网络传输时是zero-copy，而堆上内存则至少需要1次内存复制。</li><li>堆外内存是进程间共享的。也就是说，即使JVM进程崩溃也不会丢失数据。这可以用来做故障恢复（Flink暂时没有利用这项功能，不过未来很可能会去做）</li><li>堆外内存的优势</li><li>堆外内存的不足</li></ol></li></ol><h3 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h3><h4 id="内存模型图"><a href="#内存模型图" class="headerlink" title="内存模型图"></a>内存模型图</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141759.png"></p><h4 id="MemorySegment（内存段）"><a href="#MemorySegment（内存段）" class="headerlink" title="MemorySegment（内存段）"></a>MemorySegment（内存段）</h4><p>一个MemorySegment对应着一个32KB大小的内存块。这块内存既可以是堆上内存（Java的byte数组），也可以是堆外内存（基于Netty的DirectByteBuffer）</p><h5 id="图解"><a href="#图解" class="headerlink" title="图解"></a>图解</h5><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141819.png"></p><h5 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h5><ul><li><p>BYTE_ARRAY_BASE_OFFSET（二进制字节数组的起始索引）</p></li><li><p>LITTLE_ENDIAN（判断是否为Little Endian模式的字节存储顺序，若不是，就是Big Endian模式）</p></li><li><ul><li>Big Endian：低地址存放最高有效字节（MSB）</li><li>Little Endian：低地址存放最低有效字节（LSB）X86机器</li></ul></li><li><p>HeapMemory（如果MemeorySegment使用堆上内存，则表示一个堆上的字节数组（byte［］），如果MemorySegment使用堆外内存，则为null）</p></li><li><p>address（字节数组对应的相对地址）</p></li><li><p>addressLimit（标识地址结束位置）</p></li><li><p>size（内存段的字节数）</p></li></ul><h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><ul><li>HybirdMemorySegment：用来分配堆上和堆外内存和堆上内存，Flink 在实际使用中只使用了改方式。原因是当有多个实现时，JIT无法直接在编译时自动识别优化</li><li>HeapMemorySegment：用来分配堆上内存，实际没有实现</li></ul><h4 id="MemroyManager（内存管理器）"><a href="#MemroyManager（内存管理器）" class="headerlink" title="MemroyManager（内存管理器）"></a>MemroyManager（内存管理器）</h4><p>实际申请的是堆外内存，通过RocksDB的Block Cache和WriterBufferManager参数来限制，RocksDB使用的内存量</p><h2 id="State（状态）"><a href="#State（状态）" class="headerlink" title="State（状态）"></a>State（状态）</h2><p>状态管理需要考虑的因素：</p><ol><li>状态数据的存储和访问</li><li>状态数据的备份和恢复</li><li>状态数据的划分和动态扩容</li><li>状态数据的清理</li></ol><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141844.png"></p><h3 id="状态存储"><a href="#状态存储" class="headerlink" title="状态存储"></a>状态存储</h3><ul><li>MemoryStateBackend：纯内存，适用于验证、测试，不推荐生产环境</li><li>FsStateBackend：内存+文件，适用于长周期大规模的数据</li><li>RocksDBStateBackend：RocksDB，适用于长周期大规模的数据</li></ul><h3 id="重分布"><a href="#重分布" class="headerlink" title="重分布"></a>重分布</h3><ul><li>ListState：并行度在改变的时候，会将并发上的每个List都取出，然后把这些List合并到一个新的List,根据元素的个数均匀分配给新的Task</li><li>UnionListState:把划分的方式交给用户去做，当改变并发的时候，会将原来的List拼接起来，然后不做划分，直接交给用户</li><li>BroadcastState:变并发的时候，把这些数据分发到新的Task即可</li><li>KeyState：Key-Group数量取决于最大并行度（MaxParallism）</li></ul><h2 id="作业提交"><a href="#作业提交" class="headerlink" title="作业提交"></a>作业提交</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141900.png"></p><h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><h3 id="关系图"><a href="#关系图" class="headerlink" title="关系图"></a>关系图</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141918.png"></p><h3 id="Slot选择策略"><a href="#Slot选择策略" class="headerlink" title="Slot选择策略"></a>Slot选择策略</h3><ul><li><p>LocationPreferenceSlotSelectionStrategy（位置优先的选择策略）</p></li><li><ul><li>DefaultLocationPreferenceSlotSelectionStrategy（默认策略），该策略不考虑资源的均衡分配，会从满足条件的可用Slot集合选择第1个</li><li>EvenlySpreadOutLocationPreferenceSlotSelectionStrategy（均衡策略），该策略考虑资源的均衡分配，会从满足条件的可用Slot集合中选择剩余资源最多的Slot，尽量让各个TaskManager均衡地承担计算压力</li></ul></li><li><p>PreviousAllocationSlotSelectionStrategy（已分配Slot优先的选择策略），如果当前没有空闲的已分配Slot，则仍然会使用位置优先的策略来分配和申请Slot</p></li></ul><h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><ul><li><p>SchedulerNG （调度器）</p></li><li><ul><li>作用</li><li>实现</li></ul></li><li><ol><li>DefaultScheduler（使用ScchedulerStrategy来实现）</li><li>LegacyScheduler（实际使用了原来的ExecutionGraph的调度逻辑）</li></ol></li><li><ol><li>作业的生命周期管理（开始调度、挂起、取消）</li><li>作业执行资源的申请、分配、释放</li><li>作业状态的管理（发布过程中的状态变化、作业异常时的FailOver</li><li>作业的信息提供，对外提供作业的详细信息</li></ol></li><li><p>SchedulingStrategy（调度策略）</p></li><li><ul><li>实现</li></ul></li><li><ol><li>EagerSchelingStrategy（该调度策略用来执行流计算作业的调度）</li><li>LazyFromSourceSchedulingStrategy（该调度策略用来执行批处理作业的调度）</li></ol></li><li><ol><li>startScheduling：调度入口，触发调度器的调度行为</li><li>restartTasks：重启执行失败的Task，一般是Task执行异常导致的</li><li>onExecutionStateChange：当Execution的状态发生改变时</li><li>onPartitionConsumable：当IntermediateResultParitititon中的数据可以消费时</li></ol></li><li><p>ScheduleMode（调度模式）</p></li><li><ol><li>Eager调度（该模式适用于流计算。一次性申请需要所有的资源，如果资源不足，则作业启动失败。）</li><li>Lazy_From_Sources分阶段调度（适用于批处理。从Source Task开始分阶段调度，申请资源的时候，一次性申请本阶段所需要的所有资源。上游Task执行完毕后开始调度执行下游的Task，读取上游的数据，执行本阶段的计算任务，执行完毕之后，调度后一个阶段的Task，依次进行调度，直到作业执行完成）</li><li>Lazy_From_Sources_With_Batch_Slot_Request分阶段Slot重用调度（适用于批处理。与分阶段调度基本一样，区别在于该模式下使用批处理资源申请模式，可以在资源不足的情况下执行作业，但是需要确保在本阶段的作业执行中没有Shuffle行为）</li></ol></li></ul><h3 id="关键组件"><a href="#关键组件" class="headerlink" title="关键组件"></a>关键组件</h3><h4 id="JobMaster"><a href="#JobMaster" class="headerlink" title="JobMaster"></a>JobMaster</h4><ol><li><p>调度执行和管理（将JobGraph转化为ExecutionGraph，调度Task的执行，并处理Task的异常）</p></li><li><ul><li>InputSplit 分配</li><li>结果分区跟踪</li><li>作业执行异常</li></ul></li><li><p>作业Slot资源管理</p></li><li><p>检查点与保存点</p></li><li><p>监控运维相关</p></li><li><p>心跳管理</p></li></ol><h4 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h4><p>结构</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141948.png"></p><h3 id="作业调度失败"><a href="#作业调度失败" class="headerlink" title="作业调度失败"></a>作业调度失败</h3><h4 id="失败异常分类"><a href="#失败异常分类" class="headerlink" title="失败异常分类"></a>失败异常分类</h4><ul><li>NonRecoverableError：不可恢复的错误。此类错误意味着即便是重启也无法恢复作业到正常状态，一旦发生此类错误，则作业执行失败，直接退出作业执行</li><li>PartitionDataMissingError：分区数据不可访问错误。下游Task无法读取上游Task产生的数据，需要重启上游的Task</li><li>EnvironmentError：环境的错误。这种错误需要在调度策略上进行改进，如使用黑名单机制，排除有问题的机器、服务，避免将失败的Task重新调度到这些机器上。</li><li>RecoverableError：可恢复的错误</li></ul><h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><h3 id="容错保证语义"><a href="#容错保证语义" class="headerlink" title="容错保证语义"></a>容错保证语义</h3><ul><li>At-Most-Once（最多一次）</li><li>At-Leat-Once（最少一次）</li><li>Exactly-Once（引擎内严格一次）</li><li>End-to-End Exaacly-Once （端到端严格一次）</li></ul><h3 id="保存点恢复"><a href="#保存点恢复" class="headerlink" title="保存点恢复"></a>保存点恢复</h3><ol><li>算子顺序的改变，如果对应的UID没变，则可以恢复，如果对应的UID变了则恢复失败。</li><li>作业中添加了新的算子，如果是无状态算子，没有影响，可以正常恢复，如果是有状态的算子，跟无状态的算子一样处理。</li><li>从作业中删除了一个有状态的算子，默认需要恢复保存点中所记录的所有算子的状态，如果删除了一个有状态的算子，从保存点恢复的时候被删除的OperatorID找不到，所以会报错，可以通过在命令中添加-allowNonRestoredState （short: -n）跳过无法恢复的算子。</li><li>添加和删除无状态的算子，如果手动设置了UID，则可以恢复，保存点中不记录无状态的算子，如果是自动分配的UID，那么有状态算子的UID可能会变（Flink使用一个单调递增的计数器生成UID，DAG改版，计数器极有可能会变），很有可能恢复失败。</li><li>恢复的时候调整并行度，Flink1.2.0及以上版本,如果没有使用作废的API，则没问题；1.2.0以下版本需要首先升级到1.2.0才可以。</li></ol><h3 id="端到端严格一次"><a href="#端到端严格一次" class="headerlink" title="端到端严格一次"></a>端到端严格一次</h3><h4 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h4><ul><li>数据源支持断点读取</li><li>外部存储支持回滚机制或者满足幂等性</li></ul><h3 id="图解-1"><a href="#图解-1" class="headerlink" title="图解"></a>图解</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210142018.png"></p><h4 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h4><p>TwoPhaseCommitSinkFunction</p><ol><li>beginTransaction，开启一个事务，在临时目录中创建一个临时文件，之后写入数据到该文件中。此过程为不同的事务创建隔离，避免数据混淆。</li><li>preCommit。预提交阶段。将缓存数据块写出到创建的临时文件，然后关闭该文件，确保不再写入新数据到该文件，同时开启一个新事务，执行属于下一个检查点的写入操作。</li><li>commit。在提交阶段，以原子操作的方式将上一阶段的文件写入真正的文件目录下。如果提交失败，Flink应用会重启，并调用TwoPhaseCommitSinkFunction#recoverAndCommit方法尝试恢复并重新提交事务。</li><li>abort。一旦终止事务，删除临时文件。</li></ol><h2 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h2><h3 id="关系图-1"><a href="#关系图-1" class="headerlink" title="关系图"></a>关系图</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210142040.png"></p><h2 id="FLINK-API"><a href="#FLINK-API" class="headerlink" title="FLINK API"></a>FLINK API</h2><h3 id="DataStrem-JOIN"><a href="#DataStrem-JOIN" class="headerlink" title="DataStrem JOIN"></a>DataStrem JOIN</h3><h4 id="Window-JOIN"><a href="#Window-JOIN" class="headerlink" title="Window JOIN"></a>Window JOIN</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stream.join(otherStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(&lt;WindowAssigner&gt;)</span><br><span class="line">    .apply(&lt;JoinFunction&gt;)</span><br></pre></td></tr></table></figure><h3 id="Tumbling-Window-Join"><a href="#Tumbling-Window-Join" class="headerlink" title="Tumbling Window Join"></a>Tumbling Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(TumblingEventTimeWindows.of(Time.milliseconds(2)))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><h3 id="Sliding-Window-Join"><a href="#Sliding-Window-Join" class="headerlink" title="Sliding Window Join"></a>Sliding Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(SlidingEventTimeWindows.of(Time.milliseconds(2) /* size */, Time.milliseconds(1) /* slide */))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><h3 id="Session-Window-Join"><a href="#Session-Window-Join" class="headerlink" title="Session Window Join"></a>Session Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(EventTimeSessionWindows.withGap(Time.milliseconds(1)))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><p>知识源于积累,登峰造极源于自律!</p><p>好文章就得收藏慢慢品, 文章转载于: <a href="https://mp.weixin.qq.com/s/44G_siAfCLINOR0bBrun3g">https://mp.weixin.qq.com/s/44G_siAfCLINOR0bBrun3g</a></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;Flink-核心特点&quot;&gt;&lt;a href=&quot;#Flink-核心特点&quot; class=&quot;headerlink&quot; title=&quot;Flink 核心特点&quot;&gt;&lt;/a&gt;Flink 核心特点&lt;/h3&gt;&lt;h4 id=&quot;批流一体&quot;&gt;&lt;a href=&quot;#批流一体&quot; class=&quot;headerlink&quot; title=&quot;批流一体&quot;&gt;&lt;/a&gt;批流一体&lt;/h4&gt;&lt;p&gt;所有的数据都天然带有时间的概念，必然发生在某一个时间点。把事件按照时间顺序排列起来，就形成了一个事件流，也叫作数据流。&lt;strong&gt;「无界数据」&lt;/strong&gt;是持续产生的数据，所以必须持续地处理无界数据流。&lt;strong&gt;「有界数据」&lt;/strong&gt;，就是在一个确定的时间范围内的数据流，有开始有结束，一旦确定了就不会再改变。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>kafka面试常遇问题</title>
    <link href="http://xubatian.cn/kafka%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%81%87%E9%97%AE%E9%A2%98/"/>
    <id>http://xubatian.cn/kafka%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%81%87%E9%97%AE%E9%A2%98/</id>
    <published>2022-02-10T03:16:03.000Z</published>
    <updated>2022-02-10T06:41:01.803Z</updated>
    
    <content type="html"><![CDATA[<ol><li>为什么要用消息队列？为什么选择了kafka?</li><li>kafka的组件与作用(架构)？</li><li>kafka为什么要分区？</li><li>Kafka生产者分区策略？</li><li>kafka的数据可靠性怎么保证？(丢，重)</li><li>kafka的副本机制？</li><li>kafka的消费分区分配策略？</li><li>kafka的offset怎么维护？</li><li>kafka为什么这么快？(高效读写数据)</li><li>Kafka消息数据积压，Kafka消费能力不足怎么处理？</li><li>kafka事务是怎么实现的？</li><li>Kafka中的数据是有序的吗？</li><li>Kafka可以按照时间消费数据？</li><li>Kafka单条日志传输大小？</li><li>Kafka参数优化？</li><li>Kafka适合以下应用场景？</li><li>Exactly Once语义？在流式计算中怎么保持？</li></ol><span id="more"></span><h2 id="解析参考"><a href="#解析参考" class="headerlink" title="解析参考"></a>解析参考</h2><h3 id="为什么要用消息队列"><a href="#为什么要用消息队列" class="headerlink" title="为什么要用消息队列"></a>为什么要用消息队列</h3><ol><li>解耦</li></ol><p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p><ol><li>可恢复性</li></ol><p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p><ol><li>缓冲</li></ol><p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p><ol><li>灵活性与峰值处理能力</li></ol><p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p><ol><li>异步通信</li></ol><p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p><h3 id="为什么选择了kafka"><a href="#为什么选择了kafka" class="headerlink" title="为什么选择了kafka"></a>为什么选择了kafka</h3><ol><li>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒。</li><li>可扩展性：kafka集群支持热扩展。</li><li>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失。</li><li>容错性：允许集群中节点故障（若副本数量为n,则允许n-1个节点故障）。</li><li>高并发：支持数千个客户端同时读写。</li></ol><h3 id="kafka的组件与作用-架构"><a href="#kafka的组件与作用-架构" class="headerlink" title="kafka的组件与作用(架构)"></a>kafka的组件与作用(架构)</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112112.png"></p><ol><li>Producer ：消息生产者，就是向kafka broker发消息的客户端。</li><li>Consumer ：消息消费者，向kafka broker取消息的客户端。</li><li>Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li><li>Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</li><li>Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic。</li><li>Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。</li><li>Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</li><li>leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</li><li>follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。</li></ol><h3 id="kafka为什么要分区"><a href="#kafka为什么要分区" class="headerlink" title="kafka为什么要分区"></a>kafka为什么要分区</h3><ol><li>方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了。</li><li>可以提高并发，因为可以以Partition为单位读写。</li></ol><h3 id="Kafka生产者分区策略"><a href="#Kafka生产者分区策略" class="headerlink" title="Kafka生产者分区策略"></a>Kafka生产者分区策略</h3><ol><li>指明 partition 的情况下，直接将指明的值直接作为partiton值。</li><li>没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到partition值。</li><li>既没有partition值又没有key值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与topic可用的partition总数取余得到partition值，也就是常说的round-robin算法。</li></ol><h3 id="kafka的数据可靠性怎么保证"><a href="#kafka的数据可靠性怎么保证" class="headerlink" title="kafka的数据可靠性怎么保证"></a>kafka的数据可靠性怎么保证</h3><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。所以引出ack机制。</p><p><strong>ack应答机制（可问：造成数据重复和丢失的相关问题）</strong></p><p>Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。acks参数配置：</p><ul><li>0：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据。</li><li>1：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据。</li></ul><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112241.png"></p><ul><li>-1（all）：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。</li></ul><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112315.png"></p><h3 id="副本数据同步策略"><a href="#副本数据同步策略" class="headerlink" title="副本数据同步策略"></a>副本数据同步策略</h3><table><thead><tr><th align="left">方案</th><th align="center">优点</th><th align="right">缺点</th></tr></thead><tbody><tr><td align="left">半数以上完成同步，就发送ack</td><td align="center">延迟低</td><td align="right">选举新的leader时，容忍n台节点的故障，需要2n+1个副本</td></tr><tr><td align="left">全部完成同步，才发送ack</td><td align="center">选举新的leader时，容忍n台节点的故障，需要n+1个副本</td><td align="right">延迟高</td></tr></tbody></table><p>选择最后一个的原因：</p><ol><li>同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</li><li>虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。</li></ol><h3 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h3><p>如果采用全部完成同步，才发送ack的副本的同步策略的话：提出问题：leader收到数据，所有follower都开始同步数据，但有一个follower，因为某种故障，迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步，才能发送ack。这个问题怎么解决呢？</p><p>Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</p><h3 id="故障处理-LEO与HW"><a href="#故障处理-LEO与HW" class="headerlink" title="故障处理(LEO与HW)"></a>故障处理(LEO与HW)</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112418.png"></p><p>LEO：指的是每个副本最大的offset。</p><p>HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。</p><h6 id="follower故障"><a href="#follower故障" class="headerlink" title="follower故障"></a>follower故障</h6><p>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</p><h6 id="leader故障"><a href="#leader故障" class="headerlink" title="leader故障"></a>leader故障</h6><p>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</p><p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p><p>问题纠正:</p><p> (1)ISR包含leader，不只是follower,所有的元数据都是Controller来维护的</p><p> (2)其实不是什么ack不ack的 Follower 发起 Fetcher请求 之后会返回 success ； 这就理解为  Follower向leader回复了ack，容易误解为ack是生产者和borker的关系。还有这句话应该是follow向leader反馈消息</p><h3 id="kafka的副本机制"><a href="#kafka的副本机制" class="headerlink" title="kafka的副本机制"></a>kafka的副本机制</h3><p>参考上一个问题(副本数据同步策略)。</p><h3 id="kafka的消费分区分配策略"><a href="#kafka的消费分区分配策略" class="headerlink" title="kafka的消费分区分配策略"></a>kafka的消费分区分配策略</h3><p>一个consumer group中有多个consumer，一个topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费 Kafka有三种分配策略，一是RoundRobin，一是Range。高版本还有一个StickyAssignor策略 将分区的所有权从一个消费者移到另一个消费者称为重新平衡（rebalance）。当以下事件发生时，Kafka 将会进行一次分区分配：</p><p>同一个 Consumer Group 内新增消费者。</p><p>消费者离开当前所属的Consumer Group，包括shuts down或crashes。</p><h6 id="Range分区分配策略"><a href="#Range分区分配策略" class="headerlink" title="Range分区分配策略"></a>Range分区分配策略</h6><p>Range是对每个Topic而言的（即一个Topic一个Topic分），首先对同一个Topic里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区。假如有10个分区，3个消费者线程，把分区按照序号排列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0，1，2，3，4，5，6，7，8，9</span><br></pre></td></tr></table></figure><p>消费者线程为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C1-0，C2-0，C2-1</span><br></pre></td></tr></table></figure><p>那么用partition数除以消费者线程的总数来决定每个消费者线程消费几个partition，如果除不尽，前面几个消费者将会多消费一个分区。在我们的例子里面，我们有10个分区，3个消费者线程，10/3 = 3，而且除除不尽，那么消费者线程C1-0将会多消费一个分区，所以最后分区分配的结果看起来是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C1-0：0，1，2，3</span><br><span class="line"></span><br><span class="line">C2-0：4，5，6</span><br><span class="line"></span><br><span class="line">C2-1：7，8，9</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果有11个分区将会是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">C1-0：0，1，2，3</span><br><span class="line"></span><br><span class="line">C2-0：4，5，6，7</span><br><span class="line"></span><br><span class="line">C2-1：8，9，10</span><br></pre></td></tr></table></figure><p>假如我们有两个主题T1,T2，分别有10个分区，最后的分配结果将会是这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">C1-0：T1（0，1，2，3） T2（0，1，2，3）</span><br><span class="line"></span><br><span class="line">C2-0：T1（4，5，6） T2（4，5，6）</span><br><span class="line"></span><br><span class="line">C2-1：T1（7，8，9） T2（7，8，9）</span><br></pre></td></tr></table></figure><h6 id="RoundRobinAssignor分区分配策略"><a href="#RoundRobinAssignor分区分配策略" class="headerlink" title="RoundRobinAssignor分区分配策略"></a>RoundRobinAssignor分区分配策略</h6><p>RoundRobinAssignor策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者. 使用RoundRobin策略有两个前提条件必须满足：</p><p>同一个消费者组里面的所有消费者的num.streams（消费者消费线程数）必须相等；每个消费者订阅的主题必须相同。加入按照 hashCode 排序完的topic-partitions组依次为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9</span><br></pre></td></tr></table></figure><p>我们的消费者线程排序为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C1-0, C1-1, C2-0, C2-1</span><br></pre></td></tr></table></figure><p>最后分区分配的结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C1-0 将消费 T1-5, T1-2, T1-6 分区</span><br><span class="line"></span><br><span class="line">C1-1 将消费 T1-3, T1-1, T1-9 分区</span><br><span class="line"></span><br><span class="line">C2-0 将消费 T1-0, T1-4 分区</span><br><span class="line"></span><br><span class="line">C2-1 将消费 T1-8, T1-7 分区</span><br></pre></td></tr></table></figure><h6 id="StickyAssignor分区分配策略"><a href="#StickyAssignor分区分配策略" class="headerlink" title="StickyAssignor分区分配策略"></a>StickyAssignor分区分配策略</h6><p>Kafka从0.11.x版本开始引入这种分配策略，它主要有两个目的：</p><p>分区的分配要尽可能的均匀，分配给消费者者的主题分区数最多相差一个 分区的分配尽可能的与上次分配的保持相同。当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目的，StickyAssignor策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂很多。</p><p>假设消费组内有3个消费者</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C0、C1、C2</span><br></pre></td></tr></table></figure><p>它们都订阅了4个主题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t0、t1、t2、t3</span><br></pre></td></tr></table></figure><p>并且每个主题有2个分区，也就是说整个消费组订阅了</p><p>t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区</p><p>最终的分配结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0、t1p1、t3p0</span><br><span class="line"></span><br><span class="line">消费者C1：t0p1、t2p0、t3p1</span><br><span class="line"></span><br><span class="line">消费者C2：t1p0、t2p1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样初看上去似乎与采用RoundRobinAssignor策略所分配的结果相同</p><p>此时假设消费者C1脱离了消费组，那么消费组就会执行再平衡操作，进而消费分区会重新分配。如果采用RoundRobinAssignor策略，那么此时的分配结果如下：</p><p>消费者C0：t0p0、t1p0、t2p0、t3p0</p><p>消费者C2：t0p1、t1p1、t2p1、t3p1</p><p>如分配结果所示，RoundRobinAssignor策略会按照消费者C0和C2进行重新轮询分配。而如果此时使用的是StickyAssignor策略，那么分配结果为：</p><p>消费者C0：t0p0、t1p1、t3p0、t2p0</p><p>消费者C2：t1p0、t2p1、t0p1、t3p1</p><p>可以看到分配结果中保留了上一次分配中对于消费者C0和C2的所有分配结果，并将原来消费者C1的“负担”分配给了剩余的两个消费者C0和C2，最终C0和C2的分配还保持了均衡。</p><p>如果发生分区重分配，那么对于同一个分区而言有可能之前的消费者和新指派的消费者不是同一个，对于之前消费者进行到一半的处理还要在新指派的消费者中再次复现一遍，这显然很浪费系统资源。StickyAssignor策略如同其名称中的“sticky”一样，让分配策略具备一定的“粘性”，尽可能地让前后两次分配相同，进而减少系统资源的损耗以及其它异常情况的发生。</p><p>到目前为止所分析的都是消费者的订阅信息都是相同的情况，我们来看一下订阅信息不同的情况下的处理。</p><p>举例，同样消费组内有3个消费者：</p><p>C0、C1、C2</p><p>集群中有3个主题：</p><p>t0、t1、t2</p><p>这3个主题分别有</p><p>1、2、3个分区</p><p>也就是说集群中有</p><p>t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0订阅了主题t0</span><br><span class="line"></span><br><span class="line">消费者C1订阅了主题t0和t1</span><br><span class="line"></span><br><span class="line">消费者C2订阅了主题t0、t1和t2</span><br></pre></td></tr></table></figure><p>如果此时采用RoundRobinAssignor策略：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0</span><br><span class="line"></span><br><span class="line">消费者C1：t1p0</span><br><span class="line"></span><br><span class="line">消费者C2：t1p1、t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>如果此时采用的是StickyAssignor策略：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0</span><br><span class="line"></span><br><span class="line">消费者C1：t1p0、t1p1</span><br><span class="line"></span><br><span class="line">消费者C2：t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>此时消费者C0脱离了消费组，那么RoundRobinAssignor策略的分配结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">消费者C1：t0p0、t1p1</span><br><span class="line"></span><br><span class="line">消费者C2：t1p0、t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>StickyAssignor策略，那么分配结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">消费者C1：t1p0、t1p1、t0p0</span><br><span class="line"></span><br><span class="line">消费者C2：t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配：</p><p>t1p0、t1p1、t2p0、t2p1、t2p2。</p><p>从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异，这个策略的代码实现也是异常复杂。</p><h3 id="kafka的offset怎么维护"><a href="#kafka的offset怎么维护" class="headerlink" title="kafka的offset怎么维护"></a>kafka的offset怎么维护</h3><p>Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112614.png"></p><p>从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</p><p>额外补充：实际开发场景中在Spark和Flink中，可以自己手动提交kafka的offset，或者是flink两阶段提交自动提交offset。</p><h3 id="kafka为什么这么快"><a href="#kafka为什么这么快" class="headerlink" title="kafka为什么这么快"></a>kafka为什么这么快</h3><ol><li>Kafka本身是分布式集群，同时采用分区技术，并发度高。</li><li>顺序写磁盘</li></ol><p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。</p><ol><li>零拷贝技术</li></ol><p>零拷贝并不是不需要拷贝，而是减少不必要的拷贝次数。通常是说在IO读写过程中。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112638.png"></p><p>传统IO流程：</p><p>第一次：将磁盘文件，读取到操作系统内核缓冲区。</p><p>第二次：将内核缓冲区的数据，copy到application应用程序的buffer。</p><p>第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)</p><p>第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。</p><p>传统方式，读取磁盘文件并进行网络发送，经过的四次数据copy是非常繁琐的。实际IO读写，需要进行IO中断，需要CPU响应中断(带来上下文切换)，尽管后来引入DMA来接管CPU的中断请求，但四次copy是存在“不必要的拷贝”的。</p><p>重新思考传统IO方式，会注意到实际上并不需要第二个和第三个数据副本。应用程序除了缓存数据并将其传输回套接字缓冲区之外什么都不做。相反，数据可以直接从读缓冲区传输到套接字缓冲区。</p><p>显然，第二次和第三次数据copy 其实在这种场景下没有什么帮助反而带来开销，这也正是零拷贝出现的意义。</p><p>所以零拷贝是指读取磁盘文件后，不需要做其他处理，直接用网络发送出去。</p><h3 id="Kafka消费能力不足怎么处理"><a href="#Kafka消费能力不足怎么处理" class="headerlink" title="Kafka消费能力不足怎么处理"></a>Kafka消费能力不足怎么处理</h3><ol><li>如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）</li><li>如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间&lt;生产速度），使处理的数据小于生产的数据，也会造成数据积压。</li></ol><h3 id="kafka事务是怎么实现的"><a href="#kafka事务是怎么实现的" class="headerlink" title="kafka事务是怎么实现的"></a>kafka事务是怎么实现的</h3><p>Kafka从0.11版本开始引入了事务支持。事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p><h6 id="Producer事务"><a href="#Producer事务" class="headerlink" title="Producer事务"></a>Producer事务</h6><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID。为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p><h6 id="Consumer事务"><a href="#Consumer事务" class="headerlink" title="Consumer事务"></a>Consumer事务</h6><p>对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</p><h3 id="Kafka中的数据是有序的吗"><a href="#Kafka中的数据是有序的吗" class="headerlink" title="Kafka中的数据是有序的吗"></a>Kafka中的数据是有序的吗</h3><p>单分区内有序。</p><p>多分区，分区与分区间无序。</p><h3 id="Kafka可以按照时间消费数据吗"><a href="#Kafka可以按照时间消费数据吗" class="headerlink" title="Kafka可以按照时间消费数据吗"></a>Kafka可以按照时间消费数据吗</h3><p>可以，提供的API方法：</p><p>KafkaUtil.fetchOffsetsWithTimestamp(topic, sTime, kafkaProp)</p><h3 id="Kafka单条日志传输大小"><a href="#Kafka单条日志传输大小" class="headerlink" title="Kafka单条日志传输大小"></a>Kafka单条日志传输大小</h3><p>kafka对于消息体的大小默认为单条最大值是1M但是在我们应用场景中, 常常会出现一条消息大于1M，如果不对kafka进行配置。则会出现生产者无法将消息推送到kafka或消费者无法去消费kafka里面的数据, 这时我们就要对kafka进行以下配置：server.properties</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">replica.fetch.max.bytes: 1048576  broker可复制的消息的最大字节数, 默认为1M</span><br><span class="line">message.max.bytes: 1000012   kafka 会接收单个消息size的最大限制， 默认为1M左右</span><br><span class="line"></span><br><span class="line">message.max.bytes必须小于等于replica.fetch.max.bytes，否则就会导致replica之间数据同步失败</span><br></pre></td></tr></table></figure><h3 id="Kafka参数优化"><a href="#Kafka参数优化" class="headerlink" title="Kafka参数优化"></a>Kafka参数优化</h3><h6 id="Broker参数配置（server-properties）"><a href="#Broker参数配置（server-properties）" class="headerlink" title="Broker参数配置（server.properties）"></a>Broker参数配置（server.properties）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1、日志保留策略配置</span><br><span class="line"># 保留三天，也可以更短 （log.cleaner.delete.retention.ms）</span><br><span class="line">log.retention.hours=72</span><br><span class="line"></span><br><span class="line">2、Replica相关配置</span><br><span class="line">default.replication.factor:1 默认副本1个</span><br><span class="line"></span><br><span class="line">3、网络通信延时</span><br><span class="line">replica.socket.timeout.ms:30000 #当集群之间网络不稳定时,调大该参数</span><br><span class="line">replica.lag.time.max.ms= 600000# 如果网络不好,或者kafka集群压力较大,会出现副本丢失,然后会频繁复制副本,导致集群压力更大,此时可以调大该参数。</span><br></pre></td></tr></table></figure><h6 id="Producer优化（producer-properties）"><a href="#Producer优化（producer-properties）" class="headerlink" title="Producer优化（producer.properties）"></a>Producer优化（producer.properties）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">compression.type:none                 gzip  snappy  lz4  </span><br><span class="line">#默认发送不进行压缩，推荐配置一种适合的压缩算法，可以大幅度的减缓网络压力和Broker的存储压力。</span><br></pre></td></tr></table></figure><h6 id="Kafka内存调整（kafka-server-start-sh）"><a href="#Kafka内存调整（kafka-server-start-sh）" class="headerlink" title="Kafka内存调整（kafka-server-start.sh）"></a>Kafka内存调整（kafka-server-start.sh）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">默认内存1个G，生产环境尽量不要超过6个G。</span><br><span class="line">export KAFKA_HEAP_OPTS=&quot;-Xms4g -Xmx4g&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Kafka适合以下应用场景"><a href="#Kafka适合以下应用场景" class="headerlink" title="Kafka适合以下应用场景"></a>Kafka适合以下应用场景</h3><ol><li>日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer。</li><li>消息系统：解耦生产者和消费者、缓存消息等。</li><li>用户活动跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后消费者通过订阅这些topic来做实时的监控分析，亦可保存到数据库。</li><li>运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；</li><li>流式处理：比如spark和flink。</li></ol><h3 id="Exactly-Once语义"><a href="#Exactly-Once语义" class="headerlink" title="Exactly Once语义"></a>Exactly Once语义</h3><p>将服务器的ACK级别设置为-1，可以保证Producer到Server之间不会丢失数据，即At Least Once语义。相对的，将服务器ACK级别设置为0，可以保证生产者每条消息只会被发送一次，即At Most Once语义。</p><p>At Least Once可以保证数据不丢失，但是不能保证数据不重复；</p><p>相对的，At Least Once可以保证数据不重复，但是不能保证数据不丢失。</p><p>但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即Exactly Once语义。在0.11版本以前的Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11版本的Kafka，引入了一项重大特性：幂等性。</p><p>开启幂等性enable.idempotence=true。</p><p>所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条。幂等性结合At Least Once语义，就构成了Kafka的Exactly Once语义。即：</p><p>At Least Once + 幂等性 = Exactly Once</p><p>Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带Sequence Number。而Broker端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。</p><p>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once。</p><h3 id="补充，在流式计算中怎么Exactly-Once语义？以flink为例"><a href="#补充，在流式计算中怎么Exactly-Once语义？以flink为例" class="headerlink" title="补充，在流式计算中怎么Exactly Once语义？以flink为例"></a>补充，在流式计算中怎么Exactly Once语义？以flink为例</h3><h4 id="souce"><a href="#souce" class="headerlink" title="souce"></a>souce</h4><p>souce使用执行ExactlyOnce的数据源，比如kafka等</p><p>内部使用FlinkKafakConsumer，并开启CheckPoint，偏移量会保存到StateBackend中，并且默认会将偏移量写入到topic中去，即_consumer_offsets Flink设置CheckepointingModel.EXACTLY_ONCE</p><h4 id="sink"><a href="#sink" class="headerlink" title="sink"></a>sink</h4><p>存储系统支持覆盖也即幂等性：如Redis,Hbase,ES等 存储系统不支持覆：需要支持事务(预写式日志或者两阶段提交),两阶段提交可参考Flink集成的kafka sink的实现。</p><p>知识源于积累,登峰造极源于自律!</p><p>好文章就得收藏慢慢品, 文章转载于: <a href="https://mp.weixin.qq.com/s/_bZvPeAgC64ENzhIzydjSA">https://mp.weixin.qq.com/s/_bZvPeAgC64ENzhIzydjSA</a></p>]]></content>
    
    
    <summary type="html">&lt;ol&gt;
&lt;li&gt;为什么要用消息队列？为什么选择了kafka?&lt;/li&gt;
&lt;li&gt;kafka的组件与作用(架构)？&lt;/li&gt;
&lt;li&gt;kafka为什么要分区？&lt;/li&gt;
&lt;li&gt;Kafka生产者分区策略？&lt;/li&gt;
&lt;li&gt;kafka的数据可靠性怎么保证？(丢，重)&lt;/li&gt;
&lt;li&gt;kafka的副本机制？&lt;/li&gt;
&lt;li&gt;kafka的消费分区分配策略？&lt;/li&gt;
&lt;li&gt;kafka的offset怎么维护？&lt;/li&gt;
&lt;li&gt;kafka为什么这么快？(高效读写数据)&lt;/li&gt;
&lt;li&gt;Kafka消息数据积压，Kafka消费能力不足怎么处理？&lt;/li&gt;
&lt;li&gt;kafka事务是怎么实现的？&lt;/li&gt;
&lt;li&gt;Kafka中的数据是有序的吗？&lt;/li&gt;
&lt;li&gt;Kafka可以按照时间消费数据？&lt;/li&gt;
&lt;li&gt;Kafka单条日志传输大小？&lt;/li&gt;
&lt;li&gt;Kafka参数优化？&lt;/li&gt;
&lt;li&gt;Kafka适合以下应用场景？&lt;/li&gt;
&lt;li&gt;Exactly Once语义？在流式计算中怎么保持？&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="kafka" scheme="http://xubatian.cn/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>为什么要知道Hadoop机架感知？</title>
    <link href="http://xubatian.cn/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%9F%A5%E9%81%93Hadoop%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%9F/"/>
    <id>http://xubatian.cn/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%9F%A5%E9%81%93Hadoop%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%9F/</id>
    <published>2022-02-10T02:59:13.000Z</published>
    <updated>2022-02-10T06:41:07.957Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、首先，我为什么聊机架感知"><a href="#一、首先，我为什么聊机架感知" class="headerlink" title="一、首先，我为什么聊机架感知"></a><strong>一、首先，我为什么聊机架感知</strong></h4><p> 在了解hdfs<a href="https://cloud.tencent.com/product/clb?from=10680">负载均衡</a>时，需要获取DataNode情况，包括每个DataNode磁盘使用情况，获取到数据不均衡，就要做负载均衡处理。做负载均衡就要考虑热点数据发送到哪里去，集群服务器配置是否相同，机架使用情况等。</p><p> 机架感知在这里面有3个很重要的原因：</p><p>1、数据扩容，扩容的服务器在新机架上，导致数据不均衡</p><p>2、机架上的服务器磁盘配置不同（至于为什么，先不细聊）</p><p>通过感知机架，方便系统管理员手动操作，从而实现负载均衡</p><p>3、副本策略三副本，同节点、同机架、不同机架（同机房），可以实现保证有效存储时同时最大化安全策略</p><p>​                                                                                                                        </p><span id="more"></span><p><strong>机架图</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210110107.png"></p><h4 id="二、关于机架感知"><a href="#二、关于机架感知" class="headerlink" title="二、关于机架感知"></a><strong>二、关于机架感知</strong></h4><ol><li>Hadoop不能自动获取节点是否分布在多机架上</li><li>Hadoop大规模集群才会存在跨机架</li><li>不同节点之间通信尽量发生在同一个机架（可用性）</li><li>数据块副本策略会跨机架（容错性）</li></ol><h4 id="三、机架感知配置"><a href="#三、机架感知配置" class="headerlink" title="三、机架感知配置"></a><strong>三、机架感知配置</strong></h4><p>1、自定义类实现 DNSToSwitchMapping，重写 resolve() 方法；打为 jar 包，并复制到 NameNode 节点的 /soft/hadoop/shared/hadoop/common/lib 目录下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 机架感知类</span><br><span class="line"> */</span><br><span class="line">public class MyRackAware implements DNSToSwitchMapping &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 根据需求，将不同的主机划分到不同的机架上</span><br><span class="line">     * @param names 数据节点主机的集合</span><br><span class="line">     * @return 机架感知的集合</span><br><span class="line">     */</span><br><span class="line">    public List&lt;String&gt; resolve(List&lt;String&gt; names) &#123;</span><br><span class="line">        List&lt;String&gt; list = new ArrayList&lt;String&gt;();</span><br><span class="line">        try &#123;</span><br><span class="line">            //将原始信息输出到目录，方便查看</span><br><span class="line">            FileWriter fw = new FileWriter(&quot;/home/centos/rackaware.txt&quot;);</span><br><span class="line">            for (String host : names) &#123;</span><br><span class="line">                //将输入的原始host写入文件</span><br><span class="line">                fw.append(host+&quot;/r/n&quot;);</span><br><span class="line"> </span><br><span class="line">                //进行原始的host进行分机架</span><br><span class="line">                // IP形式</span><br><span class="line">                if (host.startsWith(&quot;192&quot;)) &#123;</span><br><span class="line">                    String ipEnd = host.substring(host.lastIndexOf(&quot;.&quot;) + 1);</span><br><span class="line">                    if (Integer.parseInt(ipEnd) &lt;= 103) &#123; //s102,s103 在一个机架</span><br><span class="line">                        list.add(&quot;/rack1/&quot; + ipEnd);</span><br><span class="line">                    &#125; else &#123;                              //s104 在一个机架</span><br><span class="line">                        list.add(&quot;/rack2/&quot; + ipEnd);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //主机名形式</span><br><span class="line">                else if (host.startsWith(&quot;s&quot;)) &#123;</span><br><span class="line">                    String ipEnd = host.substring(1);</span><br><span class="line">                    if (Integer.parseInt(ipEnd) &lt;= 103) &#123; //s102,s103 在一个机架</span><br><span class="line">                        list.add(&quot;/rack1/&quot; + ipEnd);</span><br><span class="line">                    &#125; else &#123;                              //s104 在一个机架</span><br><span class="line">                        list.add(&quot;/rack2/&quot; + ipEnd);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            fw.close();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        return list;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public void reloadCachedMappings() &#123;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public void reloadCachedMappings(List&lt;String&gt; names) &#123;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、配置core-site.xml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;net.topology.node.switch.mapping.impl&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.fresher.hdfs.rackaware.MyRackAware&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>3、重启集群</p><h4 id="四、机架感知（来自官网）"><a href="#四、机架感知（来自官网）" class="headerlink" title="四、机架感知（来自官网）"></a><strong>四、机架感知（来自官网）</strong></h4><p> Hadoop 组件是机架感知的。例如，HDFS 块放置将通过将一个块副本放置在不同的机架上来使用机架感知来实现容错。这在网络交换机故障或集群内分区的情况下提供数据可用性。</p><p> Hadoop 主守护进程通过调用配置文件指定的外部脚本或 java 类来获取集群工作线程的机架 ID。使用 java 类或外部脚本进行拓扑，输出必须遵循 java <strong>org.apache.hadoop.net.DNSToSwitchMapping</strong>接口。接口期望保持一一对应，拓扑信息格式为’/myrack/myhost’，其中’/‘为拓扑分隔符，’myrack’为机架标识，’myhost’为个人主机。假设每个机架有一个 /24 子网，可以使用“/192.168.100.0/192.168.100.5”格式作为唯一的机架-主机拓扑映射。</p><p> 要使用java 类进行拓扑映射，类名由配置文件中的<strong>net.topology.node.switch.mapping.impl</strong>参数指定。一个示例 NetworkTopology.java 包含在 hadoop 发行版中，可由 Hadoop 管理员自定义。使用 Java 类而不是外部脚本具有性能优势，因为当新的工作节点注册自己时，Hadoop 不需要分叉外部进程。</p><p> 如果实现外部脚本，它将在配置文件中使用<strong>net.topology.script.file.name</strong>参数指定。与 java 类不同，外部拓扑脚本不包含在 Hadoop 发行版中，而是由管理员提供。Hadoop 在 fork 拓扑脚本时会向 ARGV 发送多个 IP 地址。发送到拓扑脚本的 IP 地址数由<strong>net.topology.script.number.args</strong>控制，默认为 100。如果将<strong>net.topology.script.number.args</strong>更改为 1，则拓扑脚本将为每个由 DataNodes 和/或 NodeManagers 提交的 IP。</p><p> 如果<strong>net.topology.script.file.name</strong>或<strong>net.topology.node.switch.mapping.impl</strong>未设置，则为任何传递的 IP 地址返回机架 ID ‘/default-rack’。虽然这种行为看起来很可取，但它可能会导致 HDFS 块复制问题，因为默认行为是将一个复制块写到机架外，并且无法这样做，因为只有一个名为“/default-rack”的机架。</p><p><strong>python Example</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python3</span><br><span class="line"># this script makes assumptions about the physical environment.</span><br><span class="line">#  1) each rack is its own layer 3 network with a /24 subnet, which</span><br><span class="line"># could be typical where each rack has its own</span><br><span class="line">#     switch with uplinks to a central core router.</span><br><span class="line">#</span><br><span class="line">#             +-----------+</span><br><span class="line">#             |core router|</span><br><span class="line">#             +-----------+</span><br><span class="line">#            /             \</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   |rack switch|        |rack switch|</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   | data node |        | data node |</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   | data node |        | data node |</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#</span><br><span class="line"># 2) topology script gets list of IP&#x27;s as input, calculates network address, and prints &#x27;/network_address/ip&#x27;.</span><br><span class="line"></span><br><span class="line">import netaddr</span><br><span class="line">import sys</span><br><span class="line">sys.argv.pop(0)                                                  # discard name of topology script from argv list as we just want IP addresses</span><br><span class="line"></span><br><span class="line">netmask = &#x27;255.255.255.0&#x27;                                        # set netmask to what&#x27;s being used in your environment.  The example uses a /24</span><br><span class="line"></span><br><span class="line">for ip in sys.argv:                                              # loop over list of datanode IP&#x27;s</span><br><span class="line">    address = &#x27;&#123;0&#125;/&#123;1&#125;&#x27;.format(ip, netmask)                      # format address string so it looks like &#x27;ip/netmask&#x27; to make netaddr work</span><br><span class="line">    try:</span><br><span class="line">        network_address = netaddr.IPNetwork(address).network     # calculate and print network address</span><br><span class="line">        print(&quot;/&#123;0&#125;&quot;.format(network_address))</span><br><span class="line">    except:</span><br><span class="line">        print(&quot;/rack-unknown&quot;)                                   # print catch-all value if unable to calculate network address</span><br></pre></td></tr></table></figure><p><strong>bash Example</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line"># Here&#x27;s a bash example to show just how simple these scripts can be</span><br><span class="line"># Assuming we have flat network with everything on a single switch, we can fake a rack topology.</span><br><span class="line"># This could occur in a lab environment where we have limited nodes,like 2-8 physical machines on a unmanaged switch.</span><br><span class="line"># This may also apply to multiple virtual machines running on the same physical hardware.</span><br><span class="line"># The number of machines isn&#x27;t important, but that we are trying to fake a network topology when there isn&#x27;t one.</span><br><span class="line">#</span><br><span class="line">#       +----------+    +--------+</span><br><span class="line">#       |jobtracker|    |datanode|</span><br><span class="line">#       +----------+    +--------+</span><br><span class="line">#              \        /</span><br><span class="line">#  +--------+  +--------+  +--------+</span><br><span class="line">#  |datanode|--| switch |--|datanode|</span><br><span class="line">#  +--------+  +--------+  +--------+</span><br><span class="line">#              /        \</span><br><span class="line">#       +--------+    +--------+</span><br><span class="line">#       |datanode|    |namenode|</span><br><span class="line">#       +--------+    +--------+</span><br><span class="line">#</span><br><span class="line"># With this network topology, we are treating each host as a rack.  This is being done by taking the last octet</span><br><span class="line"># in the datanode&#x27;s IP and prepending it with the word &#x27;/rack-&#x27;.  The advantage for doing this is so HDFS</span><br><span class="line"># can create its &#x27;off-rack&#x27; block copy.</span><br><span class="line"># 1) &#x27;echo $@&#x27; will echo all ARGV values to xargs.</span><br><span class="line"># 2) &#x27;xargs&#x27; will enforce that we print a single argv value per line</span><br><span class="line"># 3) &#x27;awk&#x27; will split fields on dots and append the last field to the string &#x27;/rack-&#x27;. If awk</span><br><span class="line">#    fails to split on four dots, it will still print &#x27;/rack-&#x27; last field value</span><br><span class="line"></span><br><span class="line">echo $@ | xargs -n 1 | awk -F &#x27;.&#x27; &#x27;&#123;print &quot;/rack-&quot;$NF&#125;&#x27;</span><br></pre></td></tr></table></figure><h4 id="五、Hadoop集群网络拓扑描述"><a href="#五、Hadoop集群网络拓扑描述" class="headerlink" title="五、Hadoop集群网络拓扑描述"></a><strong>五、Hadoop集群网络拓扑描述</strong></h4><p>Hadoop集群架构通常包含两级网络拓扑，一般来说，各级机架装配30~40个服务器。</p><blockquote><p>一个机架配置一个交换机，一个交换机实际的连接能力取决于交换机的端口数量，交换机的端口数量最多是48个</p></blockquote><p>为了达到Hadoop的最佳性能，配置Hadoop系统以让其了解网络拓扑状况就极为关键。</p><p>如果集群只包含一个机架，无需做什么，就是默认配置。对于多机架的集群来说，描述清楚节点-机架的映射关系，使得Hadoop将MapReduce任务分配到各个节点时，会倾向于执行机架内的数据传输，而非跨机架数据传输。HDFS还能更加智能地防止副本，以uqde性能和弹性的平衡。</p><p>重点！！！</p><p>节点和机架等网络位置以树的形式来表示，从而能够体现出各个位置之间的网络距离。namenode使用网络位置来确定在哪里防止块的副本。MapReduce的调度器根据网络位置来查找最近的副本，将它作为map任务的输入。</p><blockquote><p>比如spark中提到的移动数据不如移动计算也是同理。又比如yarn任务提交流程中，启动多个task，在哪启动的，现在是不是很清楚了。</p></blockquote><p>综上，回头文章开头，为什么要做负载均衡，为什么要了解机架感知，数据和计算是互相影响的。</p><p>文章转载于”大数据最后一公里公众号”, 原址: <a href="https://cloud.tencent.com/developer/article/1856190">https://cloud.tencent.com/developer/article/1856190</a></p><p>知识源于积累,登峰造极源于自律.</p>]]></content>
    
    
    <summary type="html">&lt;h4 id=&quot;一、首先，我为什么聊机架感知&quot;&gt;&lt;a href=&quot;#一、首先，我为什么聊机架感知&quot; class=&quot;headerlink&quot; title=&quot;一、首先，我为什么聊机架感知&quot;&gt;&lt;/a&gt;&lt;strong&gt;一、首先，我为什么聊机架感知&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt; 在了解hdfs&lt;a href=&quot;https://cloud.tencent.com/product/clb?from=10680&quot;&gt;负载均衡&lt;/a&gt;时，需要获取DataNode情况，包括每个DataNode磁盘使用情况，获取到数据不均衡，就要做负载均衡处理。做负载均衡就要考虑热点数据发送到哪里去，集群服务器配置是否相同，机架使用情况等。&lt;/p&gt;
&lt;p&gt; 机架感知在这里面有3个很重要的原因：&lt;/p&gt;
&lt;p&gt;1、数据扩容，扩容的服务器在新机架上，导致数据不均衡&lt;/p&gt;
&lt;p&gt;2、机架上的服务器磁盘配置不同（至于为什么，先不细聊）&lt;/p&gt;
&lt;p&gt;通过感知机架，方便系统管理员手动操作，从而实现负载均衡&lt;/p&gt;
&lt;p&gt;3、副本策略三副本，同节点、同机架、不同机架（同机房），可以实现保证有效存储时同时最大化安全策略&lt;/p&gt;
&lt;p&gt;​                                                                                                                        &lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="hadoop" scheme="http://xubatian.cn/tags/hadoop/"/>
    
    <category term="机架感知" scheme="http://xubatian.cn/tags/%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5/"/>
    
  </entry>
  
  <entry>
    <title>Flink读取无界流数据计算过程演示</title>
    <link href="http://xubatian.cn/Flink%E8%AF%BB%E5%8F%96%E6%97%A0%E7%95%8C%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/"/>
    <id>http://xubatian.cn/Flink%E8%AF%BB%E5%8F%96%E6%97%A0%E7%95%8C%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/</id>
    <published>2022-02-10T02:07:21.000Z</published>
    <updated>2022-02-10T02:25:25.113Z</updated>
    
    <content type="html"><![CDATA[<p>Flink有界流式读取文本数据计算过程演示</p><span id="more"></span><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-10_10-12-09.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink有界流式读取文本数据计算过程演示&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink有界流式读取文本数据计算过程演示</title>
    <link href="http://xubatian.cn/Flink%E6%B5%81%E5%BC%8F%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/"/>
    <id>http://xubatian.cn/Flink%E6%B5%81%E5%BC%8F%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/</id>
    <published>2022-02-07T16:22:27.000Z</published>
    <updated>2022-02-10T02:17:20.844Z</updated>
    
    <content type="html"><![CDATA[<p>Flink流式读取文本数据计算过程演示. 文本数据总有一刻能读的完,所以他是有界的. 无界流读的是kafka的数据.</p><p>Flink是懒加载的,第一遍会检测整体代码.</p><p>并行度设置为1,就是单线程执行,所以Flink是一行一行读取文本数据的, 读一行计算一行. </p><p>sum算子是有状态的. 所以他的历史数据是保存在sum算子里面.sum算子做聚合计算的,他是一个有状态的算子.</p><p>批处理最终是输出一次,而流处理来一条计算一条.所以他保留了状态.方便后面来一条和前面对比进行计算.</p><span id="more"></span><p>源码地址: <a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.14.3-Demo/src/main/java/www/xubatian/cn/FlinkDemo01/Flink_WordCount_Bounded.java">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.14.3-Demo/src/main/java/www/xubatian/cn/FlinkDemo01/Flink_WordCount_Bounded.java</a></p><p>结果演示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210091224.png"></p><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-08_00-18-10.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink流式读取文本数据计算过程演示. 文本数据总有一刻能读的完,所以他是有界的. 无界流读的是kafka的数据.&lt;/p&gt;
&lt;p&gt;Flink是懒加载的,第一遍会检测整体代码.&lt;/p&gt;
&lt;p&gt;并行度设置为1,就是单线程执行,所以Flink是一行一行读取文本数据的, 读一行计算一行. &lt;/p&gt;
&lt;p&gt;sum算子是有状态的. 所以他的历史数据是保存在sum算子里面.sum算子做聚合计算的,他是一个有状态的算子.&lt;/p&gt;
&lt;p&gt;批处理最终是输出一次,而流处理来一条计算一条.所以他保留了状态.方便后面来一条和前面对比进行计算.&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Mybatis介绍之缓存</title>
    <link href="http://xubatian.cn/Mybatis%E4%BB%8B%E7%BB%8D%E4%B9%8B%E7%BC%93%E5%AD%98/"/>
    <id>http://xubatian.cn/Mybatis%E4%BB%8B%E7%BB%8D%E4%B9%8B%E7%BC%93%E5%AD%98/</id>
    <published>2022-02-07T14:25:10.000Z</published>
    <updated>2022-02-07T15:39:35.907Z</updated>
    
    <content type="html"><![CDATA[<p>Mybatis中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存1024条SQL。二级缓存是指可以跨SqlSession的缓存。 </p><p>​    Mybatis中进行SQL查询是通过org.apache.ibatis.executor.Executor接口进行的，总体来讲，它一共有两类实现，一类是BaseExecutor，一类是CachingExecutor。前者是非启用二级缓存时使用的，而后者是采用的装饰器模式，在启用了二级缓存时使用，当二级缓存没有命中时，底层还是通过BaseExecutor来实现的。</p> <span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207233751.png"></p><h1 id="Mybatis介绍之缓存"><a href="#Mybatis介绍之缓存" class="headerlink" title="Mybatis介绍之缓存"></a>Mybatis介绍之缓存</h1><h2 id="一级缓存"><a href="#一级缓存" class="headerlink" title="一级缓存"></a>一级缓存</h2><p> 一级缓存是默认启用的，在BaseExecutor的query()方法中实现，底层默认使用的是PerpetualCache实现，PerpetualCache采用HashMap存储数据。一级缓存会在进行增、删、改操作时进行清除。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ErrorContext.instance().resource(ms.getResource()).activity(<span class="string">&quot;executing a query&quot;</span>).object(ms.getId());</span><br><span class="line">    <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span> &amp;&amp; ms.isFlushCacheRequired()) &#123;</span><br><span class="line">      clearLocalCache();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;E&gt; list;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      queryStack++;</span><br><span class="line">      list = resultHandler == <span class="keyword">null</span> ? (List&lt;E&gt;) localCache.getObject(key) : <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      queryStack--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (DeferredLoad deferredLoad : deferredLoads) &#123;</span><br><span class="line">        deferredLoad.load();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// issue #601</span></span><br><span class="line">      deferredLoads.clear();</span><br><span class="line">      <span class="keyword">if</span> (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123;</span><br><span class="line">        <span class="comment">// issue #482</span></span><br><span class="line">        clearLocalCache();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> list;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>一级缓存的范围有SESSION和STATEMENT两种，默认是SESSION，如果我们不需要使用一级缓存，那么我们可以把一级缓存的范围指定为STATEMENT，这样每次执行完一个Mapper语句后都会将一级缓存清除。如果只是需要对某一条select语句禁用一级缓存，则可以在对应的select元素上加上flushCache=”true”。如果需要更改一级缓存的范围，请在Mybatis的配置文件中，在<settings>下通过localCacheScope指定。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;</span><br></pre></td></tr></table></figure><p>为了验证一级缓存，我们进行如下测试，在testCache1中，我们通过同一个SqlSession查询了两次一样的SQL，第二次不会发送SQL。在testCache2中，我们也是查询了两次一样的SQL，但是它们是不同的SqlSession，结果会发送两次SQL请求。需要注意的是当Mybatis整合Spring后，直接通过Spring注入Mapper的形式，如果不是在同一个事务中每个Mapper的每次查询操作都对应一个全新的SqlSession实例，这个时候就不会有一级缓存的命中，如有需要可以启用二级缓存。而在同一个事务中时共用的就是同一个SqlSession。这块有兴趣的朋友可以去查看MapperFactoryBean的源码，其父类SqlSessionDaoSupport在设置SqlSessionFactory或设置SqlSessionTemplate时的逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 默认是有一级缓存的，一级缓存只针对于使用同一个SqlSession的情况。&lt;br/&gt;</span></span><br><span class="line"><span class="comment">  * 注意：当使用Spring整合后的Mybatis，不在同一个事务中的Mapper接口对应的操作也是没有一级缓存的，因为它们是对应不同的SqlSession。在本示例中如需要下面的第二个语句可使用一级缓存，需要testCache()方法在一个事务中，使用<span class="doctag">@Transactional</span>标注。</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="meta">@Test</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCache</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    PersonMapper mapper = session.getMapper(PersonMapper.class);</span><br><span class="line">    mapper.findById(<span class="number">5L</span>);</span><br><span class="line">    mapper.findById(<span class="number">5L</span>);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="meta">@Test</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCache2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    SqlSession session1 = <span class="keyword">this</span>.sessionFactory.openSession();</span><br><span class="line">    SqlSession session2 = <span class="keyword">this</span>.sessionFactory.openSession();</span><br><span class="line">    session1.getMapper(PersonMapper.class).findById(<span class="number">5L</span>);</span><br><span class="line">    session2.getMapper(PersonMapper.class).findById(<span class="number">5L</span>);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="二级缓存"><a href="#二级缓存" class="headerlink" title="二级缓存"></a>二级缓存</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>二级缓存是默认启用的，如想取消，则可以通过Mybatis配置文件中的<settings>元素下的子元素<setting>来指定cacheEnabled为false。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;settings&gt;</span><br><span class="line">    &lt;setting name=<span class="string">&quot;cacheEnabled&quot;</span> value=<span class="string">&quot;false&quot;</span> /&gt;</span><br><span class="line"> &lt;/settings&gt;</span><br></pre></td></tr></table></figure><p>cacheEnabled默认是启用的，只有在该值为true的时候，底层使用的Executor才是支持二级缓存的CachingExecutor。具体可参考Mybatis的核心配置类org.apache.ibatis.session.Configuration的newExecutor方法实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Executor <span class="title">newExecutor</span><span class="params">(Transaction transaction, ExecutorType executorType)</span> </span>&#123;</span><br><span class="line">   executorType = executorType == <span class="keyword">null</span> ? defaultExecutorType : executorType;</span><br><span class="line">   executorType = executorType == <span class="keyword">null</span> ? ExecutorType.SIMPLE : executorType;</span><br><span class="line">   Executor executor;</span><br><span class="line">   <span class="keyword">if</span> (ExecutorType.BATCH == executorType) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> BatchExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ExecutorType.REUSE == executorType) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> ReuseExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> SimpleExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (cacheEnabled) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> CachingExecutor(executor);</span><br><span class="line">   &#125;</span><br><span class="line">   executor = (Executor) interceptorChain.pluginAll(executor);</span><br><span class="line">   <span class="keyword">return</span> executor;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>要使用二级缓存除了上面一个配置外，我们还需要在我们对应的Mapper.xml文件中定义需要使用的cache，具体可以参考CachingExecutor的以下实现，其中使用的cache就是我们在对应的Mapper.xml中定义的cache。还有一个条件就是需要当前的查询语句是配置了使用cache的，即下面源码的useCache()是返回true的，默认情况下所有select语句的useCache都是true，如果我们在启用了二级缓存后，有某个查询语句是我们不想缓存的，则可以通过指定其useCache为false来达到对应的效果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">  public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span><br><span class="line">      throws SQLException &#123;</span><br><span class="line">    Cache cache = ms.getCache();</span><br><span class="line">    if (cache != null) &#123;</span><br><span class="line">      flushCacheIfRequired(ms);</span><br><span class="line">      if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123;</span><br><span class="line">        ensureNoOutParams(ms, parameterObject, boundSql);</span><br><span class="line">        @SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">        List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key);</span><br><span class="line">        if (list == null) &#123;</span><br><span class="line">          list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">          tcm.putObject(cache, key, list); // issue #578 and #116</span><br><span class="line">        &#125;</span><br><span class="line">        return list;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="cache定义"><a href="#cache定义" class="headerlink" title="cache定义"></a>cache定义</h3><p> 刚刚说了我们要想使用二级缓存，是需要在对应的Mapper.xml文件中定义其中的查询语句需要使用哪个cache来缓存数据的。这有两种方式可以定义，一种是通过cache元素定义，一种是通过cache-ref元素来定义。但是需要注意的是对于同一个Mapper来讲，它只能使用一个Cache，当同时使用了<cache>和<cache-ref>时使用<cache>定义的优先级更高。Mapper使用的Cache是与我们的Mapper对应的namespace绑定的，一个namespace最多只会有一个Cache与其绑定。</p><h3 id="cache元素定义"><a href="#cache元素定义" class="headerlink" title="cache元素定义"></a>cache元素定义</h3><p> 使用cache元素来定义使用的Cache时，最简单的做法是直接在对应的Mapper.xml文件中指定一个空的<cache/>元素，这个时候Mybatis会按照默认配置创建一个Cache对象，准备的说是PerpetualCache对象，更准确的说是LruCache对象（底层用了装饰器模式）。具体可以参考XMLMapperBuilder中的cacheElement()方法中解析cache元素的逻辑。空cache元素定义会生成一个采用最近最少使用算法最多只能存储1024个元素的缓存，而且是可读写的缓存，即该缓存是全局共享的，任何一个线程在拿到缓存结果后对数据的修改都将影响其它线程获取的缓存结果，因为它们是共享的，同一个对象。</p><p>​     cache元素可指定如下属性，每种属性的指定都是针对都是针对底层Cache的一种装饰，采用的是装饰器的模式。</p><p>Ø <strong>blocking</strong>：默认为false，当指定为true时将采用BlockingCache进行封装，blocking，阻塞的意思，使用BlockingCache会在查询缓存时锁住对应的Key，如果缓存命中了则会释放对应的锁，否则会在查询数据库以后再释放锁，这样可以阻止并发情况下多个线程同时查询数据，详情可参考BlockingCache的源码。</p><p>Ø <strong>eviction</strong>：eviction，驱逐的意思。也就是元素驱逐算法，默认是LRU，对应的就是LruCache，其默认只保存1024个Key，超出时按照最近最少使用算法进行驱逐，详情请参考LruCache的源码。如果想使用自己的算法，则可以将该值指定为自己的驱逐算法实现类，只需要自己的类实现Mybatis的Cache接口即可。除了LRU以外，系统还提供了FIFO（先进先出，对应FifoCache）、SOFT（采用软引用存储Value，便于垃圾回收，对应SoftCache）和WEAK（采用弱引用存储Value，便于垃圾回收，对应WeakCache）这三种策略。</p><p>Ø <strong>flushInterval</strong>：清空缓存的时间间隔，单位是毫秒，默认是不会清空的。当指定了该值时会再用ScheduleCache包装一次，其会在每次对缓存进行操作时判断距离最近一次清空缓存的时间是否超过了flushInterval指定的时间，如果超出了，则清空当前的缓存，详情可参考ScheduleCache的实现。</p><p>Ø <strong>readOnly</strong>：是否只读，默认为false。当指定为false时，底层会用SerializedCache包装一次，其会在写缓存的时候将缓存对象进行序列化，然后在读缓存的时候进行反序列化，这样每次读到的都将是一个新的对象，即使你更改了读取到的结果，也不会影响原来缓存的对象，即非只读，你每次拿到这个缓存结果都可以进行修改，而不会影响原来的缓存结果；当指定为true时那就是每次获取的都是同一个引用，对其修改会影响后续的缓存数据获取，这种情况下是不建议对获取到的缓存结果进行更改，意为只读。这是Mybatis二级缓存读写和只读的定义，可能与我们通常情况下的只读和读写意义有点不同。每次都进行序列化和反序列化无疑会影响性能，但是这样的缓存结果更安全，不会被随意更改，具体可根据实际情况进行选择。详情可参考SerializedCache的源码。</p><p>Ø <strong>size</strong>：用来指定缓存中最多保存的Key的数量。其是针对LruCache而言的，LruCache默认只存储最多1024个Key，可通过该属性来改变默认值，当然，如果你通过eviction指定了自己的驱逐算法，同时自己的实现里面也有setSize方法，那么也可以通过cache的size属性给自定义的驱逐算法里面的size赋值。</p><p>Ø <strong>type</strong>：type属性用来指定当前底层缓存实现类，默认是PerpetualCache，如果我们想使用自定义的Cache，则可以通过该属性来指定，对应的值是我们自定义的Cache的全路径名称。</p><h3 id="cache-ref元素定义"><a href="#cache-ref元素定义" class="headerlink" title="cache-ref元素定义"></a>cache-ref元素定义</h3><p>cache-ref元素可以用来指定其它Mapper.xml中定义的Cache，有的时候可能我们多个不同的Mapper需要共享同一个缓存的，是希望在MapperA中缓存的内容在MapperB中可以直接命中的，这个时候我们就可以考虑使用cache-ref，这种场景只需要保证它们的缓存的Key是一致的即可命中，二级缓存的Key是通过Executor接口的createCacheKey()方法生成的，其实现基本都是BaseExecutor，源码如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CacheKey <span class="title">createCacheKey</span><span class="params">(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   CacheKey cacheKey = <span class="keyword">new</span> CacheKey();</span><br><span class="line">   cacheKey.update(ms.getId());</span><br><span class="line">   cacheKey.update(Integer.valueOf(rowBounds.getOffset()));</span><br><span class="line">   cacheKey.update(Integer.valueOf(rowBounds.getLimit()));</span><br><span class="line">   cacheKey.update(boundSql.getSql());</span><br><span class="line"></span><br><span class="line">   List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings();</span><br><span class="line"></span><br><span class="line">   TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry();</span><br><span class="line">   <span class="comment">// mimic DefaultParameterHandler logic</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parameterMappings.size(); i++) &#123;</span><br><span class="line">     ParameterMapping parameterMapping = parameterMappings.get(i);</span><br><span class="line">     <span class="keyword">if</span> (parameterMapping.getMode() != ParameterMode.OUT) &#123;</span><br><span class="line">       Object value;</span><br><span class="line">       String propertyName = parameterMapping.getProperty();</span><br><span class="line">       <span class="keyword">if</span> (boundSql.hasAdditionalParameter(propertyName)) &#123;</span><br><span class="line">         value = boundSql.getAdditionalParameter(propertyName);</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (parameterObject == <span class="keyword">null</span>) &#123;</span><br><span class="line">         value = <span class="keyword">null</span>;</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span>(typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123;</span><br><span class="line">         value = parameterObject;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         MetaObject metaObject = configuration.newMetaObject(parameterObject);</span><br><span class="line">         value = metaObject.getValue(propertyName);</span><br><span class="line">       &#125;</span><br><span class="line">       cacheKey.update(value);</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (configuration.getEnvironment() != <span class="keyword">null</span>) &#123;</span><br><span class="line">     <span class="comment">// issue #176</span></span><br><span class="line">     cacheKey.update(configuration.getEnvironment().getId());</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> cacheKey;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>打个比方我想在PersonMapper.xml中的查询都使用在UserMapper.xml中定义的Cache，则可以通过cache-ref元素的namespace属性指定需要引用的Cache所在的namespace，即UserMapper.xml中的定义的namespace，假设在UserMapper.xml中定义的namespace是com.elim.learn.mybatis.dao.UserMapper，则在PersonMapper.xml的cache-ref应该定义如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;cache-ref namespace=&quot;com.elim.learn.mybatis.dao.UserMapper&quot;/&gt;</span><br></pre></td></tr></table></figure><h3 id="自定义cache"><a href="#自定义cache" class="headerlink" title="自定义cache"></a>自定义cache</h3><p> 前面提到Mybatis的Cache默认会使用PerpetualCache存储数据，如果我们不想按照它的逻辑实现，或者我们想使用其它缓存框架来实现，比如使用Ehcache、Redis等，这个时候我们就可以使用自己的Cache实现，Mybatis是给我们留有对应的接口，允许我们进行自定义的。要想实现自定义的Cache我们必须定义一个自己的类来实现Mybatis提供的Cache接口，实现对应的接口方法。注意，自定义的Cache必须包含一个接收一个String参数的构造方法，这个参数就是Cache的ID，详情请参考Mybatis初始化Cache的过程，对应XMLMapperBuilder的cacheElement()方法。以下是一个简单的MyCache的实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">publicclass MyCache implements Cache &#123;</span><br><span class="line">   <span class="keyword">private</span> String id;</span><br><span class="line">   <span class="keyword">private</span> String name;<span class="comment">//Name，故意加这么一个属性，以方便演示给自定义Cache的属性设值</span></span><br><span class="line">   <span class="keyword">private</span> Map&lt;Object, Object&gt; cache = <span class="keyword">new</span> HashMap&lt;Object, Object&gt;();</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 构造方法。自定义的Cache实现一定要有一个id参数</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">MyCache</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.id = id;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.id;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putObject</span><span class="params">(Object key, Object value)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.cache.put(key, value);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Object <span class="title">getObject</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.get(key);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Object <span class="title">removeObject</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.remove(key);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.cache.clear();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.size();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> ReadWriteLock <span class="title">getReadWriteLock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> the name</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> name;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> name the name to set</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.name = name;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 定义了自己的Cache实现类后我们就可以在需要使用它的Mapper.xml文件中通过<cache>标签的type属性来指定我们需要使用的Cache。如果我们的自定义Cache是需要指定参数的，则可以通过<cache>标签的子标签<property>来指定对应的参数，Mybatis在解析的时候会调用指定属性对应的set方法。针对于上面的自定义Cache，我们的配置如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;cache type=&quot;com.elim.learn.mybatis.cache.MyCache&quot;&gt;</span><br><span class="line">      &lt;property name=&quot;name&quot; value=&quot;调用setName()方法需要传递的参数值&quot;/&gt;</span><br><span class="line">   &lt;/cache&gt;</span><br></pre></td></tr></table></figure><p>圆角矩形：注意：如果我们使用了自定义的Cache，那么cache标签的其它属性，如size、eviction等都不会对自定义的Cache起作用，也就是说不会自动对自定义的Cache进行包装，如果需要使用自定义的Cache，同时又希望使用Mybatis自带的那些Cache包装类，则可以在自定义的Cache中自己进行包装。</p><h3 id="缓存的清除"><a href="#缓存的清除" class="headerlink" title="缓存的清除"></a>缓存的清除</h3><p>二级缓存默认是会在执行update、insert和delete语句时进行清空的，具体可以参考CachingExecutor的update()实现。如果我们不希望在执行某一条更新语句时清空对应的二级缓存，那么我们可以在对应的语句上指定flushCache属性等于false。如果只是某一条select语句不希望使用二级缓存和一级缓存，则也可以在对应的select元素上加上flushCache=”true”。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;insert id=&quot;delete&quot; parameterType=&quot;java.lang.Long&quot;flushCache=&quot;false&quot;&gt;</span><br><span class="line">    delete t_person where id=#&#123;id&#125;</span><br><span class="line"> &lt;/insert&gt;</span><br></pre></td></tr></table></figure><h3 id="自己操作Cache"><a href="#自己操作Cache" class="headerlink" title="自己操作Cache"></a>自己操作Cache</h3><p>Mybatis中创建的二级缓存都会交给Configuration进行管理，Configuration类是Mybatis的核心类，里面包含了各种Mybatis资源的管理，其可以很方便的通过SqlSession、SqlSessionFactory获取，如有需要我们可以直接通过它来操作我们的Cache。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  @Test</span><br><span class="line">   public void testGetCache() &#123;</span><br><span class="line">      Configuration configuration = this.session.getConfiguration();</span><br><span class="line">//    this.sessionFactory.getConfiguration();</span><br><span class="line">      Collection&lt;Cache&gt; caches = configuration.getCaches();</span><br><span class="line">      System.out.println(caches);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>针对二级缓存进行了以下测试，获取两个不同的SqlSession执行两条相同的SQL，在未指定Cache时Mybatis将查询两次数据库，在指定了Cache时Mybatis只查询了一次数据库，第二次是从缓存中拿的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">  public void testCache2() &#123;</span><br><span class="line">     SqlSession session1 = this.sessionFactory.openSession();</span><br><span class="line">     SqlSession session2 = this.sessionFactory.openSession();</span><br><span class="line">     session1.getMapper(PersonMapper.class).findById(5L);</span><br><span class="line">     session1.commit();</span><br><span class="line">     session2.getMapper(PersonMapper.class).findById(5L);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p> 注意在上面的代码中，我在session1执行完对应的SQL后调用了session1的commit()方法，即提交了它的事务，这样我们在第二次查询的时候才会缓存命中，才不会查询数据库，否则就会连着查询两次数据库。这是因为在CachingExecutor中Mybatis在查询的过程中又在原来Cache的基础上包装了TransactionalCache，这个Cache只会在事务提交后才真正的写入缓存，所以在上面的示例中，如果session1执行完SQL后没有马上commit就紧接着用session2执行SQL，虽然session1查询时没有缓存命中，但是此时写入缓存操作还没有进行，session2再查询的时候也就不会缓存命中了。</p><p><strong>参考文档</strong></p><p><a href="http://www.mybatis.org/mybatis-3/zh/sqlmap-xml.html#cache">http://www.mybatis.org/mybatis-3/zh/sqlmap-xml.html#cache</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Mybatis中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存1024条SQL。二级缓存是指可以跨SqlSession的缓存。 &lt;/p&gt;
&lt;p&gt;​    Mybatis中进行SQL查询是通过org.apache.ibatis.executor.Executor接口进行的，总体来讲，它一共有两类实现，一类是BaseExecutor，一类是CachingExecutor。前者是非启用二级缓存时使用的，而后者是采用的装饰器模式，在启用了二级缓存时使用，当二级缓存没有命中时，底层还是通过BaseExecutor来实现的。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="http://xubatian.cn/categories/Java/"/>
    
    
    <category term="Java" scheme="http://xubatian.cn/tags/Java/"/>
    
    <category term="Mybatis" scheme="http://xubatian.cn/tags/Mybatis/"/>
    
  </entry>
  
</feed>
