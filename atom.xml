<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>我的梦想是星辰大海</title>
  
  <subtitle>知识源于积累,登峰造极源于自律</subtitle>
  <link href="http://xubatian.cn/atom.xml" rel="self"/>
  
  <link href="http://xubatian.cn/"/>
  <updated>2022-02-11T04:14:37.668Z</updated>
  <id>http://xubatian.cn/</id>
  
  <author>
    <name>xubatian</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink 原理与实现: Flink核心概念之任务链</title>
    <link href="http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E4%BB%BB%E5%8A%A1%E9%93%BE/"/>
    <id>http://xubatian.cn/Flink-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0-Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8B%E4%BB%BB%E5%8A%A1%E9%93%BE/</id>
    <published>2022-02-10T14:15:46.000Z</published>
    <updated>2022-02-11T04:14:37.668Z</updated>
    
    <content type="html"><![CDATA[<h3 id="好记性-烂笔头"><a href="#好记性-烂笔头" class="headerlink" title="好记性,烂笔头:"></a>好记性,烂笔头:</h3><p>①socket不能多并行度消费. 而kafka是可以多并行度消费的. kafka有多个分区.   </p><p>②keyby不是一个算子,他是决定我们的数据进入到下游的哪一个并行度里面的.他自己没有并行度的.他不会对数据做任何的操作.数据可能从一个并行度来的. 进过keyby之后,可能把他发到好多个并行度里面去了.</p><span id="more"></span><h3 id="正文"><a href="#正文" class="headerlink" title="正文:"></a>正文:</h3><p>任务链的意思就是说,我们把两个算子按照一定的条件连接在一起.形成一个统一的Task<br>这就是所谓的任务链.并且我们可以在图上可以看到,如下图所示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210221830.png"></p><p>任务链可以当做Spark中的stage理解. 但是他比stage灵活. spark中根据宽依赖划分stage. 所以Flink保留此特点. 如果你是重分区的操作.他就一定会划分到两个不同的任务链里面来. 除此之外Flink的任务链还要看并行度. </p><p>这个任务链有一定的条件,首先他们的<strong>①并行度要相同</strong>.所谓的并行度相同就是One-to-one,One-to-one不是说他们只有一个,而是指他们的并行度相同.第二个条件就是他们<strong>②中间没有shuffle</strong>.中间没有shuffle才会通过任务链把他们合在一起.这个任务链不用我们去做的.不过呢,我们可以设置让所有的算子之间完全隔离.就算你有条件来通过这个任务链来进行合并,我们也不让你构建一个任务链.我们只要加一个disableOperatorChaining(禁用这个任务链),禁用这个任务链之后,就算你符合条件,他也不把你这两个task链在一起,形成一个统一的Task.<br>但是这两种那个更好呢?<strong>当然是有任务链的更好.有任务链可以提高吞吐,减少IO操作</strong>.<br>所以,大多数情况下,我这一行代码(streamEnv.disableOperatorChaining)不应该做.</p><p><strong>③共享组不同也不能形成任务链</strong> 共享组的作用就是把同一个任务放在同一个slot里面</p><p>相同并行度的one to one操作，Flink这样相连的算子链接在一起形成一个task，原来的算子成为里面的一部分。将算子链接成task是非常有效的优化：它能减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。链接的行为可以在编程API中进行指定。<br>streamEnv.disableOperatorChaining:表示所有操作算子都不构建任务链<br>.disableChaining() 加在其中一个算子中，表示：该算子和其他算子不一起构建任务链。它是独立的</p><p>图 task与operator chains:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210222115.png"></p><p>任务链案例代码地址:</p><p><a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo02/Flink01_WordCount_Chain.java">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo02/Flink01_WordCount_Chain.java</a></p><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-11_12-04-16.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;好记性-烂笔头&quot;&gt;&lt;a href=&quot;#好记性-烂笔头&quot; class=&quot;headerlink&quot; title=&quot;好记性,烂笔头:&quot;&gt;&lt;/a&gt;好记性,烂笔头:&lt;/h3&gt;&lt;p&gt;①socket不能多并行度消费. 而kafka是可以多并行度消费的. kafka有多个分区.   &lt;/p&gt;
&lt;p&gt;②keyby不是一个算子,他是决定我们的数据进入到下游的哪一个并行度里面的.他自己没有并行度的.他不会对数据做任何的操作.数据可能从一个并行度来的. 进过keyby之后,可能把他发到好多个并行度里面去了.&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
    <category term="Flink任务链" scheme="http://xubatian.cn/tags/Flink%E4%BB%BB%E5%8A%A1%E9%93%BE/"/>
    
  </entry>
  
  <entry>
    <title>Flink总结速览</title>
    <link href="http://xubatian.cn/Flink%E6%80%BB%E7%BB%93%E9%80%9F%E8%A7%88/"/>
    <id>http://xubatian.cn/Flink%E6%80%BB%E7%BB%93%E9%80%9F%E8%A7%88/</id>
    <published>2022-02-10T06:11:48.000Z</published>
    <updated>2022-02-10T06:40:53.045Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Flink-核心特点"><a href="#Flink-核心特点" class="headerlink" title="Flink 核心特点"></a>Flink 核心特点</h3><h4 id="批流一体"><a href="#批流一体" class="headerlink" title="批流一体"></a>批流一体</h4><p>所有的数据都天然带有时间的概念，必然发生在某一个时间点。把事件按照时间顺序排列起来，就形成了一个事件流，也叫作数据流。<strong>「无界数据」</strong>是持续产生的数据，所以必须持续地处理无界数据流。<strong>「有界数据」</strong>，就是在一个确定的时间范围内的数据流，有开始有结束，一旦确定了就不会再改变。</p><span id="more"></span><h4 id="可靠的容错能力"><a href="#可靠的容错能力" class="headerlink" title="可靠的容错能力"></a>可靠的容错能力</h4><ul><li><p>集群级容错</p></li><li><ul><li>集群管理器集成（Hadoop YARN、Mesos或Kubernetes）</li><li>高可用性设置（HA模式基于ApacheZooKeeper）</li></ul></li><li><p>应用级容错（ Checkpoint）</p></li><li><ul><li>一致性（其本身支持Exactly-Once 语义）</li><li>轻量级（检查点的执行异步和增量检查点）</li></ul></li><li><p>高吞吐、低延迟</p></li></ul><h4 id="运行时架构"><a href="#运行时架构" class="headerlink" title="运行时架构"></a>运行时架构</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141319.png"></p><ul><li><p>Flink 客户端</p></li><li><ul><li>提交Flink作业到Flink集群</li><li>Stream Graph 和 Job Graph构建</li></ul></li><li><p>JobManager</p></li><li><ul><li>资源申请</li><li>任务调度</li><li>应用容错</li></ul></li><li><p>TaskManager</p></li><li><ul><li>接收JobManager 分发的子任务，管理子任务</li><li>任务处理（消费数据、处理数据）</li></ul></li></ul><h2 id="Flink-应用"><a href="#Flink-应用" class="headerlink" title="Flink 应用"></a>Flink 应用</h2><h4 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h4><h5 id="DataStream-体系"><a href="#DataStream-体系" class="headerlink" title="DataStream 体系"></a>DataStream 体系</h5><ol><li><p>DataStream(每个DataStream都有一个Transformation对象)</p></li><li><p>DataStreamSource（DataStream的起点）</p></li><li><p>DataStreamSink（DataStream的输出）</p></li><li><p>KeyedStream（表示根据指定的Key记性分组的数据流）</p></li><li><p>WindowdeStream &amp; AllWindowedStream（根据key分组且基于WindowAssigner切分窗口的数据流）</p></li><li><p>JoinedStreams &amp; CoGroupedStreams</p></li><li><ol><li>JoinedStreams底层使用CoGroupedStreams来实现</li><li>CoGrouped侧重的是Group，对数据进行分组，是对同一个key上的两组集合进行操作</li><li>Join侧重的是数据对，对同一个key的每一对元素进行操作</li></ol></li><li><p>ConnectedStreams（表示两个数据流的组合）</p></li><li><p>BroadcastStream &amp; BroadcastConnectedStream（DataStream的广播行为）</p></li><li><p>IterativeStream（包含IterativeStream的Dataflow是一个有向有环图）</p></li><li><p>AsyncDataStream（在DataStream上使用异步函数的能力）</p></li></ol><h5 id="处理数据API"><a href="#处理数据API" class="headerlink" title="处理数据API"></a>处理数据API</h5><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141359.png"></p><h2 id="核心抽象"><a href="#核心抽象" class="headerlink" title="核心抽象"></a>核心抽象</h2><h3 id="环境对象"><a href="#环境对象" class="headerlink" title="环境对象"></a>环境对象</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141427.png"></p><h3 id="数据流元素"><a href="#数据流元素" class="headerlink" title="数据流元素"></a>数据流元素</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141448.png"></p><ol><li><p>StreamRecord（数据流中的一条记录｜事件）</p></li><li><ol><li>数据的值本身</li><li>时间戳（可选）</li></ol></li><li><p>LatencyMarker（用来近似评估延迟）</p></li><li><ol><li>周期性的在数据源算子中创造出来的时间戳</li><li>算子编号</li><li>数据源所在的Task编号</li></ol></li><li><p>Watemark（是一个时间戳，用来告诉算子所有时间早于等于Watermark的事件或记录都已经到达，不会再有比Watermark更早的记录，算子可以根据Watermark触发窗口的计算、清理资源等）</p></li><li><p>StreamStatus（用来通知Task是否会继续接收到上游的记录或者Watermark）</p></li><li><ol><li>空闲状态（IDLE）。</li><li>活动状态（ACTIVE）。</li></ol></li></ol><h3 id="Flink-异步IO"><a href="#Flink-异步IO" class="headerlink" title="Flink 异步IO"></a>Flink 异步IO</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141557.png"></p><p>顺序输出模式（先收到的数据元素先输出，后续数据元素的异步函数调用无论是否先完成，都需要等待）</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141620.png"></p><p>无序输出模式（先处理完的数据元素先输出，不保证消息顺序）</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141640.png"></p><h3 id="数据分区"><a href="#数据分区" class="headerlink" title="数据分区"></a>数据分区</h3><ul><li>ForwardPartitioner（用于在同一个OperatorChain中上下游算子之间的数据转发，实际上数据是直接传递给下游的）</li><li>ShufflePartitioner（随机将元素进行分区，可以确保下游的Task能够均匀地获得数据）</li><li>ReblancePartitioner（以Round-robin的方式为每个元素分配分区，确保下游的Task可以均匀地获得数据，避免数据倾斜）</li><li>RescalingPartitioner（用Round-robin选择下游的一个Task进行数据分区，如上游有2个Source，下游有6个Map，那么每个Source会分配3个固定的下游Map，不会向未分配给自己的分区写入数据）</li><li>BroadcastPartitioner（将该记录广播给所有分区）</li><li>KeyGroupStreamPartitioner（KeyedStream根据KeyGroup索引编号进行分区，该分区器不是提供给用户来用的）</li></ul><h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141709.png"></p><ul><li><p>WindowAssigner（用来决定某个元素被分配到哪个/哪些窗口中去）</p></li><li><p>WindowTrigger（决定一个窗口何时能够呗计算或清除，每一个窗口都拥有一个属于自己的Trigger）</p></li><li><p>WindowEvictor（窗口数据的过滤器，可在Window Function 执行前或后，从Window中过滤元素）</p></li><li><ul><li>CountEvictor：计数过滤器。在Window中保留指定数量的元素，并从窗口头部开始丢弃其余元素</li><li>DeltaEvictor：阈值过滤器。丢弃超过阈值的数据记录</li><li>TimeEvictor：时间过滤器。保留最新一段时间内的元素</li></ul></li></ul><h3 id="Watermark-（水印）"><a href="#Watermark-（水印）" class="headerlink" title="Watermark （水印）"></a>Watermark （水印）</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>用于处理乱序事件，而正确地处理乱序事件，通常用Watermark机制结合窗口来实现</p><h4 id="DataStream-Watermark-生成"><a href="#DataStream-Watermark-生成" class="headerlink" title="DataStream Watermark 生成"></a>DataStream Watermark 生成</h4><ol><li><p>Source Function 中生成Watermark</p></li><li><p>DataStream API 中生成Watermark</p></li><li><ol><li>AssingerWithPeriodicWatermarks （周期性的生成Watermark策略，不会针对每个事件都生成）</li><li>AssingerWithPunctuatedWatermarks （对每个事件都尝试进行Watermark的生成，如果生成的结果是null 或Watermark小于之前的，则不会发往下游）</li></ol></li></ol><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><h3 id="自主内存管理"><a href="#自主内存管理" class="headerlink" title="自主内存管理"></a>自主内存管理</h3><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><ol><li><p>JVM内存管理的不足</p></li><li><ol><li>有效数据密度低</li><li>垃圾回收（大数据场景下需要消耗大量的内存，更容易触发Full GC ）</li><li>OOM 问题影响稳定性</li><li>缓存未命中问题（Java对象在堆上存储时并不是连续的）</li></ol></li><li><p>自主内存管理</p></li><li><ol><li>堆上内存的使用、监控、调试简单，堆外内存出现问题后的诊断则较为复杂</li><li>Flink有时需要分配短生命周期的MemorySegment，在堆外内存上分配比在堆上内存开销更高。</li><li>在Flink的测试中，部分操作在堆外内存上会比堆上内存慢</li><li>大内存（上百GB）JVM的启动需要很长时间，Full GC可以达到分钟级。使用堆外内存，可以将大量的数据保存在堆外，极大地减小堆内存，避免GC和内存溢出的问题。</li><li>高效的IO操作。堆外内存在写磁盘或网络传输时是zero-copy，而堆上内存则至少需要1次内存复制。</li><li>堆外内存是进程间共享的。也就是说，即使JVM进程崩溃也不会丢失数据。这可以用来做故障恢复（Flink暂时没有利用这项功能，不过未来很可能会去做）</li><li>堆外内存的优势</li><li>堆外内存的不足</li></ol></li></ol><h3 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h3><h4 id="内存模型图"><a href="#内存模型图" class="headerlink" title="内存模型图"></a>内存模型图</h4><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141759.png"></p><h4 id="MemorySegment（内存段）"><a href="#MemorySegment（内存段）" class="headerlink" title="MemorySegment（内存段）"></a>MemorySegment（内存段）</h4><p>一个MemorySegment对应着一个32KB大小的内存块。这块内存既可以是堆上内存（Java的byte数组），也可以是堆外内存（基于Netty的DirectByteBuffer）</p><h5 id="图解"><a href="#图解" class="headerlink" title="图解"></a>图解</h5><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141819.png"></p><h5 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h5><ul><li><p>BYTE_ARRAY_BASE_OFFSET（二进制字节数组的起始索引）</p></li><li><p>LITTLE_ENDIAN（判断是否为Little Endian模式的字节存储顺序，若不是，就是Big Endian模式）</p></li><li><ul><li>Big Endian：低地址存放最高有效字节（MSB）</li><li>Little Endian：低地址存放最低有效字节（LSB）X86机器</li></ul></li><li><p>HeapMemory（如果MemeorySegment使用堆上内存，则表示一个堆上的字节数组（byte［］），如果MemorySegment使用堆外内存，则为null）</p></li><li><p>address（字节数组对应的相对地址）</p></li><li><p>addressLimit（标识地址结束位置）</p></li><li><p>size（内存段的字节数）</p></li></ul><h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><ul><li>HybirdMemorySegment：用来分配堆上和堆外内存和堆上内存，Flink 在实际使用中只使用了改方式。原因是当有多个实现时，JIT无法直接在编译时自动识别优化</li><li>HeapMemorySegment：用来分配堆上内存，实际没有实现</li></ul><h4 id="MemroyManager（内存管理器）"><a href="#MemroyManager（内存管理器）" class="headerlink" title="MemroyManager（内存管理器）"></a>MemroyManager（内存管理器）</h4><p>实际申请的是堆外内存，通过RocksDB的Block Cache和WriterBufferManager参数来限制，RocksDB使用的内存量</p><h2 id="State（状态）"><a href="#State（状态）" class="headerlink" title="State（状态）"></a>State（状态）</h2><p>状态管理需要考虑的因素：</p><ol><li>状态数据的存储和访问</li><li>状态数据的备份和恢复</li><li>状态数据的划分和动态扩容</li><li>状态数据的清理</li></ol><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141844.png"></p><h3 id="状态存储"><a href="#状态存储" class="headerlink" title="状态存储"></a>状态存储</h3><ul><li>MemoryStateBackend：纯内存，适用于验证、测试，不推荐生产环境</li><li>FsStateBackend：内存+文件，适用于长周期大规模的数据</li><li>RocksDBStateBackend：RocksDB，适用于长周期大规模的数据</li></ul><h3 id="重分布"><a href="#重分布" class="headerlink" title="重分布"></a>重分布</h3><ul><li>ListState：并行度在改变的时候，会将并发上的每个List都取出，然后把这些List合并到一个新的List,根据元素的个数均匀分配给新的Task</li><li>UnionListState:把划分的方式交给用户去做，当改变并发的时候，会将原来的List拼接起来，然后不做划分，直接交给用户</li><li>BroadcastState:变并发的时候，把这些数据分发到新的Task即可</li><li>KeyState：Key-Group数量取决于最大并行度（MaxParallism）</li></ul><h2 id="作业提交"><a href="#作业提交" class="headerlink" title="作业提交"></a>作业提交</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141900.png"></p><h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><h3 id="关系图"><a href="#关系图" class="headerlink" title="关系图"></a>关系图</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141918.png"></p><h3 id="Slot选择策略"><a href="#Slot选择策略" class="headerlink" title="Slot选择策略"></a>Slot选择策略</h3><ul><li><p>LocationPreferenceSlotSelectionStrategy（位置优先的选择策略）</p></li><li><ul><li>DefaultLocationPreferenceSlotSelectionStrategy（默认策略），该策略不考虑资源的均衡分配，会从满足条件的可用Slot集合选择第1个</li><li>EvenlySpreadOutLocationPreferenceSlotSelectionStrategy（均衡策略），该策略考虑资源的均衡分配，会从满足条件的可用Slot集合中选择剩余资源最多的Slot，尽量让各个TaskManager均衡地承担计算压力</li></ul></li><li><p>PreviousAllocationSlotSelectionStrategy（已分配Slot优先的选择策略），如果当前没有空闲的已分配Slot，则仍然会使用位置优先的策略来分配和申请Slot</p></li></ul><h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><ul><li><p>SchedulerNG （调度器）</p></li><li><ul><li>作用</li><li>实现</li></ul></li><li><ol><li>DefaultScheduler（使用ScchedulerStrategy来实现）</li><li>LegacyScheduler（实际使用了原来的ExecutionGraph的调度逻辑）</li></ol></li><li><ol><li>作业的生命周期管理（开始调度、挂起、取消）</li><li>作业执行资源的申请、分配、释放</li><li>作业状态的管理（发布过程中的状态变化、作业异常时的FailOver</li><li>作业的信息提供，对外提供作业的详细信息</li></ol></li><li><p>SchedulingStrategy（调度策略）</p></li><li><ul><li>实现</li></ul></li><li><ol><li>EagerSchelingStrategy（该调度策略用来执行流计算作业的调度）</li><li>LazyFromSourceSchedulingStrategy（该调度策略用来执行批处理作业的调度）</li></ol></li><li><ol><li>startScheduling：调度入口，触发调度器的调度行为</li><li>restartTasks：重启执行失败的Task，一般是Task执行异常导致的</li><li>onExecutionStateChange：当Execution的状态发生改变时</li><li>onPartitionConsumable：当IntermediateResultParitititon中的数据可以消费时</li></ol></li><li><p>ScheduleMode（调度模式）</p></li><li><ol><li>Eager调度（该模式适用于流计算。一次性申请需要所有的资源，如果资源不足，则作业启动失败。）</li><li>Lazy_From_Sources分阶段调度（适用于批处理。从Source Task开始分阶段调度，申请资源的时候，一次性申请本阶段所需要的所有资源。上游Task执行完毕后开始调度执行下游的Task，读取上游的数据，执行本阶段的计算任务，执行完毕之后，调度后一个阶段的Task，依次进行调度，直到作业执行完成）</li><li>Lazy_From_Sources_With_Batch_Slot_Request分阶段Slot重用调度（适用于批处理。与分阶段调度基本一样，区别在于该模式下使用批处理资源申请模式，可以在资源不足的情况下执行作业，但是需要确保在本阶段的作业执行中没有Shuffle行为）</li></ol></li></ul><h3 id="关键组件"><a href="#关键组件" class="headerlink" title="关键组件"></a>关键组件</h3><h4 id="JobMaster"><a href="#JobMaster" class="headerlink" title="JobMaster"></a>JobMaster</h4><ol><li><p>调度执行和管理（将JobGraph转化为ExecutionGraph，调度Task的执行，并处理Task的异常）</p></li><li><ul><li>InputSplit 分配</li><li>结果分区跟踪</li><li>作业执行异常</li></ul></li><li><p>作业Slot资源管理</p></li><li><p>检查点与保存点</p></li><li><p>监控运维相关</p></li><li><p>心跳管理</p></li></ol><h4 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h4><p>结构</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210141948.png"></p><h3 id="作业调度失败"><a href="#作业调度失败" class="headerlink" title="作业调度失败"></a>作业调度失败</h3><h4 id="失败异常分类"><a href="#失败异常分类" class="headerlink" title="失败异常分类"></a>失败异常分类</h4><ul><li>NonRecoverableError：不可恢复的错误。此类错误意味着即便是重启也无法恢复作业到正常状态，一旦发生此类错误，则作业执行失败，直接退出作业执行</li><li>PartitionDataMissingError：分区数据不可访问错误。下游Task无法读取上游Task产生的数据，需要重启上游的Task</li><li>EnvironmentError：环境的错误。这种错误需要在调度策略上进行改进，如使用黑名单机制，排除有问题的机器、服务，避免将失败的Task重新调度到这些机器上。</li><li>RecoverableError：可恢复的错误</li></ul><h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><h3 id="容错保证语义"><a href="#容错保证语义" class="headerlink" title="容错保证语义"></a>容错保证语义</h3><ul><li>At-Most-Once（最多一次）</li><li>At-Leat-Once（最少一次）</li><li>Exactly-Once（引擎内严格一次）</li><li>End-to-End Exaacly-Once （端到端严格一次）</li></ul><h3 id="保存点恢复"><a href="#保存点恢复" class="headerlink" title="保存点恢复"></a>保存点恢复</h3><ol><li>算子顺序的改变，如果对应的UID没变，则可以恢复，如果对应的UID变了则恢复失败。</li><li>作业中添加了新的算子，如果是无状态算子，没有影响，可以正常恢复，如果是有状态的算子，跟无状态的算子一样处理。</li><li>从作业中删除了一个有状态的算子，默认需要恢复保存点中所记录的所有算子的状态，如果删除了一个有状态的算子，从保存点恢复的时候被删除的OperatorID找不到，所以会报错，可以通过在命令中添加-allowNonRestoredState （short: -n）跳过无法恢复的算子。</li><li>添加和删除无状态的算子，如果手动设置了UID，则可以恢复，保存点中不记录无状态的算子，如果是自动分配的UID，那么有状态算子的UID可能会变（Flink使用一个单调递增的计数器生成UID，DAG改版，计数器极有可能会变），很有可能恢复失败。</li><li>恢复的时候调整并行度，Flink1.2.0及以上版本,如果没有使用作废的API，则没问题；1.2.0以下版本需要首先升级到1.2.0才可以。</li></ol><h3 id="端到端严格一次"><a href="#端到端严格一次" class="headerlink" title="端到端严格一次"></a>端到端严格一次</h3><h4 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h4><ul><li>数据源支持断点读取</li><li>外部存储支持回滚机制或者满足幂等性</li></ul><h3 id="图解-1"><a href="#图解-1" class="headerlink" title="图解"></a>图解</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210142018.png"></p><h4 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h4><p>TwoPhaseCommitSinkFunction</p><ol><li>beginTransaction，开启一个事务，在临时目录中创建一个临时文件，之后写入数据到该文件中。此过程为不同的事务创建隔离，避免数据混淆。</li><li>preCommit。预提交阶段。将缓存数据块写出到创建的临时文件，然后关闭该文件，确保不再写入新数据到该文件，同时开启一个新事务，执行属于下一个检查点的写入操作。</li><li>commit。在提交阶段，以原子操作的方式将上一阶段的文件写入真正的文件目录下。如果提交失败，Flink应用会重启，并调用TwoPhaseCommitSinkFunction#recoverAndCommit方法尝试恢复并重新提交事务。</li><li>abort。一旦终止事务，删除临时文件。</li></ol><h2 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h2><h3 id="关系图-1"><a href="#关系图-1" class="headerlink" title="关系图"></a>关系图</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210142040.png"></p><h2 id="FLINK-API"><a href="#FLINK-API" class="headerlink" title="FLINK API"></a>FLINK API</h2><h3 id="DataStrem-JOIN"><a href="#DataStrem-JOIN" class="headerlink" title="DataStrem JOIN"></a>DataStrem JOIN</h3><h4 id="Window-JOIN"><a href="#Window-JOIN" class="headerlink" title="Window JOIN"></a>Window JOIN</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stream.join(otherStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(&lt;WindowAssigner&gt;)</span><br><span class="line">    .apply(&lt;JoinFunction&gt;)</span><br></pre></td></tr></table></figure><h3 id="Tumbling-Window-Join"><a href="#Tumbling-Window-Join" class="headerlink" title="Tumbling Window Join"></a>Tumbling Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(TumblingEventTimeWindows.of(Time.milliseconds(2)))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><h3 id="Sliding-Window-Join"><a href="#Sliding-Window-Join" class="headerlink" title="Sliding Window Join"></a>Sliding Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(SlidingEventTimeWindows.of(Time.milliseconds(2) /* size */, Time.milliseconds(1) /* slide */))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><h3 id="Session-Window-Join"><a href="#Session-Window-Join" class="headerlink" title="Session Window Join"></a>Session Window Join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; orangeStream = ...</span><br><span class="line">DataStream&lt;Integer&gt; greenStream = ...</span><br><span class="line"></span><br><span class="line">orangeStream.join(greenStream)</span><br><span class="line">    .where(&lt;KeySelector&gt;)</span><br><span class="line">    .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">    .window(EventTimeSessionWindows.withGap(Time.milliseconds(1)))</span><br><span class="line">    .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String join(Integer first, Integer second) &#123;</span><br><span class="line">            return first + &quot;,&quot; + second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><p>知识源于积累,登峰造极源于自律!</p><p>好文章就得收藏慢慢品, 文章转载于: <a href="https://mp.weixin.qq.com/s/44G_siAfCLINOR0bBrun3g">https://mp.weixin.qq.com/s/44G_siAfCLINOR0bBrun3g</a></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;Flink-核心特点&quot;&gt;&lt;a href=&quot;#Flink-核心特点&quot; class=&quot;headerlink&quot; title=&quot;Flink 核心特点&quot;&gt;&lt;/a&gt;Flink 核心特点&lt;/h3&gt;&lt;h4 id=&quot;批流一体&quot;&gt;&lt;a href=&quot;#批流一体&quot; class=&quot;headerlink&quot; title=&quot;批流一体&quot;&gt;&lt;/a&gt;批流一体&lt;/h4&gt;&lt;p&gt;所有的数据都天然带有时间的概念，必然发生在某一个时间点。把事件按照时间顺序排列起来，就形成了一个事件流，也叫作数据流。&lt;strong&gt;「无界数据」&lt;/strong&gt;是持续产生的数据，所以必须持续地处理无界数据流。&lt;strong&gt;「有界数据」&lt;/strong&gt;，就是在一个确定的时间范围内的数据流，有开始有结束，一旦确定了就不会再改变。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>kafka面试常遇问题</title>
    <link href="http://xubatian.cn/kafka%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%81%87%E9%97%AE%E9%A2%98/"/>
    <id>http://xubatian.cn/kafka%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%81%87%E9%97%AE%E9%A2%98/</id>
    <published>2022-02-10T03:16:03.000Z</published>
    <updated>2022-02-10T06:41:01.803Z</updated>
    
    <content type="html"><![CDATA[<ol><li>为什么要用消息队列？为什么选择了kafka?</li><li>kafka的组件与作用(架构)？</li><li>kafka为什么要分区？</li><li>Kafka生产者分区策略？</li><li>kafka的数据可靠性怎么保证？(丢，重)</li><li>kafka的副本机制？</li><li>kafka的消费分区分配策略？</li><li>kafka的offset怎么维护？</li><li>kafka为什么这么快？(高效读写数据)</li><li>Kafka消息数据积压，Kafka消费能力不足怎么处理？</li><li>kafka事务是怎么实现的？</li><li>Kafka中的数据是有序的吗？</li><li>Kafka可以按照时间消费数据？</li><li>Kafka单条日志传输大小？</li><li>Kafka参数优化？</li><li>Kafka适合以下应用场景？</li><li>Exactly Once语义？在流式计算中怎么保持？</li></ol><span id="more"></span><h2 id="解析参考"><a href="#解析参考" class="headerlink" title="解析参考"></a>解析参考</h2><h3 id="为什么要用消息队列"><a href="#为什么要用消息队列" class="headerlink" title="为什么要用消息队列"></a>为什么要用消息队列</h3><ol><li>解耦</li></ol><p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p><ol><li>可恢复性</li></ol><p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p><ol><li>缓冲</li></ol><p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p><ol><li>灵活性与峰值处理能力</li></ol><p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p><ol><li>异步通信</li></ol><p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p><h3 id="为什么选择了kafka"><a href="#为什么选择了kafka" class="headerlink" title="为什么选择了kafka"></a>为什么选择了kafka</h3><ol><li>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒。</li><li>可扩展性：kafka集群支持热扩展。</li><li>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失。</li><li>容错性：允许集群中节点故障（若副本数量为n,则允许n-1个节点故障）。</li><li>高并发：支持数千个客户端同时读写。</li></ol><h3 id="kafka的组件与作用-架构"><a href="#kafka的组件与作用-架构" class="headerlink" title="kafka的组件与作用(架构)"></a>kafka的组件与作用(架构)</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112112.png"></p><ol><li>Producer ：消息生产者，就是向kafka broker发消息的客户端。</li><li>Consumer ：消息消费者，向kafka broker取消息的客户端。</li><li>Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li><li>Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</li><li>Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic。</li><li>Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。</li><li>Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</li><li>leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</li><li>follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。</li></ol><h3 id="kafka为什么要分区"><a href="#kafka为什么要分区" class="headerlink" title="kafka为什么要分区"></a>kafka为什么要分区</h3><ol><li>方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了。</li><li>可以提高并发，因为可以以Partition为单位读写。</li></ol><h3 id="Kafka生产者分区策略"><a href="#Kafka生产者分区策略" class="headerlink" title="Kafka生产者分区策略"></a>Kafka生产者分区策略</h3><ol><li>指明 partition 的情况下，直接将指明的值直接作为partiton值。</li><li>没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到partition值。</li><li>既没有partition值又没有key值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与topic可用的partition总数取余得到partition值，也就是常说的round-robin算法。</li></ol><h3 id="kafka的数据可靠性怎么保证"><a href="#kafka的数据可靠性怎么保证" class="headerlink" title="kafka的数据可靠性怎么保证"></a>kafka的数据可靠性怎么保证</h3><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。所以引出ack机制。</p><p><strong>ack应答机制（可问：造成数据重复和丢失的相关问题）</strong></p><p>Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。acks参数配置：</p><ul><li>0：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据。</li><li>1：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据。</li></ul><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112241.png"></p><ul><li>-1（all）：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。</li></ul><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112315.png"></p><h3 id="副本数据同步策略"><a href="#副本数据同步策略" class="headerlink" title="副本数据同步策略"></a>副本数据同步策略</h3><table><thead><tr><th align="left">方案</th><th align="center">优点</th><th align="right">缺点</th></tr></thead><tbody><tr><td align="left">半数以上完成同步，就发送ack</td><td align="center">延迟低</td><td align="right">选举新的leader时，容忍n台节点的故障，需要2n+1个副本</td></tr><tr><td align="left">全部完成同步，才发送ack</td><td align="center">选举新的leader时，容忍n台节点的故障，需要n+1个副本</td><td align="right">延迟高</td></tr></tbody></table><p>选择最后一个的原因：</p><ol><li>同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</li><li>虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。</li></ol><h3 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h3><p>如果采用全部完成同步，才发送ack的副本的同步策略的话：提出问题：leader收到数据，所有follower都开始同步数据，但有一个follower，因为某种故障，迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步，才能发送ack。这个问题怎么解决呢？</p><p>Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</p><h3 id="故障处理-LEO与HW"><a href="#故障处理-LEO与HW" class="headerlink" title="故障处理(LEO与HW)"></a>故障处理(LEO与HW)</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112418.png"></p><p>LEO：指的是每个副本最大的offset。</p><p>HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。</p><h6 id="follower故障"><a href="#follower故障" class="headerlink" title="follower故障"></a>follower故障</h6><p>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</p><h6 id="leader故障"><a href="#leader故障" class="headerlink" title="leader故障"></a>leader故障</h6><p>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</p><p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p><p>问题纠正:</p><p> (1)ISR包含leader，不只是follower,所有的元数据都是Controller来维护的</p><p> (2)其实不是什么ack不ack的 Follower 发起 Fetcher请求 之后会返回 success ； 这就理解为  Follower向leader回复了ack，容易误解为ack是生产者和borker的关系。还有这句话应该是follow向leader反馈消息</p><h3 id="kafka的副本机制"><a href="#kafka的副本机制" class="headerlink" title="kafka的副本机制"></a>kafka的副本机制</h3><p>参考上一个问题(副本数据同步策略)。</p><h3 id="kafka的消费分区分配策略"><a href="#kafka的消费分区分配策略" class="headerlink" title="kafka的消费分区分配策略"></a>kafka的消费分区分配策略</h3><p>一个consumer group中有多个consumer，一个topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费 Kafka有三种分配策略，一是RoundRobin，一是Range。高版本还有一个StickyAssignor策略 将分区的所有权从一个消费者移到另一个消费者称为重新平衡（rebalance）。当以下事件发生时，Kafka 将会进行一次分区分配：</p><p>同一个 Consumer Group 内新增消费者。</p><p>消费者离开当前所属的Consumer Group，包括shuts down或crashes。</p><h6 id="Range分区分配策略"><a href="#Range分区分配策略" class="headerlink" title="Range分区分配策略"></a>Range分区分配策略</h6><p>Range是对每个Topic而言的（即一个Topic一个Topic分），首先对同一个Topic里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区。假如有10个分区，3个消费者线程，把分区按照序号排列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0，1，2，3，4，5，6，7，8，9</span><br></pre></td></tr></table></figure><p>消费者线程为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C1-0，C2-0，C2-1</span><br></pre></td></tr></table></figure><p>那么用partition数除以消费者线程的总数来决定每个消费者线程消费几个partition，如果除不尽，前面几个消费者将会多消费一个分区。在我们的例子里面，我们有10个分区，3个消费者线程，10/3 = 3，而且除除不尽，那么消费者线程C1-0将会多消费一个分区，所以最后分区分配的结果看起来是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C1-0：0，1，2，3</span><br><span class="line"></span><br><span class="line">C2-0：4，5，6</span><br><span class="line"></span><br><span class="line">C2-1：7，8，9</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果有11个分区将会是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">C1-0：0，1，2，3</span><br><span class="line"></span><br><span class="line">C2-0：4，5，6，7</span><br><span class="line"></span><br><span class="line">C2-1：8，9，10</span><br></pre></td></tr></table></figure><p>假如我们有两个主题T1,T2，分别有10个分区，最后的分配结果将会是这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">C1-0：T1（0，1，2，3） T2（0，1，2，3）</span><br><span class="line"></span><br><span class="line">C2-0：T1（4，5，6） T2（4，5，6）</span><br><span class="line"></span><br><span class="line">C2-1：T1（7，8，9） T2（7，8，9）</span><br></pre></td></tr></table></figure><h6 id="RoundRobinAssignor分区分配策略"><a href="#RoundRobinAssignor分区分配策略" class="headerlink" title="RoundRobinAssignor分区分配策略"></a>RoundRobinAssignor分区分配策略</h6><p>RoundRobinAssignor策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者. 使用RoundRobin策略有两个前提条件必须满足：</p><p>同一个消费者组里面的所有消费者的num.streams（消费者消费线程数）必须相等；每个消费者订阅的主题必须相同。加入按照 hashCode 排序完的topic-partitions组依次为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9</span><br></pre></td></tr></table></figure><p>我们的消费者线程排序为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C1-0, C1-1, C2-0, C2-1</span><br></pre></td></tr></table></figure><p>最后分区分配的结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C1-0 将消费 T1-5, T1-2, T1-6 分区</span><br><span class="line"></span><br><span class="line">C1-1 将消费 T1-3, T1-1, T1-9 分区</span><br><span class="line"></span><br><span class="line">C2-0 将消费 T1-0, T1-4 分区</span><br><span class="line"></span><br><span class="line">C2-1 将消费 T1-8, T1-7 分区</span><br></pre></td></tr></table></figure><h6 id="StickyAssignor分区分配策略"><a href="#StickyAssignor分区分配策略" class="headerlink" title="StickyAssignor分区分配策略"></a>StickyAssignor分区分配策略</h6><p>Kafka从0.11.x版本开始引入这种分配策略，它主要有两个目的：</p><p>分区的分配要尽可能的均匀，分配给消费者者的主题分区数最多相差一个 分区的分配尽可能的与上次分配的保持相同。当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目的，StickyAssignor策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂很多。</p><p>假设消费组内有3个消费者</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C0、C1、C2</span><br></pre></td></tr></table></figure><p>它们都订阅了4个主题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t0、t1、t2、t3</span><br></pre></td></tr></table></figure><p>并且每个主题有2个分区，也就是说整个消费组订阅了</p><p>t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区</p><p>最终的分配结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0、t1p1、t3p0</span><br><span class="line"></span><br><span class="line">消费者C1：t0p1、t2p0、t3p1</span><br><span class="line"></span><br><span class="line">消费者C2：t1p0、t2p1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样初看上去似乎与采用RoundRobinAssignor策略所分配的结果相同</p><p>此时假设消费者C1脱离了消费组，那么消费组就会执行再平衡操作，进而消费分区会重新分配。如果采用RoundRobinAssignor策略，那么此时的分配结果如下：</p><p>消费者C0：t0p0、t1p0、t2p0、t3p0</p><p>消费者C2：t0p1、t1p1、t2p1、t3p1</p><p>如分配结果所示，RoundRobinAssignor策略会按照消费者C0和C2进行重新轮询分配。而如果此时使用的是StickyAssignor策略，那么分配结果为：</p><p>消费者C0：t0p0、t1p1、t3p0、t2p0</p><p>消费者C2：t1p0、t2p1、t0p1、t3p1</p><p>可以看到分配结果中保留了上一次分配中对于消费者C0和C2的所有分配结果，并将原来消费者C1的“负担”分配给了剩余的两个消费者C0和C2，最终C0和C2的分配还保持了均衡。</p><p>如果发生分区重分配，那么对于同一个分区而言有可能之前的消费者和新指派的消费者不是同一个，对于之前消费者进行到一半的处理还要在新指派的消费者中再次复现一遍，这显然很浪费系统资源。StickyAssignor策略如同其名称中的“sticky”一样，让分配策略具备一定的“粘性”，尽可能地让前后两次分配相同，进而减少系统资源的损耗以及其它异常情况的发生。</p><p>到目前为止所分析的都是消费者的订阅信息都是相同的情况，我们来看一下订阅信息不同的情况下的处理。</p><p>举例，同样消费组内有3个消费者：</p><p>C0、C1、C2</p><p>集群中有3个主题：</p><p>t0、t1、t2</p><p>这3个主题分别有</p><p>1、2、3个分区</p><p>也就是说集群中有</p><p>t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0订阅了主题t0</span><br><span class="line"></span><br><span class="line">消费者C1订阅了主题t0和t1</span><br><span class="line"></span><br><span class="line">消费者C2订阅了主题t0、t1和t2</span><br></pre></td></tr></table></figure><p>如果此时采用RoundRobinAssignor策略：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0</span><br><span class="line"></span><br><span class="line">消费者C1：t1p0</span><br><span class="line"></span><br><span class="line">消费者C2：t1p1、t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>如果此时采用的是StickyAssignor策略：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">消费者C0：t0p0</span><br><span class="line"></span><br><span class="line">消费者C1：t1p0、t1p1</span><br><span class="line"></span><br><span class="line">消费者C2：t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>此时消费者C0脱离了消费组，那么RoundRobinAssignor策略的分配结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">消费者C1：t0p0、t1p1</span><br><span class="line"></span><br><span class="line">消费者C2：t1p0、t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>StickyAssignor策略，那么分配结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">消费者C1：t1p0、t1p1、t0p0</span><br><span class="line"></span><br><span class="line">消费者C2：t2p0、t2p1、t2p2</span><br></pre></td></tr></table></figure><p>可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配：</p><p>t1p0、t1p1、t2p0、t2p1、t2p2。</p><p>从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异，这个策略的代码实现也是异常复杂。</p><h3 id="kafka的offset怎么维护"><a href="#kafka的offset怎么维护" class="headerlink" title="kafka的offset怎么维护"></a>kafka的offset怎么维护</h3><p>Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112614.png"></p><p>从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</p><p>额外补充：实际开发场景中在Spark和Flink中，可以自己手动提交kafka的offset，或者是flink两阶段提交自动提交offset。</p><h3 id="kafka为什么这么快"><a href="#kafka为什么这么快" class="headerlink" title="kafka为什么这么快"></a>kafka为什么这么快</h3><ol><li>Kafka本身是分布式集群，同时采用分区技术，并发度高。</li><li>顺序写磁盘</li></ol><p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。</p><ol><li>零拷贝技术</li></ol><p>零拷贝并不是不需要拷贝，而是减少不必要的拷贝次数。通常是说在IO读写过程中。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210112638.png"></p><p>传统IO流程：</p><p>第一次：将磁盘文件，读取到操作系统内核缓冲区。</p><p>第二次：将内核缓冲区的数据，copy到application应用程序的buffer。</p><p>第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)</p><p>第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。</p><p>传统方式，读取磁盘文件并进行网络发送，经过的四次数据copy是非常繁琐的。实际IO读写，需要进行IO中断，需要CPU响应中断(带来上下文切换)，尽管后来引入DMA来接管CPU的中断请求，但四次copy是存在“不必要的拷贝”的。</p><p>重新思考传统IO方式，会注意到实际上并不需要第二个和第三个数据副本。应用程序除了缓存数据并将其传输回套接字缓冲区之外什么都不做。相反，数据可以直接从读缓冲区传输到套接字缓冲区。</p><p>显然，第二次和第三次数据copy 其实在这种场景下没有什么帮助反而带来开销，这也正是零拷贝出现的意义。</p><p>所以零拷贝是指读取磁盘文件后，不需要做其他处理，直接用网络发送出去。</p><h3 id="Kafka消费能力不足怎么处理"><a href="#Kafka消费能力不足怎么处理" class="headerlink" title="Kafka消费能力不足怎么处理"></a>Kafka消费能力不足怎么处理</h3><ol><li>如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）</li><li>如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间&lt;生产速度），使处理的数据小于生产的数据，也会造成数据积压。</li></ol><h3 id="kafka事务是怎么实现的"><a href="#kafka事务是怎么实现的" class="headerlink" title="kafka事务是怎么实现的"></a>kafka事务是怎么实现的</h3><p>Kafka从0.11版本开始引入了事务支持。事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p><h6 id="Producer事务"><a href="#Producer事务" class="headerlink" title="Producer事务"></a>Producer事务</h6><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID。为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p><h6 id="Consumer事务"><a href="#Consumer事务" class="headerlink" title="Consumer事务"></a>Consumer事务</h6><p>对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</p><h3 id="Kafka中的数据是有序的吗"><a href="#Kafka中的数据是有序的吗" class="headerlink" title="Kafka中的数据是有序的吗"></a>Kafka中的数据是有序的吗</h3><p>单分区内有序。</p><p>多分区，分区与分区间无序。</p><h3 id="Kafka可以按照时间消费数据吗"><a href="#Kafka可以按照时间消费数据吗" class="headerlink" title="Kafka可以按照时间消费数据吗"></a>Kafka可以按照时间消费数据吗</h3><p>可以，提供的API方法：</p><p>KafkaUtil.fetchOffsetsWithTimestamp(topic, sTime, kafkaProp)</p><h3 id="Kafka单条日志传输大小"><a href="#Kafka单条日志传输大小" class="headerlink" title="Kafka单条日志传输大小"></a>Kafka单条日志传输大小</h3><p>kafka对于消息体的大小默认为单条最大值是1M但是在我们应用场景中, 常常会出现一条消息大于1M，如果不对kafka进行配置。则会出现生产者无法将消息推送到kafka或消费者无法去消费kafka里面的数据, 这时我们就要对kafka进行以下配置：server.properties</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">replica.fetch.max.bytes: 1048576  broker可复制的消息的最大字节数, 默认为1M</span><br><span class="line">message.max.bytes: 1000012   kafka 会接收单个消息size的最大限制， 默认为1M左右</span><br><span class="line"></span><br><span class="line">message.max.bytes必须小于等于replica.fetch.max.bytes，否则就会导致replica之间数据同步失败</span><br></pre></td></tr></table></figure><h3 id="Kafka参数优化"><a href="#Kafka参数优化" class="headerlink" title="Kafka参数优化"></a>Kafka参数优化</h3><h6 id="Broker参数配置（server-properties）"><a href="#Broker参数配置（server-properties）" class="headerlink" title="Broker参数配置（server.properties）"></a>Broker参数配置（server.properties）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1、日志保留策略配置</span><br><span class="line"># 保留三天，也可以更短 （log.cleaner.delete.retention.ms）</span><br><span class="line">log.retention.hours=72</span><br><span class="line"></span><br><span class="line">2、Replica相关配置</span><br><span class="line">default.replication.factor:1 默认副本1个</span><br><span class="line"></span><br><span class="line">3、网络通信延时</span><br><span class="line">replica.socket.timeout.ms:30000 #当集群之间网络不稳定时,调大该参数</span><br><span class="line">replica.lag.time.max.ms= 600000# 如果网络不好,或者kafka集群压力较大,会出现副本丢失,然后会频繁复制副本,导致集群压力更大,此时可以调大该参数。</span><br></pre></td></tr></table></figure><h6 id="Producer优化（producer-properties）"><a href="#Producer优化（producer-properties）" class="headerlink" title="Producer优化（producer.properties）"></a>Producer优化（producer.properties）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">compression.type:none                 gzip  snappy  lz4  </span><br><span class="line">#默认发送不进行压缩，推荐配置一种适合的压缩算法，可以大幅度的减缓网络压力和Broker的存储压力。</span><br></pre></td></tr></table></figure><h6 id="Kafka内存调整（kafka-server-start-sh）"><a href="#Kafka内存调整（kafka-server-start-sh）" class="headerlink" title="Kafka内存调整（kafka-server-start.sh）"></a>Kafka内存调整（kafka-server-start.sh）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">默认内存1个G，生产环境尽量不要超过6个G。</span><br><span class="line">export KAFKA_HEAP_OPTS=&quot;-Xms4g -Xmx4g&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Kafka适合以下应用场景"><a href="#Kafka适合以下应用场景" class="headerlink" title="Kafka适合以下应用场景"></a>Kafka适合以下应用场景</h3><ol><li>日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer。</li><li>消息系统：解耦生产者和消费者、缓存消息等。</li><li>用户活动跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后消费者通过订阅这些topic来做实时的监控分析，亦可保存到数据库。</li><li>运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；</li><li>流式处理：比如spark和flink。</li></ol><h3 id="Exactly-Once语义"><a href="#Exactly-Once语义" class="headerlink" title="Exactly Once语义"></a>Exactly Once语义</h3><p>将服务器的ACK级别设置为-1，可以保证Producer到Server之间不会丢失数据，即At Least Once语义。相对的，将服务器ACK级别设置为0，可以保证生产者每条消息只会被发送一次，即At Most Once语义。</p><p>At Least Once可以保证数据不丢失，但是不能保证数据不重复；</p><p>相对的，At Least Once可以保证数据不重复，但是不能保证数据不丢失。</p><p>但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即Exactly Once语义。在0.11版本以前的Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11版本的Kafka，引入了一项重大特性：幂等性。</p><p>开启幂等性enable.idempotence=true。</p><p>所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条。幂等性结合At Least Once语义，就构成了Kafka的Exactly Once语义。即：</p><p>At Least Once + 幂等性 = Exactly Once</p><p>Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带Sequence Number。而Broker端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。</p><p>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once。</p><h3 id="补充，在流式计算中怎么Exactly-Once语义？以flink为例"><a href="#补充，在流式计算中怎么Exactly-Once语义？以flink为例" class="headerlink" title="补充，在流式计算中怎么Exactly Once语义？以flink为例"></a>补充，在流式计算中怎么Exactly Once语义？以flink为例</h3><h4 id="souce"><a href="#souce" class="headerlink" title="souce"></a>souce</h4><p>souce使用执行ExactlyOnce的数据源，比如kafka等</p><p>内部使用FlinkKafakConsumer，并开启CheckPoint，偏移量会保存到StateBackend中，并且默认会将偏移量写入到topic中去，即_consumer_offsets Flink设置CheckepointingModel.EXACTLY_ONCE</p><h4 id="sink"><a href="#sink" class="headerlink" title="sink"></a>sink</h4><p>存储系统支持覆盖也即幂等性：如Redis,Hbase,ES等 存储系统不支持覆：需要支持事务(预写式日志或者两阶段提交),两阶段提交可参考Flink集成的kafka sink的实现。</p><p>知识源于积累,登峰造极源于自律!</p><p>好文章就得收藏慢慢品, 文章转载于: <a href="https://mp.weixin.qq.com/s/_bZvPeAgC64ENzhIzydjSA">https://mp.weixin.qq.com/s/_bZvPeAgC64ENzhIzydjSA</a></p>]]></content>
    
    
    <summary type="html">&lt;ol&gt;
&lt;li&gt;为什么要用消息队列？为什么选择了kafka?&lt;/li&gt;
&lt;li&gt;kafka的组件与作用(架构)？&lt;/li&gt;
&lt;li&gt;kafka为什么要分区？&lt;/li&gt;
&lt;li&gt;Kafka生产者分区策略？&lt;/li&gt;
&lt;li&gt;kafka的数据可靠性怎么保证？(丢，重)&lt;/li&gt;
&lt;li&gt;kafka的副本机制？&lt;/li&gt;
&lt;li&gt;kafka的消费分区分配策略？&lt;/li&gt;
&lt;li&gt;kafka的offset怎么维护？&lt;/li&gt;
&lt;li&gt;kafka为什么这么快？(高效读写数据)&lt;/li&gt;
&lt;li&gt;Kafka消息数据积压，Kafka消费能力不足怎么处理？&lt;/li&gt;
&lt;li&gt;kafka事务是怎么实现的？&lt;/li&gt;
&lt;li&gt;Kafka中的数据是有序的吗？&lt;/li&gt;
&lt;li&gt;Kafka可以按照时间消费数据？&lt;/li&gt;
&lt;li&gt;Kafka单条日志传输大小？&lt;/li&gt;
&lt;li&gt;Kafka参数优化？&lt;/li&gt;
&lt;li&gt;Kafka适合以下应用场景？&lt;/li&gt;
&lt;li&gt;Exactly Once语义？在流式计算中怎么保持？&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="kafka" scheme="http://xubatian.cn/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>为什么要知道Hadoop机架感知？</title>
    <link href="http://xubatian.cn/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%9F%A5%E9%81%93Hadoop%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%9F/"/>
    <id>http://xubatian.cn/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%9F%A5%E9%81%93Hadoop%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%9F/</id>
    <published>2022-02-10T02:59:13.000Z</published>
    <updated>2022-02-10T06:41:07.957Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、首先，我为什么聊机架感知"><a href="#一、首先，我为什么聊机架感知" class="headerlink" title="一、首先，我为什么聊机架感知"></a><strong>一、首先，我为什么聊机架感知</strong></h4><p> 在了解hdfs<a href="https://cloud.tencent.com/product/clb?from=10680">负载均衡</a>时，需要获取DataNode情况，包括每个DataNode磁盘使用情况，获取到数据不均衡，就要做负载均衡处理。做负载均衡就要考虑热点数据发送到哪里去，集群服务器配置是否相同，机架使用情况等。</p><p> 机架感知在这里面有3个很重要的原因：</p><p>1、数据扩容，扩容的服务器在新机架上，导致数据不均衡</p><p>2、机架上的服务器磁盘配置不同（至于为什么，先不细聊）</p><p>通过感知机架，方便系统管理员手动操作，从而实现负载均衡</p><p>3、副本策略三副本，同节点、同机架、不同机架（同机房），可以实现保证有效存储时同时最大化安全策略</p><p>​                                                                                                                        </p><span id="more"></span><p><strong>机架图</strong></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210110107.png"></p><h4 id="二、关于机架感知"><a href="#二、关于机架感知" class="headerlink" title="二、关于机架感知"></a><strong>二、关于机架感知</strong></h4><ol><li>Hadoop不能自动获取节点是否分布在多机架上</li><li>Hadoop大规模集群才会存在跨机架</li><li>不同节点之间通信尽量发生在同一个机架（可用性）</li><li>数据块副本策略会跨机架（容错性）</li></ol><h4 id="三、机架感知配置"><a href="#三、机架感知配置" class="headerlink" title="三、机架感知配置"></a><strong>三、机架感知配置</strong></h4><p>1、自定义类实现 DNSToSwitchMapping，重写 resolve() 方法；打为 jar 包，并复制到 NameNode 节点的 /soft/hadoop/shared/hadoop/common/lib 目录下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 机架感知类</span><br><span class="line"> */</span><br><span class="line">public class MyRackAware implements DNSToSwitchMapping &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 根据需求，将不同的主机划分到不同的机架上</span><br><span class="line">     * @param names 数据节点主机的集合</span><br><span class="line">     * @return 机架感知的集合</span><br><span class="line">     */</span><br><span class="line">    public List&lt;String&gt; resolve(List&lt;String&gt; names) &#123;</span><br><span class="line">        List&lt;String&gt; list = new ArrayList&lt;String&gt;();</span><br><span class="line">        try &#123;</span><br><span class="line">            //将原始信息输出到目录，方便查看</span><br><span class="line">            FileWriter fw = new FileWriter(&quot;/home/centos/rackaware.txt&quot;);</span><br><span class="line">            for (String host : names) &#123;</span><br><span class="line">                //将输入的原始host写入文件</span><br><span class="line">                fw.append(host+&quot;/r/n&quot;);</span><br><span class="line"> </span><br><span class="line">                //进行原始的host进行分机架</span><br><span class="line">                // IP形式</span><br><span class="line">                if (host.startsWith(&quot;192&quot;)) &#123;</span><br><span class="line">                    String ipEnd = host.substring(host.lastIndexOf(&quot;.&quot;) + 1);</span><br><span class="line">                    if (Integer.parseInt(ipEnd) &lt;= 103) &#123; //s102,s103 在一个机架</span><br><span class="line">                        list.add(&quot;/rack1/&quot; + ipEnd);</span><br><span class="line">                    &#125; else &#123;                              //s104 在一个机架</span><br><span class="line">                        list.add(&quot;/rack2/&quot; + ipEnd);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //主机名形式</span><br><span class="line">                else if (host.startsWith(&quot;s&quot;)) &#123;</span><br><span class="line">                    String ipEnd = host.substring(1);</span><br><span class="line">                    if (Integer.parseInt(ipEnd) &lt;= 103) &#123; //s102,s103 在一个机架</span><br><span class="line">                        list.add(&quot;/rack1/&quot; + ipEnd);</span><br><span class="line">                    &#125; else &#123;                              //s104 在一个机架</span><br><span class="line">                        list.add(&quot;/rack2/&quot; + ipEnd);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            fw.close();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        return list;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public void reloadCachedMappings() &#123;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public void reloadCachedMappings(List&lt;String&gt; names) &#123;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、配置core-site.xml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;net.topology.node.switch.mapping.impl&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.fresher.hdfs.rackaware.MyRackAware&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>3、重启集群</p><h4 id="四、机架感知（来自官网）"><a href="#四、机架感知（来自官网）" class="headerlink" title="四、机架感知（来自官网）"></a><strong>四、机架感知（来自官网）</strong></h4><p> Hadoop 组件是机架感知的。例如，HDFS 块放置将通过将一个块副本放置在不同的机架上来使用机架感知来实现容错。这在网络交换机故障或集群内分区的情况下提供数据可用性。</p><p> Hadoop 主守护进程通过调用配置文件指定的外部脚本或 java 类来获取集群工作线程的机架 ID。使用 java 类或外部脚本进行拓扑，输出必须遵循 java <strong>org.apache.hadoop.net.DNSToSwitchMapping</strong>接口。接口期望保持一一对应，拓扑信息格式为’/myrack/myhost’，其中’/‘为拓扑分隔符，’myrack’为机架标识，’myhost’为个人主机。假设每个机架有一个 /24 子网，可以使用“/192.168.100.0/192.168.100.5”格式作为唯一的机架-主机拓扑映射。</p><p> 要使用java 类进行拓扑映射，类名由配置文件中的<strong>net.topology.node.switch.mapping.impl</strong>参数指定。一个示例 NetworkTopology.java 包含在 hadoop 发行版中，可由 Hadoop 管理员自定义。使用 Java 类而不是外部脚本具有性能优势，因为当新的工作节点注册自己时，Hadoop 不需要分叉外部进程。</p><p> 如果实现外部脚本，它将在配置文件中使用<strong>net.topology.script.file.name</strong>参数指定。与 java 类不同，外部拓扑脚本不包含在 Hadoop 发行版中，而是由管理员提供。Hadoop 在 fork 拓扑脚本时会向 ARGV 发送多个 IP 地址。发送到拓扑脚本的 IP 地址数由<strong>net.topology.script.number.args</strong>控制，默认为 100。如果将<strong>net.topology.script.number.args</strong>更改为 1，则拓扑脚本将为每个由 DataNodes 和/或 NodeManagers 提交的 IP。</p><p> 如果<strong>net.topology.script.file.name</strong>或<strong>net.topology.node.switch.mapping.impl</strong>未设置，则为任何传递的 IP 地址返回机架 ID ‘/default-rack’。虽然这种行为看起来很可取，但它可能会导致 HDFS 块复制问题，因为默认行为是将一个复制块写到机架外，并且无法这样做，因为只有一个名为“/default-rack”的机架。</p><p><strong>python Example</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python3</span><br><span class="line"># this script makes assumptions about the physical environment.</span><br><span class="line">#  1) each rack is its own layer 3 network with a /24 subnet, which</span><br><span class="line"># could be typical where each rack has its own</span><br><span class="line">#     switch with uplinks to a central core router.</span><br><span class="line">#</span><br><span class="line">#             +-----------+</span><br><span class="line">#             |core router|</span><br><span class="line">#             +-----------+</span><br><span class="line">#            /             \</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   |rack switch|        |rack switch|</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   | data node |        | data node |</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#   | data node |        | data node |</span><br><span class="line">#   +-----------+        +-----------+</span><br><span class="line">#</span><br><span class="line"># 2) topology script gets list of IP&#x27;s as input, calculates network address, and prints &#x27;/network_address/ip&#x27;.</span><br><span class="line"></span><br><span class="line">import netaddr</span><br><span class="line">import sys</span><br><span class="line">sys.argv.pop(0)                                                  # discard name of topology script from argv list as we just want IP addresses</span><br><span class="line"></span><br><span class="line">netmask = &#x27;255.255.255.0&#x27;                                        # set netmask to what&#x27;s being used in your environment.  The example uses a /24</span><br><span class="line"></span><br><span class="line">for ip in sys.argv:                                              # loop over list of datanode IP&#x27;s</span><br><span class="line">    address = &#x27;&#123;0&#125;/&#123;1&#125;&#x27;.format(ip, netmask)                      # format address string so it looks like &#x27;ip/netmask&#x27; to make netaddr work</span><br><span class="line">    try:</span><br><span class="line">        network_address = netaddr.IPNetwork(address).network     # calculate and print network address</span><br><span class="line">        print(&quot;/&#123;0&#125;&quot;.format(network_address))</span><br><span class="line">    except:</span><br><span class="line">        print(&quot;/rack-unknown&quot;)                                   # print catch-all value if unable to calculate network address</span><br></pre></td></tr></table></figure><p><strong>bash Example</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line"># Here&#x27;s a bash example to show just how simple these scripts can be</span><br><span class="line"># Assuming we have flat network with everything on a single switch, we can fake a rack topology.</span><br><span class="line"># This could occur in a lab environment where we have limited nodes,like 2-8 physical machines on a unmanaged switch.</span><br><span class="line"># This may also apply to multiple virtual machines running on the same physical hardware.</span><br><span class="line"># The number of machines isn&#x27;t important, but that we are trying to fake a network topology when there isn&#x27;t one.</span><br><span class="line">#</span><br><span class="line">#       +----------+    +--------+</span><br><span class="line">#       |jobtracker|    |datanode|</span><br><span class="line">#       +----------+    +--------+</span><br><span class="line">#              \        /</span><br><span class="line">#  +--------+  +--------+  +--------+</span><br><span class="line">#  |datanode|--| switch |--|datanode|</span><br><span class="line">#  +--------+  +--------+  +--------+</span><br><span class="line">#              /        \</span><br><span class="line">#       +--------+    +--------+</span><br><span class="line">#       |datanode|    |namenode|</span><br><span class="line">#       +--------+    +--------+</span><br><span class="line">#</span><br><span class="line"># With this network topology, we are treating each host as a rack.  This is being done by taking the last octet</span><br><span class="line"># in the datanode&#x27;s IP and prepending it with the word &#x27;/rack-&#x27;.  The advantage for doing this is so HDFS</span><br><span class="line"># can create its &#x27;off-rack&#x27; block copy.</span><br><span class="line"># 1) &#x27;echo $@&#x27; will echo all ARGV values to xargs.</span><br><span class="line"># 2) &#x27;xargs&#x27; will enforce that we print a single argv value per line</span><br><span class="line"># 3) &#x27;awk&#x27; will split fields on dots and append the last field to the string &#x27;/rack-&#x27;. If awk</span><br><span class="line">#    fails to split on four dots, it will still print &#x27;/rack-&#x27; last field value</span><br><span class="line"></span><br><span class="line">echo $@ | xargs -n 1 | awk -F &#x27;.&#x27; &#x27;&#123;print &quot;/rack-&quot;$NF&#125;&#x27;</span><br></pre></td></tr></table></figure><h4 id="五、Hadoop集群网络拓扑描述"><a href="#五、Hadoop集群网络拓扑描述" class="headerlink" title="五、Hadoop集群网络拓扑描述"></a><strong>五、Hadoop集群网络拓扑描述</strong></h4><p>Hadoop集群架构通常包含两级网络拓扑，一般来说，各级机架装配30~40个服务器。</p><blockquote><p>一个机架配置一个交换机，一个交换机实际的连接能力取决于交换机的端口数量，交换机的端口数量最多是48个</p></blockquote><p>为了达到Hadoop的最佳性能，配置Hadoop系统以让其了解网络拓扑状况就极为关键。</p><p>如果集群只包含一个机架，无需做什么，就是默认配置。对于多机架的集群来说，描述清楚节点-机架的映射关系，使得Hadoop将MapReduce任务分配到各个节点时，会倾向于执行机架内的数据传输，而非跨机架数据传输。HDFS还能更加智能地防止副本，以uqde性能和弹性的平衡。</p><p>重点！！！</p><p>节点和机架等网络位置以树的形式来表示，从而能够体现出各个位置之间的网络距离。namenode使用网络位置来确定在哪里防止块的副本。MapReduce的调度器根据网络位置来查找最近的副本，将它作为map任务的输入。</p><blockquote><p>比如spark中提到的移动数据不如移动计算也是同理。又比如yarn任务提交流程中，启动多个task，在哪启动的，现在是不是很清楚了。</p></blockquote><p>综上，回头文章开头，为什么要做负载均衡，为什么要了解机架感知，数据和计算是互相影响的。</p><p>文章转载于”大数据最后一公里公众号”, 原址: <a href="https://cloud.tencent.com/developer/article/1856190">https://cloud.tencent.com/developer/article/1856190</a></p><p>知识源于积累,登峰造极源于自律.</p>]]></content>
    
    
    <summary type="html">&lt;h4 id=&quot;一、首先，我为什么聊机架感知&quot;&gt;&lt;a href=&quot;#一、首先，我为什么聊机架感知&quot; class=&quot;headerlink&quot; title=&quot;一、首先，我为什么聊机架感知&quot;&gt;&lt;/a&gt;&lt;strong&gt;一、首先，我为什么聊机架感知&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt; 在了解hdfs&lt;a href=&quot;https://cloud.tencent.com/product/clb?from=10680&quot;&gt;负载均衡&lt;/a&gt;时，需要获取DataNode情况，包括每个DataNode磁盘使用情况，获取到数据不均衡，就要做负载均衡处理。做负载均衡就要考虑热点数据发送到哪里去，集群服务器配置是否相同，机架使用情况等。&lt;/p&gt;
&lt;p&gt; 机架感知在这里面有3个很重要的原因：&lt;/p&gt;
&lt;p&gt;1、数据扩容，扩容的服务器在新机架上，导致数据不均衡&lt;/p&gt;
&lt;p&gt;2、机架上的服务器磁盘配置不同（至于为什么，先不细聊）&lt;/p&gt;
&lt;p&gt;通过感知机架，方便系统管理员手动操作，从而实现负载均衡&lt;/p&gt;
&lt;p&gt;3、副本策略三副本，同节点、同机架、不同机架（同机房），可以实现保证有效存储时同时最大化安全策略&lt;/p&gt;
&lt;p&gt;​                                                                                                                        &lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="hadoop" scheme="http://xubatian.cn/tags/hadoop/"/>
    
    <category term="机架感知" scheme="http://xubatian.cn/tags/%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5/"/>
    
  </entry>
  
  <entry>
    <title>Flink读取无界流数据计算过程演示</title>
    <link href="http://xubatian.cn/Flink%E8%AF%BB%E5%8F%96%E6%97%A0%E7%95%8C%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/"/>
    <id>http://xubatian.cn/Flink%E8%AF%BB%E5%8F%96%E6%97%A0%E7%95%8C%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/</id>
    <published>2022-02-10T02:07:21.000Z</published>
    <updated>2022-02-10T02:25:25.113Z</updated>
    
    <content type="html"><![CDATA[<p>Flink有界流式读取文本数据计算过程演示</p><span id="more"></span><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-10_10-12-09.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink有界流式读取文本数据计算过程演示&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink有界流式读取文本数据计算过程演示</title>
    <link href="http://xubatian.cn/Flink%E6%B5%81%E5%BC%8F%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/"/>
    <id>http://xubatian.cn/Flink%E6%B5%81%E5%BC%8F%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E6%BC%94%E7%A4%BA/</id>
    <published>2022-02-07T16:22:27.000Z</published>
    <updated>2022-02-10T02:17:20.844Z</updated>
    
    <content type="html"><![CDATA[<p>Flink流式读取文本数据计算过程演示. 文本数据总有一刻能读的完,所以他是有界的. 无界流读的是kafka的数据.</p><p>Flink是懒加载的,第一遍会检测整体代码.</p><p>并行度设置为1,就是单线程执行,所以Flink是一行一行读取文本数据的, 读一行计算一行. </p><p>sum算子是有状态的. 所以他的历史数据是保存在sum算子里面.sum算子做聚合计算的,他是一个有状态的算子.</p><p>批处理最终是输出一次,而流处理来一条计算一条.所以他保留了状态.方便后面来一条和前面对比进行计算.</p><span id="more"></span><p>源码地址: <a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.14.3-Demo/src/main/java/www/xubatian/cn/FlinkDemo01/Flink_WordCount_Bounded.java">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.14.3-Demo/src/main/java/www/xubatian/cn/FlinkDemo01/Flink_WordCount_Bounded.java</a></p><p>结果演示:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210091224.png"></p><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/2022-02-08_00-18-10.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink流式读取文本数据计算过程演示. 文本数据总有一刻能读的完,所以他是有界的. 无界流读的是kafka的数据.&lt;/p&gt;
&lt;p&gt;Flink是懒加载的,第一遍会检测整体代码.&lt;/p&gt;
&lt;p&gt;并行度设置为1,就是单线程执行,所以Flink是一行一行读取文本数据的, 读一行计算一行. &lt;/p&gt;
&lt;p&gt;sum算子是有状态的. 所以他的历史数据是保存在sum算子里面.sum算子做聚合计算的,他是一个有状态的算子.&lt;/p&gt;
&lt;p&gt;批处理最终是输出一次,而流处理来一条计算一条.所以他保留了状态.方便后面来一条和前面对比进行计算.&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Mybatis介绍之缓存</title>
    <link href="http://xubatian.cn/Mybatis%E4%BB%8B%E7%BB%8D%E4%B9%8B%E7%BC%93%E5%AD%98/"/>
    <id>http://xubatian.cn/Mybatis%E4%BB%8B%E7%BB%8D%E4%B9%8B%E7%BC%93%E5%AD%98/</id>
    <published>2022-02-07T14:25:10.000Z</published>
    <updated>2022-02-07T15:39:35.907Z</updated>
    
    <content type="html"><![CDATA[<p>Mybatis中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存1024条SQL。二级缓存是指可以跨SqlSession的缓存。 </p><p>​    Mybatis中进行SQL查询是通过org.apache.ibatis.executor.Executor接口进行的，总体来讲，它一共有两类实现，一类是BaseExecutor，一类是CachingExecutor。前者是非启用二级缓存时使用的，而后者是采用的装饰器模式，在启用了二级缓存时使用，当二级缓存没有命中时，底层还是通过BaseExecutor来实现的。</p> <span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207233751.png"></p><h1 id="Mybatis介绍之缓存"><a href="#Mybatis介绍之缓存" class="headerlink" title="Mybatis介绍之缓存"></a>Mybatis介绍之缓存</h1><h2 id="一级缓存"><a href="#一级缓存" class="headerlink" title="一级缓存"></a>一级缓存</h2><p> 一级缓存是默认启用的，在BaseExecutor的query()方法中实现，底层默认使用的是PerpetualCache实现，PerpetualCache采用HashMap存储数据。一级缓存会在进行增、删、改操作时进行清除。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ErrorContext.instance().resource(ms.getResource()).activity(<span class="string">&quot;executing a query&quot;</span>).object(ms.getId());</span><br><span class="line">    <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span> &amp;&amp; ms.isFlushCacheRequired()) &#123;</span><br><span class="line">      clearLocalCache();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;E&gt; list;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      queryStack++;</span><br><span class="line">      list = resultHandler == <span class="keyword">null</span> ? (List&lt;E&gt;) localCache.getObject(key) : <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      queryStack--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (DeferredLoad deferredLoad : deferredLoads) &#123;</span><br><span class="line">        deferredLoad.load();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// issue #601</span></span><br><span class="line">      deferredLoads.clear();</span><br><span class="line">      <span class="keyword">if</span> (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123;</span><br><span class="line">        <span class="comment">// issue #482</span></span><br><span class="line">        clearLocalCache();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> list;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>一级缓存的范围有SESSION和STATEMENT两种，默认是SESSION，如果我们不需要使用一级缓存，那么我们可以把一级缓存的范围指定为STATEMENT，这样每次执行完一个Mapper语句后都会将一级缓存清除。如果只是需要对某一条select语句禁用一级缓存，则可以在对应的select元素上加上flushCache=”true”。如果需要更改一级缓存的范围，请在Mybatis的配置文件中，在<settings>下通过localCacheScope指定。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;</span><br></pre></td></tr></table></figure><p>为了验证一级缓存，我们进行如下测试，在testCache1中，我们通过同一个SqlSession查询了两次一样的SQL，第二次不会发送SQL。在testCache2中，我们也是查询了两次一样的SQL，但是它们是不同的SqlSession，结果会发送两次SQL请求。需要注意的是当Mybatis整合Spring后，直接通过Spring注入Mapper的形式，如果不是在同一个事务中每个Mapper的每次查询操作都对应一个全新的SqlSession实例，这个时候就不会有一级缓存的命中，如有需要可以启用二级缓存。而在同一个事务中时共用的就是同一个SqlSession。这块有兴趣的朋友可以去查看MapperFactoryBean的源码，其父类SqlSessionDaoSupport在设置SqlSessionFactory或设置SqlSessionTemplate时的逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 默认是有一级缓存的，一级缓存只针对于使用同一个SqlSession的情况。&lt;br/&gt;</span></span><br><span class="line"><span class="comment">  * 注意：当使用Spring整合后的Mybatis，不在同一个事务中的Mapper接口对应的操作也是没有一级缓存的，因为它们是对应不同的SqlSession。在本示例中如需要下面的第二个语句可使用一级缓存，需要testCache()方法在一个事务中，使用<span class="doctag">@Transactional</span>标注。</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="meta">@Test</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCache</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    PersonMapper mapper = session.getMapper(PersonMapper.class);</span><br><span class="line">    mapper.findById(<span class="number">5L</span>);</span><br><span class="line">    mapper.findById(<span class="number">5L</span>);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="meta">@Test</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCache2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    SqlSession session1 = <span class="keyword">this</span>.sessionFactory.openSession();</span><br><span class="line">    SqlSession session2 = <span class="keyword">this</span>.sessionFactory.openSession();</span><br><span class="line">    session1.getMapper(PersonMapper.class).findById(<span class="number">5L</span>);</span><br><span class="line">    session2.getMapper(PersonMapper.class).findById(<span class="number">5L</span>);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="二级缓存"><a href="#二级缓存" class="headerlink" title="二级缓存"></a>二级缓存</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>二级缓存是默认启用的，如想取消，则可以通过Mybatis配置文件中的<settings>元素下的子元素<setting>来指定cacheEnabled为false。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;settings&gt;</span><br><span class="line">    &lt;setting name=<span class="string">&quot;cacheEnabled&quot;</span> value=<span class="string">&quot;false&quot;</span> /&gt;</span><br><span class="line"> &lt;/settings&gt;</span><br></pre></td></tr></table></figure><p>cacheEnabled默认是启用的，只有在该值为true的时候，底层使用的Executor才是支持二级缓存的CachingExecutor。具体可参考Mybatis的核心配置类org.apache.ibatis.session.Configuration的newExecutor方法实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Executor <span class="title">newExecutor</span><span class="params">(Transaction transaction, ExecutorType executorType)</span> </span>&#123;</span><br><span class="line">   executorType = executorType == <span class="keyword">null</span> ? defaultExecutorType : executorType;</span><br><span class="line">   executorType = executorType == <span class="keyword">null</span> ? ExecutorType.SIMPLE : executorType;</span><br><span class="line">   Executor executor;</span><br><span class="line">   <span class="keyword">if</span> (ExecutorType.BATCH == executorType) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> BatchExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ExecutorType.REUSE == executorType) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> ReuseExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> SimpleExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (cacheEnabled) &#123;</span><br><span class="line">     executor = <span class="keyword">new</span> CachingExecutor(executor);</span><br><span class="line">   &#125;</span><br><span class="line">   executor = (Executor) interceptorChain.pluginAll(executor);</span><br><span class="line">   <span class="keyword">return</span> executor;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>要使用二级缓存除了上面一个配置外，我们还需要在我们对应的Mapper.xml文件中定义需要使用的cache，具体可以参考CachingExecutor的以下实现，其中使用的cache就是我们在对应的Mapper.xml中定义的cache。还有一个条件就是需要当前的查询语句是配置了使用cache的，即下面源码的useCache()是返回true的，默认情况下所有select语句的useCache都是true，如果我们在启用了二级缓存后，有某个查询语句是我们不想缓存的，则可以通过指定其useCache为false来达到对应的效果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">  public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span><br><span class="line">      throws SQLException &#123;</span><br><span class="line">    Cache cache = ms.getCache();</span><br><span class="line">    if (cache != null) &#123;</span><br><span class="line">      flushCacheIfRequired(ms);</span><br><span class="line">      if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123;</span><br><span class="line">        ensureNoOutParams(ms, parameterObject, boundSql);</span><br><span class="line">        @SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">        List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key);</span><br><span class="line">        if (list == null) &#123;</span><br><span class="line">          list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">          tcm.putObject(cache, key, list); // issue #578 and #116</span><br><span class="line">        &#125;</span><br><span class="line">        return list;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="cache定义"><a href="#cache定义" class="headerlink" title="cache定义"></a>cache定义</h3><p> 刚刚说了我们要想使用二级缓存，是需要在对应的Mapper.xml文件中定义其中的查询语句需要使用哪个cache来缓存数据的。这有两种方式可以定义，一种是通过cache元素定义，一种是通过cache-ref元素来定义。但是需要注意的是对于同一个Mapper来讲，它只能使用一个Cache，当同时使用了<cache>和<cache-ref>时使用<cache>定义的优先级更高。Mapper使用的Cache是与我们的Mapper对应的namespace绑定的，一个namespace最多只会有一个Cache与其绑定。</p><h3 id="cache元素定义"><a href="#cache元素定义" class="headerlink" title="cache元素定义"></a>cache元素定义</h3><p> 使用cache元素来定义使用的Cache时，最简单的做法是直接在对应的Mapper.xml文件中指定一个空的<cache/>元素，这个时候Mybatis会按照默认配置创建一个Cache对象，准备的说是PerpetualCache对象，更准确的说是LruCache对象（底层用了装饰器模式）。具体可以参考XMLMapperBuilder中的cacheElement()方法中解析cache元素的逻辑。空cache元素定义会生成一个采用最近最少使用算法最多只能存储1024个元素的缓存，而且是可读写的缓存，即该缓存是全局共享的，任何一个线程在拿到缓存结果后对数据的修改都将影响其它线程获取的缓存结果，因为它们是共享的，同一个对象。</p><p>​     cache元素可指定如下属性，每种属性的指定都是针对都是针对底层Cache的一种装饰，采用的是装饰器的模式。</p><p>Ø <strong>blocking</strong>：默认为false，当指定为true时将采用BlockingCache进行封装，blocking，阻塞的意思，使用BlockingCache会在查询缓存时锁住对应的Key，如果缓存命中了则会释放对应的锁，否则会在查询数据库以后再释放锁，这样可以阻止并发情况下多个线程同时查询数据，详情可参考BlockingCache的源码。</p><p>Ø <strong>eviction</strong>：eviction，驱逐的意思。也就是元素驱逐算法，默认是LRU，对应的就是LruCache，其默认只保存1024个Key，超出时按照最近最少使用算法进行驱逐，详情请参考LruCache的源码。如果想使用自己的算法，则可以将该值指定为自己的驱逐算法实现类，只需要自己的类实现Mybatis的Cache接口即可。除了LRU以外，系统还提供了FIFO（先进先出，对应FifoCache）、SOFT（采用软引用存储Value，便于垃圾回收，对应SoftCache）和WEAK（采用弱引用存储Value，便于垃圾回收，对应WeakCache）这三种策略。</p><p>Ø <strong>flushInterval</strong>：清空缓存的时间间隔，单位是毫秒，默认是不会清空的。当指定了该值时会再用ScheduleCache包装一次，其会在每次对缓存进行操作时判断距离最近一次清空缓存的时间是否超过了flushInterval指定的时间，如果超出了，则清空当前的缓存，详情可参考ScheduleCache的实现。</p><p>Ø <strong>readOnly</strong>：是否只读，默认为false。当指定为false时，底层会用SerializedCache包装一次，其会在写缓存的时候将缓存对象进行序列化，然后在读缓存的时候进行反序列化，这样每次读到的都将是一个新的对象，即使你更改了读取到的结果，也不会影响原来缓存的对象，即非只读，你每次拿到这个缓存结果都可以进行修改，而不会影响原来的缓存结果；当指定为true时那就是每次获取的都是同一个引用，对其修改会影响后续的缓存数据获取，这种情况下是不建议对获取到的缓存结果进行更改，意为只读。这是Mybatis二级缓存读写和只读的定义，可能与我们通常情况下的只读和读写意义有点不同。每次都进行序列化和反序列化无疑会影响性能，但是这样的缓存结果更安全，不会被随意更改，具体可根据实际情况进行选择。详情可参考SerializedCache的源码。</p><p>Ø <strong>size</strong>：用来指定缓存中最多保存的Key的数量。其是针对LruCache而言的，LruCache默认只存储最多1024个Key，可通过该属性来改变默认值，当然，如果你通过eviction指定了自己的驱逐算法，同时自己的实现里面也有setSize方法，那么也可以通过cache的size属性给自定义的驱逐算法里面的size赋值。</p><p>Ø <strong>type</strong>：type属性用来指定当前底层缓存实现类，默认是PerpetualCache，如果我们想使用自定义的Cache，则可以通过该属性来指定，对应的值是我们自定义的Cache的全路径名称。</p><h3 id="cache-ref元素定义"><a href="#cache-ref元素定义" class="headerlink" title="cache-ref元素定义"></a>cache-ref元素定义</h3><p>cache-ref元素可以用来指定其它Mapper.xml中定义的Cache，有的时候可能我们多个不同的Mapper需要共享同一个缓存的，是希望在MapperA中缓存的内容在MapperB中可以直接命中的，这个时候我们就可以考虑使用cache-ref，这种场景只需要保证它们的缓存的Key是一致的即可命中，二级缓存的Key是通过Executor接口的createCacheKey()方法生成的，其实现基本都是BaseExecutor，源码如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CacheKey <span class="title">createCacheKey</span><span class="params">(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   CacheKey cacheKey = <span class="keyword">new</span> CacheKey();</span><br><span class="line">   cacheKey.update(ms.getId());</span><br><span class="line">   cacheKey.update(Integer.valueOf(rowBounds.getOffset()));</span><br><span class="line">   cacheKey.update(Integer.valueOf(rowBounds.getLimit()));</span><br><span class="line">   cacheKey.update(boundSql.getSql());</span><br><span class="line"></span><br><span class="line">   List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings();</span><br><span class="line"></span><br><span class="line">   TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry();</span><br><span class="line">   <span class="comment">// mimic DefaultParameterHandler logic</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parameterMappings.size(); i++) &#123;</span><br><span class="line">     ParameterMapping parameterMapping = parameterMappings.get(i);</span><br><span class="line">     <span class="keyword">if</span> (parameterMapping.getMode() != ParameterMode.OUT) &#123;</span><br><span class="line">       Object value;</span><br><span class="line">       String propertyName = parameterMapping.getProperty();</span><br><span class="line">       <span class="keyword">if</span> (boundSql.hasAdditionalParameter(propertyName)) &#123;</span><br><span class="line">         value = boundSql.getAdditionalParameter(propertyName);</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (parameterObject == <span class="keyword">null</span>) &#123;</span><br><span class="line">         value = <span class="keyword">null</span>;</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span>(typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123;</span><br><span class="line">         value = parameterObject;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         MetaObject metaObject = configuration.newMetaObject(parameterObject);</span><br><span class="line">         value = metaObject.getValue(propertyName);</span><br><span class="line">       &#125;</span><br><span class="line">       cacheKey.update(value);</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (configuration.getEnvironment() != <span class="keyword">null</span>) &#123;</span><br><span class="line">     <span class="comment">// issue #176</span></span><br><span class="line">     cacheKey.update(configuration.getEnvironment().getId());</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> cacheKey;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>打个比方我想在PersonMapper.xml中的查询都使用在UserMapper.xml中定义的Cache，则可以通过cache-ref元素的namespace属性指定需要引用的Cache所在的namespace，即UserMapper.xml中的定义的namespace，假设在UserMapper.xml中定义的namespace是com.elim.learn.mybatis.dao.UserMapper，则在PersonMapper.xml的cache-ref应该定义如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;cache-ref namespace=&quot;com.elim.learn.mybatis.dao.UserMapper&quot;/&gt;</span><br></pre></td></tr></table></figure><h3 id="自定义cache"><a href="#自定义cache" class="headerlink" title="自定义cache"></a>自定义cache</h3><p> 前面提到Mybatis的Cache默认会使用PerpetualCache存储数据，如果我们不想按照它的逻辑实现，或者我们想使用其它缓存框架来实现，比如使用Ehcache、Redis等，这个时候我们就可以使用自己的Cache实现，Mybatis是给我们留有对应的接口，允许我们进行自定义的。要想实现自定义的Cache我们必须定义一个自己的类来实现Mybatis提供的Cache接口，实现对应的接口方法。注意，自定义的Cache必须包含一个接收一个String参数的构造方法，这个参数就是Cache的ID，详情请参考Mybatis初始化Cache的过程，对应XMLMapperBuilder的cacheElement()方法。以下是一个简单的MyCache的实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">publicclass MyCache implements Cache &#123;</span><br><span class="line">   <span class="keyword">private</span> String id;</span><br><span class="line">   <span class="keyword">private</span> String name;<span class="comment">//Name，故意加这么一个属性，以方便演示给自定义Cache的属性设值</span></span><br><span class="line">   <span class="keyword">private</span> Map&lt;Object, Object&gt; cache = <span class="keyword">new</span> HashMap&lt;Object, Object&gt;();</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 构造方法。自定义的Cache实现一定要有一个id参数</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">MyCache</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.id = id;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.id;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putObject</span><span class="params">(Object key, Object value)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.cache.put(key, value);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Object <span class="title">getObject</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.get(key);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Object <span class="title">removeObject</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.remove(key);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.cache.clear();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.cache.size();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> ReadWriteLock <span class="title">getReadWriteLock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> the name</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> name;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> name the name to set</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.name = name;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 定义了自己的Cache实现类后我们就可以在需要使用它的Mapper.xml文件中通过<cache>标签的type属性来指定我们需要使用的Cache。如果我们的自定义Cache是需要指定参数的，则可以通过<cache>标签的子标签<property>来指定对应的参数，Mybatis在解析的时候会调用指定属性对应的set方法。针对于上面的自定义Cache，我们的配置如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;cache type=&quot;com.elim.learn.mybatis.cache.MyCache&quot;&gt;</span><br><span class="line">      &lt;property name=&quot;name&quot; value=&quot;调用setName()方法需要传递的参数值&quot;/&gt;</span><br><span class="line">   &lt;/cache&gt;</span><br></pre></td></tr></table></figure><p>圆角矩形：注意：如果我们使用了自定义的Cache，那么cache标签的其它属性，如size、eviction等都不会对自定义的Cache起作用，也就是说不会自动对自定义的Cache进行包装，如果需要使用自定义的Cache，同时又希望使用Mybatis自带的那些Cache包装类，则可以在自定义的Cache中自己进行包装。</p><h3 id="缓存的清除"><a href="#缓存的清除" class="headerlink" title="缓存的清除"></a>缓存的清除</h3><p>二级缓存默认是会在执行update、insert和delete语句时进行清空的，具体可以参考CachingExecutor的update()实现。如果我们不希望在执行某一条更新语句时清空对应的二级缓存，那么我们可以在对应的语句上指定flushCache属性等于false。如果只是某一条select语句不希望使用二级缓存和一级缓存，则也可以在对应的select元素上加上flushCache=”true”。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;insert id=&quot;delete&quot; parameterType=&quot;java.lang.Long&quot;flushCache=&quot;false&quot;&gt;</span><br><span class="line">    delete t_person where id=#&#123;id&#125;</span><br><span class="line"> &lt;/insert&gt;</span><br></pre></td></tr></table></figure><h3 id="自己操作Cache"><a href="#自己操作Cache" class="headerlink" title="自己操作Cache"></a>自己操作Cache</h3><p>Mybatis中创建的二级缓存都会交给Configuration进行管理，Configuration类是Mybatis的核心类，里面包含了各种Mybatis资源的管理，其可以很方便的通过SqlSession、SqlSessionFactory获取，如有需要我们可以直接通过它来操作我们的Cache。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  @Test</span><br><span class="line">   public void testGetCache() &#123;</span><br><span class="line">      Configuration configuration = this.session.getConfiguration();</span><br><span class="line">//    this.sessionFactory.getConfiguration();</span><br><span class="line">      Collection&lt;Cache&gt; caches = configuration.getCaches();</span><br><span class="line">      System.out.println(caches);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>针对二级缓存进行了以下测试，获取两个不同的SqlSession执行两条相同的SQL，在未指定Cache时Mybatis将查询两次数据库，在指定了Cache时Mybatis只查询了一次数据库，第二次是从缓存中拿的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">  public void testCache2() &#123;</span><br><span class="line">     SqlSession session1 = this.sessionFactory.openSession();</span><br><span class="line">     SqlSession session2 = this.sessionFactory.openSession();</span><br><span class="line">     session1.getMapper(PersonMapper.class).findById(5L);</span><br><span class="line">     session1.commit();</span><br><span class="line">     session2.getMapper(PersonMapper.class).findById(5L);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p> 注意在上面的代码中，我在session1执行完对应的SQL后调用了session1的commit()方法，即提交了它的事务，这样我们在第二次查询的时候才会缓存命中，才不会查询数据库，否则就会连着查询两次数据库。这是因为在CachingExecutor中Mybatis在查询的过程中又在原来Cache的基础上包装了TransactionalCache，这个Cache只会在事务提交后才真正的写入缓存，所以在上面的示例中，如果session1执行完SQL后没有马上commit就紧接着用session2执行SQL，虽然session1查询时没有缓存命中，但是此时写入缓存操作还没有进行，session2再查询的时候也就不会缓存命中了。</p><p><strong>参考文档</strong></p><p><a href="http://www.mybatis.org/mybatis-3/zh/sqlmap-xml.html#cache">http://www.mybatis.org/mybatis-3/zh/sqlmap-xml.html#cache</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Mybatis中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存1024条SQL。二级缓存是指可以跨SqlSession的缓存。 &lt;/p&gt;
&lt;p&gt;​    Mybatis中进行SQL查询是通过org.apache.ibatis.executor.Executor接口进行的，总体来讲，它一共有两类实现，一类是BaseExecutor，一类是CachingExecutor。前者是非启用二级缓存时使用的，而后者是采用的装饰器模式，在启用了二级缓存时使用，当二级缓存没有命中时，底层还是通过BaseExecutor来实现的。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="http://xubatian.cn/categories/Java/"/>
    
    
    <category term="Java" scheme="http://xubatian.cn/tags/Java/"/>
    
    <category term="Mybatis" scheme="http://xubatian.cn/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>推荐一款Mybatis分页插件</title>
    <link href="http://xubatian.cn/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BEMybatis%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6/"/>
    <id>http://xubatian.cn/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BEMybatis%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6/</id>
    <published>2022-02-07T13:52:43.000Z</published>
    <updated>2022-02-07T14:17:20.428Z</updated>
    
    <content type="html"><![CDATA[<p>介绍Mybatis的插件，以及如何通过Mybatis的插件功能实现一个自定义的分页插件。前段时间遇到了一款开源的Mybatis分页插件，叫<code>PageHelper</code>，github地址是 <a href="https://github.com/pagehelper/Mybatis-PageHelper">https://github.com/pagehelper/Mybatis-PageHelper</a>   其原理是通过<code>ThreadLocal</code>来存放分页信息，从而可以做到在Service层实现无侵入性的Mybatis分页。笔者感觉还不错，所以特意发博文记录一下，并推荐给大家。</p><span id="more"></span><h1 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h1><p>以下是使用<code>PageHelper</code>进行分页的一个简单的示例，更多详细的内容，请大家参数上面提供的<a href="https://github.com/pagehelper/Mybatis-PageHelper">github地址</a>。</p><h2 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h2><p>笔者使用的是Maven，添加依赖如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;pagehelper&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;4.1.6&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h2 id="注册Mybatis-Plugin"><a href="#注册Mybatis-Plugin" class="headerlink" title="注册Mybatis Plugin"></a>注册Mybatis Plugin</h2><p>跟其它Mybatis Plugin一样，我们需要在Mybatis的配置文件中注册需要使用的Plugin，<code>PageHelper</code>中对应的Plugin实现类就是<code>com.github.pagehelper.PageHelper</code>自身。顺便说一句，Mybatis的Plugin我们说是Plugin，实际上对应的却是<code>org.apache.ibatis.plugin.Interceptor</code>接口，因为<code>Interceptor</code>的核心是其中的<code>plugin(Object target)</code>方法，而对于<code>plugin(Object target)</code>方法的实现，我们在需要对对应的对象进行拦截时会通过<code>org.apache.ibatis.plugin.Plugin</code>的静态方法<code>wrap(Object target, Interceptor interceptor)</code>返回一个代理对象，而方法入参就是当前的<code>Interceptor</code>实现类。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugins&gt;  </span><br><span class="line">   &lt;plugin interceptor=&quot;com.github.pagehelper.PageHelper&quot;/&gt;  </span><br><span class="line">&lt;/plugins&gt;</span><br></pre></td></tr></table></figure><h2 id="使用PageHelper"><a href="#使用PageHelper" class="headerlink" title="使用PageHelper"></a>使用PageHelper</h2><p><code>PageHelper</code>拦截的是<code>org.apache.ibatis.executor.Executor</code>的<code>query</code>方法，其传参的核心原理是通过<code>ThreadLocal</code>进行的。当我们需要对某个查询进行分页查询时，我们可以在调用Mapper进行查询前调用一次<code>PageHelper.startPage(..)</code>，这样<code>PageHelper</code>会把分页信息存入一个<code>ThreadLocal</code>变量中。在拦截到<code>Executor</code>的<code>query</code>方法执行时会从对应的<code>ThreadLocal</code>中获取分页信息，获取到了，则进行分页处理，处理完了后又会把<code>ThreadLocal</code>中的分页信息清理掉，以便不影响下一次的查询操作。所以当我们使用了<code>PageHelper.startPage(..)</code>后，每次将对最近一次的查询进行分页查询，如果下一次查询还需要进行分页查询，需要重新进行一次<code>PageHelper.startPage(..)</code>。这样就做到了在引入了分页后可以对原来的查询代码没有任何的侵入性。此外，在进行分页查询时，我们的返回结果一般是一个<code>java.util.List</code>，<code>PageHelper</code>分页查询后的结果会变成<code>com.github.pagehelper.Page</code>类型，其继承了<code>java.util.ArrayList</code>，所以不会对我们的方法声明造成影响。<code>com.github.pagehelper.Page</code>中包含有返回结果的分页信息，包括总记录数，总的分页数等信息，所以一般我们需要把返回结果强转为<code>com.github.pagehelper.Page</code>类型。以下是一个简单的使用<code>PageHelper</code>进行分页查询的示例代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">public class PageHelperTest &#123;</span><br><span class="line"></span><br><span class="line">private static SqlSessionFactory sqlSessionFactory;</span><br><span class="line">private SqlSession session;</span><br><span class="line"></span><br><span class="line">@BeforeClass</span><br><span class="line">public static void beforeClass() throws IOException &#123;</span><br><span class="line">InputStream is = Resources.getResourceAsStream(&quot;mybatis-config-single.xml&quot;);</span><br><span class="line">sqlSessionFactory = new SqlSessionFactoryBuilder().build(is);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Before</span><br><span class="line">public void before() &#123;</span><br><span class="line">this.session = sqlSessionFactory.openSession();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@After</span><br><span class="line">public void after() &#123;</span><br><span class="line">this.session.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Test</span><br><span class="line">public void test() &#123;</span><br><span class="line">int pageNum = 2;//页码，从1开始</span><br><span class="line">int pageSize = 10;//每页记录数</span><br><span class="line">PageHelper.startPage(pageNum, pageSize);//指定开始分页</span><br><span class="line">UserMapper userMapper = this.session.getMapper(UserMapper.class);</span><br><span class="line">List&lt;User&gt; all = userMapper.findAll();</span><br><span class="line">Page&lt;User&gt; page = (Page&lt;User&gt;) all;</span><br><span class="line">System.out.println(page.getPages());</span><br><span class="line">System.out.println(page);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上是通过<code>PageHelper.startPage(..)</code>传递分页信息的示例，其实<code>PageHelper</code>还支持Mapper参数传递分页信息等其它用法。关于<code>PageHelper</code>的更多用法和配置信息等请参考该项目的GitHub<a href="https://github.com/pagehelper/Mybatis-PageHelper">官方文档</a>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍Mybatis的插件，以及如何通过Mybatis的插件功能实现一个自定义的分页插件。前段时间遇到了一款开源的Mybatis分页插件，叫&lt;code&gt;PageHelper&lt;/code&gt;，github地址是 &lt;a href=&quot;https://github.com/pagehelper/Mybatis-PageHelper&quot;&gt;https://github.com/pagehelper/Mybatis-PageHelper&lt;/a&gt;   其原理是通过&lt;code&gt;ThreadLocal&lt;/code&gt;来存放分页信息，从而可以做到在Service层实现无侵入性的Mybatis分页。笔者感觉还不错，所以特意发博文记录一下，并推荐给大家。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="http://xubatian.cn/categories/Java/"/>
    
    
    <category term="Java" scheme="http://xubatian.cn/tags/Java/"/>
    
    <category term="Mybatis" scheme="http://xubatian.cn/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>mybatis简介</title>
    <link href="http://xubatian.cn/mybatis%E7%AE%80%E4%BB%8B/"/>
    <id>http://xubatian.cn/mybatis%E7%AE%80%E4%BB%8B/</id>
    <published>2022-02-07T13:41:56.000Z</published>
    <updated>2022-02-07T13:51:26.032Z</updated>
    
    <content type="html"><![CDATA[<p>Mybatis框架简介</p><span id="more"></span><h1 id="MyBatis介绍"><a href="#MyBatis介绍" class="headerlink" title="MyBatis介绍"></a>MyBatis介绍</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>原是apache的一个开源项目iBatis，2010年6月这个项目由apache software foundation 迁移到了google code，随着开发团队转投Google Code旗下，ibatis3.x正式更名为Mybatis ，代码于2013年11月迁移到Github。<br>相对Hibernate和ApacheOJB等“一站式”ORM（Object Mapping）解决方案而言，ibatis 是一种“半自动化”的ORM实现。Relational<br>无论 Hibernate还是Apache OJB，都对数据库结构提供了较为完整的封装，提供了从POJO到数据库表的全套映射机制。程序员往往只需定义好了POJO 到数据库表的映射关系，即可通过 Hibernate或者OJB 提供的方法完成持久层操作。程序员甚至不需要对 SQL 的熟练掌握，Hibernate/OJB 会根据制定的存储逻辑，自动生成对应的 SQL 并调用 JDBC 接口加以执行。</p><h2 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a>官方文档</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207214544.png" alt="博客:www.xubatian.cn"></p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>1）支持自定义SQL、存储过程、及高级映射<br>2）实现自动对SQL的参数设置<br>3）实现自动对结果集进行解析和封装<br>4）通过XML或者注解进行配置和映射，大大减少代码量<br>5）数据源的连接信息通过配置文件进行配置</p><p>可以发现，MyBatis是对JDBC进行了简单的封装，帮助用户进行SQL参数的自动设置，以及结果集与Java对象的自动映射。与Hibernate相比，配置更加简单、灵活、执行效率高。但是正因为此，所以没有实现完全自动化，需要手写SQL，这是优点也是缺点。</p><p>因此，对性能要求较高的电商类项目，一般会使用MyBatis，而对与业务逻辑复杂，不太在乎执行效率的传统行业，一般会使用Hibernate</p><h2 id="Mybaits整体架构"><a href="#Mybaits整体架构" class="headerlink" title="Mybaits整体架构"></a>Mybaits整体架构</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207214710.png" alt="博客:www.xubatian.cn"></p><p>1、配置文件<br>全局配置文件：mybatis-config.xmlhibernate.cfg.xml，作用：配置数据源，引入映射文件<br>映射文件：XxMapper.xmlxx.hbm.xml，作用：配置sql语句、参数、结果集封装类型等</p><p>2、SqlSessionFactory<br>相当于Hibernate的SessionFactory，作用：获取SqlSession<br>通过newSqlSessionFactoryBuilder().build(inputStream)来构建，inputStream：读取配置文件的IO流</p><p>3、SqlSession<br>相当于Hibernate的Session，作用：执行CRUD操作</p><p>4、Executor<br>执行器，SqlSession通过调用它来完成具体的CRUD<br>它是一个接口，提供了两种实现：缓存的实现、数据库的实现</p><p>5、Mapped Statement<br>在映射文件里面配置，包含3部分内容：<br>具体的sql，sql执行所需的参数类型，sql执行结果的封装类型<br>参数类型和结果集封装类型包括3种：<br>HashMap，基本数据类型，pojo</p><p>…….未完待续</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Mybatis框架简介&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="http://xubatian.cn/categories/Java/"/>
    
    
    <category term="Java" scheme="http://xubatian.cn/tags/Java/"/>
    
    <category term="Mybatis" scheme="http://xubatian.cn/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>Flink使用idea将匿名内部类替换为lambda表达会擦除泛型</title>
    <link href="http://xubatian.cn/Flink%E4%BD%BF%E7%94%A8idea%E5%B0%86%E5%8C%BF%E5%90%8D%E5%86%85%E9%83%A8%E7%B1%BB%E6%9B%BF%E6%8D%A2%E4%B8%BAlambda%E8%A1%A8%E8%BE%BE%E4%BC%9A%E6%93%A6%E9%99%A4%E6%B3%9B%E5%9E%8B/"/>
    <id>http://xubatian.cn/Flink%E4%BD%BF%E7%94%A8idea%E5%B0%86%E5%8C%BF%E5%90%8D%E5%86%85%E9%83%A8%E7%B1%BB%E6%9B%BF%E6%8D%A2%E4%B8%BAlambda%E8%A1%A8%E8%BE%BE%E4%BC%9A%E6%93%A6%E9%99%A4%E6%B3%9B%E5%9E%8B/</id>
    <published>2022-02-07T06:12:57.000Z</published>
    <updated>2022-02-07T09:16:00.327Z</updated>
    
    <content type="html"><![CDATA[<p>Flink代码使用IDEA将new匿名内部类替换为lambda表达式运行会报错,因为替换后会擦除泛型</p><p>测试Flink1.12.0没有出现返回值类型报错问题. 不知道是否是Flink高版本结局了此问题还是idea高版本解决了此问题.</p><span id="more"></span><h2 id="源码地址-™"><a href="#源码地址-™" class="headerlink" title="源码地址:™"></a>源码地址:™</h2><p><a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo01/Flink_WordCount_Bounded.java">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/blob/main/flink-1.12.0-Demo/src/main/java/com/shangbaishuyao/demo/FlinkDemo01/Flink_WordCount_Bounded.java</a></p><h2 id="报错类型示例"><a href="#报错类型示例" class="headerlink" title="报错类型示例"></a>报错类型示例</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207141902.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207141937.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207142024.png" alt="博客:www.xubatian.cn"></p><h2 id="返回值类型报错"><a href="#返回值类型报错" class="headerlink" title="返回值类型报错"></a>返回值类型报错</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207142213.png" alt="博客:www.xubatian.cn"></p><h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式:"></a>解决方式:</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207142525.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207144407.png" alt="博客:www.xubatian.cn"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink代码使用IDEA将new匿名内部类替换为lambda表达式运行会报错,因为替换后会擦除泛型&lt;/p&gt;
&lt;p&gt;测试Flink1.12.0没有出现返回值类型报错问题. 不知道是否是Flink高版本结局了此问题还是idea高版本解决了此问题.&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>2022年,二月,你好!</title>
    <link href="http://xubatian.cn/%E4%BA%8C%E6%9C%88-%E4%BD%A0%E5%A5%BD/"/>
    <id>http://xubatian.cn/%E4%BA%8C%E6%9C%88-%E4%BD%A0%E5%A5%BD/</id>
    <published>2022-01-31T23:30:30.000Z</published>
    <updated>2022-02-10T02:54:12.479Z</updated>
    
    <content type="html"><![CDATA[<p>二月了呀! 要加油了…..</p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220210105354.png" alt="博客:www.xubatian.cn"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;二月了呀! 要加油了…..&lt;/p&gt;</summary>
    
    
    
    <category term="动态" scheme="http://xubatian.cn/categories/%E5%8A%A8%E6%80%81/"/>
    
    
    <category term="动态" scheme="http://xubatian.cn/tags/%E5%8A%A8%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>Flink流处理案例</title>
    <link href="http://xubatian.cn/Flink%E6%B5%81%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/"/>
    <id>http://xubatian.cn/Flink%E6%B5%81%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</id>
    <published>2022-01-31T09:02:26.000Z</published>
    <updated>2022-02-07T06:01:54.853Z</updated>
    
    <content type="html"><![CDATA[<p>简单Flink流处理案例</p><p>①自定义flatmap操作</p><p>② new 匿名内部类接口 操作</p><p>③简单的算子运用: FlatMap压平, Map转换,Tuple2二元组.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在Java中,二元组Tuple就是<span class="number">2</span>,即Tuple2;三元组就是<span class="number">3</span>,即Tuple3</span><br><span class="line">元组索引从<span class="number">0</span>开始</span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="源代码地址"><a href="#源代码地址" class="headerlink" title="源代码地址"></a>源代码地址</h2><p><a href="https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/tree/main/flink-1.12.0-Demo">https://github.com/ShangBaiShuYao/flink-learning-from-zhisheng/tree/main/flink-1.12.0-Demo</a></p><h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220131173631.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207125512.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220131173834.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220131174208.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220131180631.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207130501.png" alt="博客:www.xubatian.cn"></p><h2 id="补充另一种写法-new-匿名内部类接口"><a href="#补充另一种写法-new-匿名内部类接口" class="headerlink" title="补充另一种写法: new 匿名内部类接口"></a>补充另一种写法: new 匿名内部类接口</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207131308.png" alt="博客:www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220207135330.png" alt="博客:www.xubatian.cn"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;简单Flink流处理案例&lt;/p&gt;
&lt;p&gt;①自定义flatmap操作&lt;/p&gt;
&lt;p&gt;② new 匿名内部类接口 操作&lt;/p&gt;
&lt;p&gt;③简单的算子运用: FlatMap压平, Map转换,Tuple2二元组.&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;在Java中,二元组Tuple就是&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,即Tuple2;三元组就是&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;,即Tuple3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;元组索引从&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;开始&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>《说书人》朱广权+尼格买提版</title>
    <link href="http://xubatian.cn/%E8%AF%B4%E4%B9%A6%E4%BA%BA/"/>
    <id>http://xubatian.cn/%E8%AF%B4%E4%B9%A6%E4%BA%BA/</id>
    <published>2022-01-28T14:33:41.000Z</published>
    <updated>2022-02-07T16:23:15.288Z</updated>
    
    <content type="html"><![CDATA[<p>侠义多是平凡辈 , 无须仗剑走天涯。——朱广权</p><span id="more"></span><div style="position: relative; padding: 30% 45%;"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/%E3%80%90%E5%89%8D%E6%96%B9%E9%AB%98%E7%87%83%E3%80%91%E5%BD%93%E5%94%A2%E5%91%90%E9%81%87%E8%A7%81%E7%94%B5%E9%9F%B3%EF%BC%81%E6%9C%B1%E5%B9%BF%E6%9D%83-%E5%B0%BC%E6%A0%BC%E4%B9%B0%E6%8F%90%E7%89%88%E3%80%8A%E8%AF%B4%E4%B9%A6%E4%BA%BA%E3%80%8B.mp4" frameborder="no" scrolling="no"></iframe></div> ]]></content>
    
    
    <summary type="html">&lt;p&gt;侠义多是平凡辈 , 无须仗剑走天涯。——朱广权&lt;/p&gt;</summary>
    
    
    
    <category term="轻松一刻" scheme="http://xubatian.cn/categories/%E8%BD%BB%E6%9D%BE%E4%B8%80%E5%88%BB/"/>
    
    
    <category term="轻松一刻" scheme="http://xubatian.cn/tags/%E8%BD%BB%E6%9D%BE%E4%B8%80%E5%88%BB/"/>
    
  </entry>
  
  <entry>
    <title>到底是什么使我心态不稳?</title>
    <link href="http://xubatian.cn/%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88%E6%98%AF%E6%88%91%E5%BF%83%E6%80%81%E4%B8%8D%E7%A8%B3/"/>
    <id>http://xubatian.cn/%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88%E6%98%AF%E6%88%91%E5%BF%83%E6%80%81%E4%B8%8D%E7%A8%B3/</id>
    <published>2022-01-28T05:47:56.000Z</published>
    <updated>2022-01-28T07:46:01.670Z</updated>
    
    <content type="html"><![CDATA[<p>编译spark源码的三天时间,我到底经历了什么?</p><span id="more"></span><p>原本我是打算使用本地进行编译的…结果撑了一天,不行了.一大波bug正在赶来….</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220128135223.png" alt="博客: www.xubatian.cn"></p><p>这种bug,我解决了不下二十个. 最关键的是,这种报错都是些jar包下载不下来….</p><div align="center">    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220128135425.png" alt="博客: www.xubatian.cn"></img></div><p>想想还是算了吧,换服务器编译吧… 在准备了一堆maven,scala等一堆环境变量之后,终于走上了编译之路.</p><p>打死我都没想,这条路黑暗了我两天美好的人生….</p><p>再哭一下…..</p><div align="center">    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220128135700.png" alt="博客: www.xubatian.cn"></img></div><p>—————————————————————– 以下是我最常遇到的bug  , 经常光顾我 ,也是老熟人了  ———————————————————–</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220128135009.png" alt="博客: www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220128135024.png" alt="博客: www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220128140050.png" alt="博客: www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220128144435.png" alt="博客: www.xubatian.cn"></p><p>阳光总在风雨后…</p><p>历经三天的折磨,终于编译出了合适我hadoop版本的spark…..</p><p>此处咧嘴大笑….</p><div align="center">    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/20220128141051.png" alt="博客: www.xubatian.cn"></img></div><div align="center">    <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/tempImage1643355914082.gif" alt="博客: www.xubatian.cn"></img></div><p>炫耀版的展示一下….嘻嘻…</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/www.xubatian.cn_400.png" alt="博客: www.xubatian.cn"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;编译spark源码的三天时间,我到底经历了什么?&lt;/p&gt;</summary>
    
    
    
    <category term="动态" scheme="http://xubatian.cn/categories/%E5%8A%A8%E6%80%81/"/>
    
    
    <category term="动态" scheme="http://xubatian.cn/tags/%E5%8A%A8%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>streamx源码编译及安装部署-本地编译(推荐)</title>
    <link href="http://xubatian.cn/streamx%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2-%E6%9C%AC%E5%9C%B0%E7%BC%96%E8%AF%91(%E6%8E%A8%E8%8D%90)/"/>
    <id>http://xubatian.cn/streamx%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2-%E6%9C%AC%E5%9C%B0%E7%BC%96%E8%AF%91(%E6%8E%A8%E8%8D%90)/</id>
    <published>2022-01-22T12:21:54.000Z</published>
    <updated>2022-01-23T03:05:51.541Z</updated>
    
    <content type="html"><![CDATA[<p>锚定既定奋斗目标，意气风发走向未来。——人民日报</p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/www.xubatian.cn_394.jpg" alt="blog: www.xubatian.cn"></p><p>在服务器端进行了streamx编译的那文章也说了,我没有flink,hadoop 的配置,所以我重新进行了streamx的源码编译,版本依旧是streamx-1.2.0 稳定版本</p><p><strong>现在编译的是Flink版本为1.14.3 , hadoop版本为3.1.3.</strong></p><h1 id="源码编译的前提条件"><a href="#源码编译的前提条件" class="headerlink" title="源码编译的前提条件"></a>源码编译的前提条件</h1><p>我使用的是maven 3.8.3版本. node js , jdk1.8.3 ,npm. </p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/20220122203333.png" alt="blog: www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/20220122203432.png" alt="blog: www.xubatian.cn"></p><h1 id="streamx源码编译"><a href="#streamx源码编译" class="headerlink" title="streamx源码编译"></a>streamx源码编译</h1><h2 id="从官网下载streamx稳定版本"><a href="#从官网下载streamx稳定版本" class="headerlink" title="从官网下载streamx稳定版本"></a>从官网下载streamx稳定版本</h2><p>官网地址: <a href="https://www.streamxhub.com/#">https://www.streamxhub.com/#</a></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_391.png" alt="blog: www.xubatian.cn"></p><p>github地址: <a href="https://github.com/streamxhub/streamx">https://github.com/streamxhub/streamx</a></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_390.png" alt="blog: www.xubatian.cn"></p><h2 id="修改streamx的相关版本"><a href="#修改streamx的相关版本" class="headerlink" title="修改streamx的相关版本"></a>修改streamx的相关版本</h2><p>修改为公司hadoop,flink,spark等相符合的大数据组件版本. </p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122201007.png" alt="blog: www.xubatian.cn"></p><h2 id="编译streamx源码"><a href="#编译streamx源码" class="headerlink" title="编译streamx源码"></a>编译streamx源码</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/20220122203910.png" alt="blog: www.xubatian.cn"></p><h2 id="报错及解决方式"><a href="#报错及解决方式" class="headerlink" title="报错及解决方式"></a>报错及解决方式</h2><p>常常报错的问题就是 jar包下载不下来. 或者maven镜像无法来取jar包. </p><p>解决方式:</p><p>① 看看是那个jar包下载不下来. </p><p>② 复制该jar名称,去maven中央仓库直接下载版本相同的jar</p><p>maven中央仓库地址: <a href="https://mvnrepository.com/">https://mvnrepository.com/</a> </p><p>注: 也可以直接放到谷歌浏览器上直接搜索.</p><p>③ 删除之前编译残留的文件,将下载好的jar包拷贝到本地maven仓库(注意:一定要放到指定的文件夹下)</p><p>④ 然后重新编译</p><h3 id="如下是示例"><a href="#如下是示例" class="headerlink" title="如下是示例:"></a>如下是示例:</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122194838.png" alt="blog: www.xubatian.cn"></p><h3 id="查看本地maven仓库-删除全部残余文件"><a href="#查看本地maven仓库-删除全部残余文件" class="headerlink" title="查看本地maven仓库,删除全部残余文件"></a>查看本地maven仓库,删除全部残余文件</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122195038.png" alt="blog: www.xubatian.cn"></p><h3 id="下载版本一样的jar包"><a href="#下载版本一样的jar包" class="headerlink" title="下载版本一样的jar包"></a>下载版本一样的jar包</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122195126.png" alt="blog: www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122195208.png" alt="blog: www.xubatian.cn"></p><p>将下载好的jar拷贝至本地maven仓库</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122195342.png" alt="blog: www.xubatian.cn"></p><h3 id="重新编译"><a href="#重新编译" class="headerlink" title="重新编译"></a>重新编译</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/20220122203910.png" alt="blog: www.xubatian.cn"></p><h2 id="反复经过N次上述行为后-恭喜你-成功了"><a href="#反复经过N次上述行为后-恭喜你-成功了" class="headerlink" title="反复经过N次上述行为后,恭喜你,成功了"></a>反复经过N次上述行为后,恭喜你,成功了</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122200810.png" alt="blog: www.xubatian.cn"></p><h2 id="在此目录下的压缩包拷贝至服务器上解压"><a href="#在此目录下的压缩包拷贝至服务器上解压" class="headerlink" title="在此目录下的压缩包拷贝至服务器上解压"></a>在此目录下的压缩包拷贝至服务器上解压</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122201341.png" alt="blog: www.xubatian.cn"></p><p>后缀是macOS的是我在本地进行编译的. 后缀是Linux的是我在服务器端编译的.</p><p>二者的区别就是 macOS端的我修改了hadoop版本为3.1.3 ,Flink版本为1.14.3</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/20220122205512.png" alt="blog: www.xubatian.cn"></p><h2 id="streamx部署"><a href="#streamx部署" class="headerlink" title="streamx部署"></a>streamx部署</h2><p>请看我的另一篇文章: <a href="https://www.xubatian.cn/streamx%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E7%BC%96%E8%AF%91/">streamx源码编译及安装部署-服务器端编译</a></p><h2 id="启动streamx"><a href="#启动streamx" class="headerlink" title="启动streamx"></a>启动streamx</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122201928.png" alt="blog: www.xubatian.cn"></p><h2 id="访问Web页面"><a href="#访问Web页面" class="headerlink" title="访问Web页面"></a>访问Web页面</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122202012.png" alt="blog: www.xubatian.cn"></p><h2 id="编译好的streamx存放地址"><a href="#编译好的streamx存放地址" class="headerlink" title="编译好的streamx存放地址"></a>编译好的streamx存放地址</h2><p>streamx1.12.0 源码默认配置 直接编译 编译后的压缩包为: streamx-console-service-1.2.0-Linux-bin.tar.gz<br>streamx1.12.0 源码,修改hadoop版本为3.1.3, flink版本为1.14.3 编译后的压缩包为: streamx-console-service-1.2.0-macOS-bin.tar.gz<br>两个压缩包都方式这里,链接: <a href="https://pan.baidu.com/s/1M4R0K3rOzNZOdilnJiduFw">https://pan.baidu.com/s/1M4R0K3rOzNZOdilnJiduFw</a> 提取码: 2olc</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;锚定既定奋斗目标，意气风发走向未来。——人民日报&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="streamx" scheme="http://xubatian.cn/tags/streamx/"/>
    
  </entry>
  
  <entry>
    <title>streamx源码编译及安装部署-服务器端编译</title>
    <link href="http://xubatian.cn/streamx%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E7%BC%96%E8%AF%91/"/>
    <id>http://xubatian.cn/streamx%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E7%BC%96%E8%AF%91/</id>
    <published>2022-01-22T06:38:59.000Z</published>
    <updated>2022-01-23T03:05:56.394Z</updated>
    
    <content type="html"><![CDATA[<p>遇到问题，改变苛求别人的惯性，重新塑造思考问题的方式。换个角度看世界，换个方向看问题，就会豁然开朗。——人民日报</p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_387.jpg" alt="blog: www.xubatian.cn"></p><h1 id="什么是streamx"><a href="#什么是streamx" class="headerlink" title="什么是streamx"></a>什么是streamx</h1><p> 大数据技术如今发展的如火如荼，已经呈现百花齐放欣欣向荣的景象，实时处理流域 Apache Spark 和 Apache Flink 更是一个伟大的进步，尤其是 Apache Flink 被普遍认为是下一代大数据流计算引擎， 我们在使用 Flink 时发现从编程模型， 启动配置到运维管理都有很多可以抽象共用的地方， 我们将一些好的经验固化下来并结合业内的最佳实践， 通过不断努力终于诞生了今天的框架 —— StreamX， 项目的初衷是 —— 让 Flink 开发更简单， 使用 StreamX 开发，可以极大降低学习成本和开发门槛， 让开发者只用关心最核心的业务， StreamX 规范了项目的配置，鼓励函数式编程，定义了最佳的编程方式，提供了一系列开箱即用的 Connectors ，标准化了配置、开发、测试、部署、监控、运维的整个过程， 提供 Scala 和 Java 两套api， 其最终目的是打造一个一站式大数据平台，流批一体，湖仓一体的解决方案.</p><h1 id="源码编译的前提条件"><a href="#源码编译的前提条件" class="headerlink" title="源码编译的前提条件"></a>源码编译的前提条件</h1><p>我使用的是CentOS Linux release 7.5.1804 (Core).  mysql5.7. 以及maven 3.8.3版本. node js 和 jdk1.8.3 .最少2个多G的磁盘空间</p><p>   <img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122150459.png" alt="blog: www.xubatian.cn"></p><h2 id="安装node-js"><a href="#安装node-js" class="headerlink" title="安装node-js"></a>安装node-js</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]$ wget https://nodejs.org/dist/v16.13.1/node-v16.13.1-linux-x64.tar.xz</span><br></pre></td></tr></table></figure><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]$ tar xf node-v16.13.1-linux-x64.tar.xz </span><br></pre></td></tr></table></figure><h3 id="进入解压目录"><a href="#进入解压目录" class="headerlink" title="进入解压目录"></a>进入解压目录</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]$ cd node-v16.13.1-linux-x64</span><br></pre></td></tr></table></figure><h3 id="修改Linux环境变量"><a href="#修改Linux环境变量" class="headerlink" title="修改Linux环境变量"></a>修改Linux环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]$ vim /etc/profile.d/shangbaishuyao_configurationfile.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">JAVA_HOME 加<span class="built_in">export</span>是对全局有效,相当于对外暴露一个接口</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">KAFKA_HOME</span></span><br><span class="line">export KAFKA_HOME=/opt/module/kafka_2.11-2.4.1</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">HIVE_HOME</span></span><br><span class="line">export HIVE_HOME=/opt/module/hive-3.1.2</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">MAVEN_HOME</span></span><br><span class="line">export MAVEN_HOME=/opt/module/maven-3.8.3</span><br><span class="line">export MAVEN_HOME</span><br><span class="line">export PATH=$PATH:$MAVEN_HOME/bin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> SPARK_HOME</span></span><br><span class="line">export SPARK_HOME=/opt/module/spark-3.0.0-hadoop3.2</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> NODE_JS</span></span><br><span class="line">export NODE_HOME=/opt/module/node-v16.13.1-linux-x64</span><br><span class="line">export PATH=$PATH:$NODE_HOME/bin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">HBASE_HOME</span></span><br><span class="line">export HBASE_HOME=/opt/module/hbase-2.0.5</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">FLINK_HOME</span></span><br><span class="line">export FLINK_HOME=/opt/module/flink-1.14.3</span><br><span class="line">export PATH=$PATH:$FLINK_HOME/bin</span><br><span class="line"></span><br><span class="line">export HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line">[shangbaishuyao@hadoop102 module]$</span><br></pre></td></tr></table></figure><h3 id="刷新环境变量"><a href="#刷新环境变量" class="headerlink" title="刷新环境变量"></a>刷新环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]$ source /etc/profile.d/shangbaishuyao_configurationfile.sh</span><br></pre></td></tr></table></figure><h3 id="查看是否安装成功"><a href="#查看是否安装成功" class="headerlink" title="查看是否安装成功"></a>查看是否安装成功</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]$ node -v</span><br><span class="line">v16.13.1</span><br></pre></td></tr></table></figure><h2 id="安装maven"><a href="#安装maven" class="headerlink" title="安装maven"></a>安装maven</h2><p>网上例子很多,此处略.</p><p>参考文章: <a href="https://www.cnblogs.com/freeweb/p/5241013.html">https://www.cnblogs.com/freeweb/p/5241013.html</a></p><h2 id="安装npm"><a href="#安装npm" class="headerlink" title="安装npm"></a>安装npm</h2><p>直接安装好node.js就有npm命令了,此处略. 有个问题是. 我在编译streamx的时候因为npm版本过低所以失败三次. 所以我升级了npm命令为: npm install -g npm</p><h2 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h2><p>网上例子很多,此处略.</p><h2 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h2><p>网上例子很多,此处略.</p><h3 id="进入mysql修改配置"><a href="#进入mysql修改配置" class="headerlink" title="进入mysql修改配置"></a>进入mysql修改配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[shangbaishuyao@hadoop102 streamx-release-1.2.0]$ vim /etc/my.cnf</span><br><span class="line"></span><br><span class="line">#streamx</span><br><span class="line">port=3306</span><br><span class="line">bind-address=0.0.0.0</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122153152.png" alt="blog: www.xubatian.cn"></p><h3 id="重新启动mysql"><a href="#重新启动mysql" class="headerlink" title="重新启动mysql"></a>重新启动mysql</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service mysql restart</span><br></pre></td></tr></table></figure><h1 id="streamx源码编译"><a href="#streamx源码编译" class="headerlink" title="streamx源码编译"></a>streamx源码编译</h1><h2 id="从官网下载streamx稳定版本"><a href="#从官网下载streamx稳定版本" class="headerlink" title="从官网下载streamx稳定版本"></a>从官网下载streamx稳定版本</h2><p>官网地址: <a href="https://www.streamxhub.com/#">https://www.streamxhub.com/#</a></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_391.png" alt="blog: www.xubatian.cn"></p><p>github地址: <a href="https://github.com/streamxhub/streamx">https://github.com/streamxhub/streamx</a></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_390.png" alt="blog: www.xubatian.cn"></p><h2 id="修改streamx的相关版本"><a href="#修改streamx的相关版本" class="headerlink" title="修改streamx的相关版本"></a>修改streamx的相关版本</h2><p>修改为公司hadoop,flink,spark等相符合的大数据组件版本. </p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_392.png" alt="blog: www.xubatian.cn"></p><p>然后将压缩包上传到服务器上并解压.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[shangbaishuyao@hadoop102 module]$ unzip streamx-release-1.2.0.zip -d /opt/module/</span><br></pre></td></tr></table></figure><p>进入解压目录编译源码,1.2.0默认flink版本为1.4,如需更改修改pom.xml再进行编译。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[shangbaishuyao@hadoop102 streamx-release-1.2.0]$ mvn clean install -DskipTests -Denv=prod</span><br></pre></td></tr></table></figure><p>等待……</p><p>最后成功!</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_376.png" alt="blog: www.xubatian.cn"></p><h2 id="进行解压编译成功后的压缩包"><a href="#进行解压编译成功后的压缩包" class="headerlink" title="进行解压编译成功后的压缩包"></a>进行解压编译成功后的压缩包</h2><p>编译后在/opt/module/streamx-release-1.2.0/streamx-console/streamx-console-service/target目录会有对应tar包</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_380.png" alt="blog: www.xubatian.cn"></p><h2 id="进入解压后的目录"><a href="#进入解压后的目录" class="headerlink" title="进入解压后的目录"></a>进入解压后的目录</h2><p>进入到对应目录，修改配置文件，需要使用mysql地址来存储数据。</p><p>注意：数据库不会自动创建，需要手动创建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[shangbaishuyao@hadoop102 module]$ cd streamx-console-service-1.2.0/</span><br><span class="line">[shangbaishuyao@hadoop102 streamx-console-service-1.2.0]$ vim conf/application.yml</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_381.png" alt="blog: www.xubatian.cn"></p><p>手动创建streamx的数据库</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/20220122153945.png" alt="blog: www.xubatian.cn"></p><h2 id="启动streamx"><a href="#启动streamx" class="headerlink" title="启动streamx"></a>启动streamx</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[shangbaishuyao@hadoop102 streamx-release-1.2.0]$ bin/startup.sh </span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_382.png" alt="blog: www.xubatian.cn"></p><h2 id="查看是否启动成功"><a href="#查看是否启动成功" class="headerlink" title="查看是否启动成功"></a>查看是否启动成功</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_384.png" alt="blog: www.xubatian.cn"></p><p>如果没有streamXconsole说明出现错误. 去logs里面查看具体错误.</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_383.png" alt="blog: www.xubatian.cn"></p><h2 id="使用浏览器访问streamx"><a href="#使用浏览器访问streamx" class="headerlink" title="使用浏览器访问streamx"></a>使用浏览器访问streamx</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_385.png" alt="blog: www.xubatian.cn"></p><p>账号为: admin 密码为: streamx</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_386.png" alt="blog: www.xubatian.cn"></p><h2 id="编译好的streamx存放地址"><a href="#编译好的streamx存放地址" class="headerlink" title="编译好的streamx存放地址"></a>编译好的streamx存放地址</h2><p>streamx1.12.0 源码默认配置 直接编译 编译后的压缩包为: streamx-console-service-1.2.0-Linux-bin.tar.gz<br>streamx1.12.0 源码,修改hadoop版本为3.1.3, flink版本为1.14.3 编译后的压缩包为: streamx-console-service-1.2.0-macOS-bin.tar.gz<br>两个压缩包都方式这里,链接: <a href="https://pan.baidu.com/s/1M4R0K3rOzNZOdilnJiduFw">https://pan.baidu.com/s/1M4R0K3rOzNZOdilnJiduFw</a> 提取码: 2olc</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;遇到问题，改变苛求别人的惯性，重新塑造思考问题的方式。换个角度看世界，换个方向看问题，就会豁然开朗。——人民日报&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="streamx" scheme="http://xubatian.cn/tags/streamx/"/>
    
  </entry>
  
  <entry>
    <title>Flink部署</title>
    <link href="http://xubatian.cn/Flink%E9%83%A8%E7%BD%B2/"/>
    <id>http://xubatian.cn/Flink%E9%83%A8%E7%BD%B2/</id>
    <published>2022-01-20T21:39:16.000Z</published>
    <updated>2022-01-23T02:58:21.611Z</updated>
    
    <content type="html"><![CDATA[<p>所处的位置不同，看到的风景和思考的问题也有所不同。——人民日报</p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_360.jpg" alt="blog: www.xubatian.cn"></p><h1 id="Standalone模式Flink自带的"><a href="#Standalone模式Flink自带的" class="headerlink" title="Standalone模式Flink自带的"></a>Standalone模式Flink自带的</h1><p>首先运行我们standalone的环境    </p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_361.png" alt="blog: www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_362.png" alt="blog: www.xubatian.cn"></p><p>解压缩  <strong>flink-1.7.2-bin-hadoop27-scala_2.11.tgz</strong>(如果你两个模式都想试一下就这个压缩包,实际上你要真正搭建独立模式只需要flink-1.7.2后面不需要接hadoop27-scala_2.11的压缩包)，进入conf目录中。</p><p>1）修改 flink/conf/flink-conf.yaml 文件：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_363.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_364.png"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_365.png"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">为了更好地看清图片内容,我复制出来这两行:</span><br><span class="line"><span class="meta">#</span><span class="bash"> The heap size <span class="keyword">for</span> the TaskManager JVM</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#整个TaskManager的内存大小</span></span></span><br><span class="line">taskmanager.heap.size: 1024m    </span><br><span class="line"></span><br><span class="line">下面是,这一个G的内存可以同时允许你同时并行运行多少个Task,每个task会占用一个插槽</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#插槽即可理解为流水槽,你的水从流水槽上流出去,这个slot就好比是两个木板上的流水槽,这个slot是TaskManager的</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#TaskManager说白了就暂时是我们的worker节点,实际上来说你也可以看成是executor节点也可以.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#但是这里和saprk的standalone去类比的话这就矛盾了,因为flink的TaskManager在这里有相当于executor,也相当</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#于worker.   spark的standalone模式中,一个worker下面可以有多个executor,每一个executor并行可以运行两个</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#以上的任务吗?可以的. 所以我们spark独立模式理解起来有点难度.他是一个worker下面有一个executor,executor下面</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#又可能会运行多个task,也可能只运行一个task.这对初学者不好理解.而这里我们的flink将他简化了,他把worker这</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 一层去掉了,worker这一层就是taskmanager,就还好比是executor一样.这个executor上到底运行了几个task是由</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># slot来决定的.即由插槽来决定的. 这里的插槽设置为1,表示每一个TaskManager上有多少个slot.这里是有1个slot.这就意味着</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#我这个taskmanager上只能同时运行一个任务.你如果想要增加我们的并行度,就必须修改插槽数量.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> taskmanager.numberOfTaskSlots: 1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改为3个插槽,表示每一个TaskManager里面有三个插槽,这三个插槽可以同时允许运行三个并行度,这三个并行度可以是不一样的广告</span></span><br><span class="line">taskmanager.numberOfTaskSlots: 3</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The parallelism used <span class="keyword">for</span> programs that did not specify and other parallelism.</span></span><br></pre></td></tr></table></figure><p>就只需要配置下面两个文件就可以了</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_366.png" alt="blog: www.xubatian.cn"></p><p>2）修改 /conf/slave文件：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_367.png" alt="blog: www.xubatian.cn"></p><p>3）分发给另外两台机子：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_368.png" alt="blog: www.xubatian.cn"></p><p>4）启动：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_369.png" alt="blog: www.xubatian.cn"></p><p>访问<a href="http://localhost:8081可以对flink集群和任务进行监控管理">http://localhost:8081可以对flink集群和任务进行监控管理</a></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_370.png" alt="blog: www.xubatian.cn"></p><h2 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;所处的位置不同，看到的风景和思考的问题也有所不同。——人民日报&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink简介</title>
    <link href="http://xubatian.cn/Flink%E7%AE%80%E4%BB%8B/"/>
    <id>http://xubatian.cn/Flink%E7%AE%80%E4%BB%8B/</id>
    <published>2022-01-19T07:57:22.000Z</published>
    <updated>2022-01-23T02:58:21.611Z</updated>
    
    <content type="html"><![CDATA[<p>一旦时机到来，我们要能迅速地发现时机、把握时机，不犹豫，不踌躇，乘风而起，破万里浪。——人民日报</p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/www.xubatian.cn_347.jpg" alt="blog: www.xubatian.cn"></p><h1 id="Flink简介"><a href="#Flink简介" class="headerlink" title="Flink简介"></a>Flink简介</h1><p>Flink其中一半是java语言开发的,另一半是scala语言开发的;spark的源码是scala语言开发的.但是scala是基于jvm的,所有的语法直接照着jvm调就可以了    </p><p>大数据中比较重要的框架,Hadoop(mapreduce),Spark,Flink,只有这三个才叫计算框架.<br>Flink,不管你是开发流式计算也好,还是做离线计算也好,还是做批量计算也好,他就是那一套代码,他不像Spark,Spark开发流式计算用的是SparkStreaming,用批量计算使用RDD,sparkCore<br>Flink有一套代码,但是他有很多套API<br>Flink有中文版,你发现Apache顶级项目有中文版的有那几个?他们的特点是什么?<br>因为他们50%以上的代码都是由中国人贡献的,Flink也一样,50%以上的代码是由中国国内贡献的</p><p>Flink和spark类似,他们的数据都是在内存中直接计算的,甚至他的状态都是存在内存中的 </p><p>Flink是默认就是有状态的计算,Flink中没有无状态这个说法但是spark中有无状态这种说法</p><p>flink的kappa架构怎么实现: <a href="https://www.jianshu.com/p/5f5736656bd5">https://www.jianshu.com/p/5f5736656bd5</a><br>Flink数据倾斜问题: <a href="https://www.cnblogs.com/qiu-hua/p/14056747.html">https://www.cnblogs.com/qiu-hua/p/14056747.html</a><br>                  <a href="https://www.cnblogs.com/Christbao/p/13569616.html">https://www.cnblogs.com/Christbao/p/13569616.html</a></p><p>但是实际上大数据量经常出现，一个 Flink 作业包含 200 个 Task 节点，其中有 199 个节点可以在很短的时间内完成计算。但是有一个节点执行时间远超其他结果，并且随着数据量的持续增加，导致该计算节点挂掉，从而整个任务失败重启。<br>我们可以在 Flink 的管理界面中看到任务的某一个 Task 数据量远超其他节点。<br>Flink 任务出现数据倾斜的直观表现是任务节点频繁出现反压，但是增加并行度后并不能解决问题；部分节点出现 OOM 异常，是因为大量的数据集中在某个节点上，导致该节点内存被爆，任务失败重启。</p><h2 id="初识Flink"><a href="#初识Flink" class="headerlink" title="初识Flink"></a>初识Flink</h2><p>Flink起源于Stratosphere项目，Stratosphere是在2010~2014年由3所地处柏林的大学和欧洲的一些其他的大学共同进行的研究项目，2014年4月Stratosphere的代码被复制并捐赠给了Apache软件基金会，参加这个孵化项目的初始成员是Stratosphere系统的核心开发人员，2014年12月，Flink一跃成为Apache软件基金会的顶级项目。<br>在德语中，Flink一词表示快速和灵巧，项目采用一只松鼠的彩色图案作为logo，这不仅是因为松鼠具有快速和灵巧的特点，还因为柏林的松鼠有一种迷人的红棕色，而Flink的松鼠logo拥有可爱的尾巴，尾巴的颜色与Apache软件基金会的logo颜色相呼应，也就是说，这是一只Apache风格的松鼠。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/www.xubatian.cn_348.png" alt="blog: www.xubatian.cn">Flink项目的理念是：“Apache Flink是为分布式、高性能、随时可用以及准确的流处理应用程序打造的开源流处理框架”。</p><p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img/www.xubatian.cn_349.png" alt="blog: www.xubatian.cn"></p><p>博主解析图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_350.png" alt="blog: www.xubatian.cn"></p><h2 id="Flink的重要特点"><a href="#Flink的重要特点" class="headerlink" title="Flink的重要特点"></a>Flink的重要特点</h2><h3 id="事件驱动型-Event-driven"><a href="#事件驱动型-Event-driven" class="headerlink" title="事件驱动型(Event-driven)"></a>事件驱动型(Event-driven)</h3><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_351.png" alt="blog: www.xubatian.cn"></p><p>事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据(其实就是他可以从多个源中读取数据)，并根据到来的事件触发计算(就是来一条数据立马计算不等待(计算是根据业务来的,可以做聚合计算等))、状态更新或其他外部动作。比较典型的就是以kafka为代表的消息队列几乎都是事件驱动型应用。</p><p>与之不同的就是SparkStreaming微批次，如图：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_352.png" alt="blog: www.xubatian.cn"></p><p>事件驱动型：</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_353.png" alt="blog: www.xubatian.cn"></p><p>博主解析图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_354.png" alt="blog: www.xubatian.cn"></p><h3 id="事件驱动型应用的优势？"><a href="#事件驱动型应用的优势？" class="headerlink" title="事件驱动型应用的优势？"></a>事件驱动型应用的优势？</h3><p>事件驱动型应用无须查询远程数据库，本地数据访问使得它具有更高的吞吐和更低的延迟。而由于定期向远程持久化存储的 checkpoint 工作可以异步、增量式完成，因此对于正常事件处理的影响甚微。事件驱动型应用的优势不仅限于本地数据访问。传统分层架构下，通常多个应用会共享同一个数据库，因而任何对数据库自身的更改（例如：由应用更新或服务扩容导致数据布局发生改变）都需要谨慎协调。反观事件驱动型应用，由于只需考虑自身数据，因此在更改数据表示或服务扩容时所需的协调工作将大大减少</p><h3 id="流与批的世界观"><a href="#流与批的世界观" class="headerlink" title="流与批的世界观"></a>流与批的世界观</h3><p>有界和无界分别对应的就是批处理和流处理<br><strong>批处理</strong>(就是所谓的有界数据)的特点是有界、持久、大量，非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。<br><strong>流处理</strong>(就是所谓的无界数据)的特点是无界、实时,  无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。<br>在spark的世界观中，一切都是由批次组成的，离线数据是一个大批次，而实时数据是由一个一个无限的小批次组成的。<br>而在flink的世界观中，一切都是由流组成的，离线数据是有界限的流，实时数据是一个没有界限的流，这就是所谓的有界流和无界流。</p><p><strong>无界数据流</strong>：无界数据流有一个开始但是没有结束，它们不会在生成时终止并提供数据，必须连续处理无界流，也就是说必须在获取后立即处理event。对于无界数据流我们无法等待所有数据都到达，因为输入是无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序（例如事件发生的顺序）获取event，以便能够推断结果完整性。</p><p><strong>有界数据流</strong>：有界数据流有明确定义的开始和结束，可以在执行任何计算之前通过获取所有数据来处理有界流，处理有界流不需要有序获取，因为可以始终对有界数据集进行排序，有界流的处理也称为批处理。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_355.png" alt="blog: www.xubatian.cn"></p><p>这种以流为世界观的架构，获得的最大好处就是具有极低的延迟。</p><p>博主解析图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_356.png" alt="blog: www.xubatian.cn"></p><h3 id="分层API"><a href="#分层API" class="headerlink" title="分层API"></a>分层API</h3><p>(对于我们学flink来说,我们三层都必须得会,经常用到的是中间那层DataStream API)<br>Flink他本质上把批量的数据和流数据都看成是流了,所以他本质上是流处理,所以他也可以做批处理,他和saprk相反,spark把所有的数据都看成是批处理了,但是spark也是可以做流处理的<br>记住: DataStream API做流处理,流处理是无界的  DataSetAPI是做批处理是有界的    </p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_357.png" alt="blog: www.xubatian.cn"></p><p>分层API是Flink根据抽象程度,提供的三种不同的API,所谓抽象程度就是看你封装的程度,如果你不怎么封装,那就是底层的API,稍微封装一下就叫中间的API,封装的很厉害就叫高级API.</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_358.png" alt="blog: www.xubatian.cn"></p><p>最底层级的抽象仅仅提供了有状态流，它将通过过程函数（Process Function）被嵌入到DataStream API中。底层过程函数（Process Function） 与 DataStream API 相集成，使其可以对某些特定的操作进行底层的抽象，它允许用户可以自由地处理来自一个或多个数据流的事件，并使用一致的容错的状态。除此之外，用户可以注册事件时间并处理时间回调，从而使程序可以处理复杂的计算。</p><p>实际上，大多数应用并不需要上述的底层抽象，而是针对核心API（Core APIs） 进行编程，比如DataStream API（有界或无界流数据）以及DataSet API（有界数据集）。这些API为数据处理提供了通用的构建模块，比如由用户定义的多种形式的转换（transformations），连接（joins），聚合（aggregations），窗口操作（windows）等等。DataSet API 为有界数据集提供了额外的支持，例如循环与迭代。这些API处理的数据类型以类（classes）的形式由各自的编程语言所表示。</p><p>Table API 是以表为中心的声明式编程，其中表可能会动态变化（在表达流数据时）。Table API遵循（扩展的）关系模型：表有二维数据结构（schema）（类似于关系数据库中的表），同时API提供可比较的操作，例如select、project、join、group-by、aggregate等。Table API程序声明式地定义了什么逻辑操作应该执行，而不是准确地确定这些操作代码的看上去如何。</p><p>尽管Table API可以通过多种类型的用户自定义函数（UDF）进行扩展，其仍不如核心API更具表达能力，但是使用起来却更加简洁（代码量更少）。除此之外，Table API程序在执行之前会经过内置优化器进行优化。<br>你可以在表与 DataStream/DataSet 之间无缝切换，以允许程序将 Table API 与 DataStream 以及 DataSet 混合使用。</p><p>Flink提供的最高层级的抽象是 SQL 。这一层抽象在语法与表达能力上与 Table API 类似，但是是以SQL查询表达式的形式表现程序。SQL抽象与Table API交互密切，同时SQL查询可以直接在Table API定义的表上执行。</p><p>目前Flink作为批处理还不是主流，不如Spark成熟，所以DataSet使用的并不是很多。Flink Table API和Flink SQL也并不完善，大多都由各大厂商自己定制。所以我们主要学习DataStream API的使用。实际上Flink作为最接近Google DataFlow模型的实现，是流批统一的观点，所以基本上使用DataStream就可以了。<br>Flink几大模块<br>Flink Table &amp; SQL(还没开发完)<br>Flink Gelly(图计算)<br>Flink CEP(复杂事件处理)</p><p>Flink官方给你提供的连接器,虽然都是flink的,但是他来自两个不同的库,一个来自flink的,一个来自Bahir的</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_359.png" alt="blog: www.xubatian.cn"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一旦时机到来，我们要能迅速地发现时机、把握时机，不犹豫，不踌躇，乘风而起，破万里浪。——人民日报&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Flink" scheme="http://xubatian.cn/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>SparkCore之RDD编程的编程模型</title>
    <link href="http://xubatian.cn/SparkCore%E4%B9%8BRDD%E7%BC%96%E7%A8%8B%E7%9A%84%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
    <id>http://xubatian.cn/SparkCore%E4%B9%8BRDD%E7%BC%96%E7%A8%8B%E7%9A%84%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/</id>
    <published>2022-01-19T06:50:36.000Z</published>
    <updated>2022-01-23T02:58:21.755Z</updated>
    
    <content type="html"><![CDATA[<p>闲适因为忙碌才获得意义。如果摸鱼成为常态，放松就失去了意义；如果划水占据人生，幸福就会失去方向。               ——人民日报    </p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_340.jpg" alt="blog: www.xubatian.cn"></p><h1 id="RDD编程"><a href="#RDD编程" class="headerlink" title="RDD编程"></a>RDD编程</h1><p>创建RDD ,RDD的转换, RDD的输出</p><h2 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h2><p>在spark中无论是Transformations方法还是Actions方法,我们都要把他们称作算子</p><p>在Spark中，RDD被表示为对象，通过对象上的方法调用来对RDD进行转换。经过一系列的Transformations(转换)定义RDD之后，就可以调用Actions(行动)触发RDD的计算，Action可以是向应用程序返回结果(count, collect等)，或者是向存储系统保存数据(saveAsTextFile等)。在Spark中，只有遇到Action，才会执行RDD的计算(即延迟计算)，这样在运行时可以通过管道的方式传输多个转换。 </p><p>要使用Spark，开发者需要编写一个Driver程序，它被提交到集群以调度运行。Driver中定义了一个或多个RDD，并调用RDD上的Action，Executor则执行RDD分区计算任务。</p><p>Actions(行动)算子会真正的去触发job去执行<br>Transformation(转换)算子懒执行<br>所以返回值是RDD类型的是Transformation算子,返回值非RDD类型就是Action算子</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_341.png" alt="blog: www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_342.png" alt="blog: www.xubatian.cn"></p><h2 id="RDD的创建"><a href="#RDD的创建" class="headerlink" title="RDD的创建"></a>RDD的创建</h2><p>在Spark中创建RDD的创建方式可以分为三种：<br>从scala集合中创建RDD；<br>从外部存储创建RDD；<br>从其他RDD创建(这个其实讲的就是转换)。</p><h3 id="从集合中创建"><a href="#从集合中创建" class="headerlink" title="从集合中创建"></a>从集合中创建</h3><p>从集合中创建RDD，Spark主要提供了两种函数：parallelize(并行化)和makeRDD(创建RDD)</p><p>1）使用parallelize()从集合创建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val rdd = sc.parallelize(Array(1,2,3,4,5,6,7,8))</span><br><span class="line">rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:24</span><br></pre></td></tr></table></figure><p>2）使用makeRDD()从集合创建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val rdd1 = sc.makeRDD(Array(1,2,3,4,5,6,7,8))</span><br><span class="line">rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[1] at makeRDD at &lt;console&gt;:24</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_343.png" alt="blog: www.xubatian.cn"></p><h3 id="由外部存储系统的数据集创建"><a href="#由外部存储系统的数据集创建" class="headerlink" title="由外部存储系统的数据集创建"></a>由外部存储系统的数据集创建</h3><p>包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase等，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val rdd2= sc.textFile(&quot;hdfs://hadoop102:9000/RELEASE&quot;)</span><br><span class="line">rdd2: org.apache.spark.rdd.RDD[String] = hdfs://hadoop102:9000/RELEASE MapPartitionsRDD[4] at textFile at &lt;console&gt;:24</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="从其他RDD创建"><a href="#从其他RDD创建" class="headerlink" title="从其他RDD创建"></a>从其他RDD创建</h3><p>下面都是…此处略</p><h2 id="RDD的转换"><a href="#RDD的转换" class="headerlink" title="RDD的转换"></a>RDD的转换</h2><p>RDD整体上分为Value类型和Key-Value类型,  K-V形式其实也是value类型<br>eg:   (k,(k,v))是value, 是不是kv? 是,只不过value类型是二元组.<br>如果是单个值, 是value, 如果是形如二元组是K,V.  k,v形式是value类型, 我把整个k,v元组当成整体来看,他就是value类型.  他们两是包含的关系. 所有的RDD都可以看做是value类型, 只过不特殊的我们拎出来,如k-v等等</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_344.png" alt="blog: www.xubatian.cn"></p><h3 id="Value类型"><a href="#Value类型" class="headerlink" title="Value类型"></a>Value类型</h3><p>什么叫做value类型呢?<br>因为他里面传的函数都是操作当前这个RDD里面的元素. 可能是单个元素, 可能是一个分区里面的元素.但是他操作的是里面的数据.<br>什么叫双value类型呢?<br>双value类型它里面传的参数是任意一个RDD.<br>Eg : RDD1.调用一个算子(RDD2)<br>以为之前提过, scala也好,spark也好,他是面向数据处理的. 那这个双value类型就是数学里面的,集合之间的关系. 集合里面有哪些关系呢? 并集, 交叉 ,笛卡尔集</p><h4 id="map-func-案例"><a href="#map-func-案例" class="headerlink" title="map(func)案例"></a>map(func)案例</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 作用：返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成</span><br><span class="line">2. 需求：创建一个1-10数组的RDD，将所有元素*2形成新的RDD</span><br></pre></td></tr></table></figure><p>  (1)   创建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; var source  = sc.parallelize(1 to 10)</span><br><span class="line"></span><br><span class="line">source: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[8] at parallelize at &lt;console&gt;:24</span><br></pre></td></tr></table></figure><p>（2）打印</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; source.collect()</span><br><span class="line"></span><br><span class="line">res7: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</span><br></pre></td></tr></table></figure><p>（3）将所有元素*2</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val mapadd = source.map(_ * 2)</span><br><span class="line">这个map是算子</span><br><span class="line"></span><br><span class="line">mapadd: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[9] at map at &lt;console&gt;:26</span><br></pre></td></tr></table></figure><p>（4）打印最终结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; mapadd.collect()</span><br><span class="line"></span><br><span class="line">res8: Array[Int] = Array(2, 4, 6, 8, 10, 12, 14, 16, 18, 20)</span><br></pre></td></tr></table></figure><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_345.png" alt="blog: www.xubatian.cn"></p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_346.png" alt="blog: www.xubatian.cn"></p><h3 id="双Value类型交互"><a href="#双Value类型交互" class="headerlink" title="双Value类型交互"></a>双Value类型交互</h3><p>以后慢慢写……</p><h3 id="Key-Value类型"><a href="#Key-Value类型" class="headerlink" title="Key-Value类型"></a>Key-Value类型</h3><p>以后慢慢写……</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;闲适因为忙碌才获得意义。如果摸鱼成为常态，放松就失去了意义；如果划水占据人生，幸福就会失去方向。               ——人民日报    &lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="spark" scheme="http://xubatian.cn/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>SparkCore之RDD概述</title>
    <link href="http://xubatian.cn/SparkCore%E4%B9%8BRDD%E6%A6%82%E8%BF%B0/"/>
    <id>http://xubatian.cn/SparkCore%E4%B9%8BRDD%E6%A6%82%E8%BF%B0/</id>
    <published>2022-01-19T06:22:21.000Z</published>
    <updated>2022-01-23T02:58:21.728Z</updated>
    
    <content type="html"><![CDATA[<p>仰观天宇，时间更加深邃；俯身耕耘，未来无限可能                  ——人民日报    </p><span id="more"></span><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_331.jpg" alt="blog: www.xubatian.cn"></p><p>我们Spark中的stage是按照shuffle来切的.</p><h1 id="RDD概述"><a href="#RDD概述" class="headerlink" title="RDD概述"></a>RDD概述</h1><h2 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h2><p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象。代码中是一个抽象类，它代表一个弹性的(分区)、不可变(元素)、可分区、里面的元素可并行计算的集合。</p><p>RDD是抽象类</p><h2 id="RDD的属性"><a href="#RDD的属性" class="headerlink" title="RDD的属性"></a>RDD的属性</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_332.png" alt="blog: www.xubatian.cn"></p><p>（1）一组分区（Partition）,切片和分区是一样的，即数据集的基本组成单位；<br>（2）一个计算每个分区的函数；<br>（3）RDD之间的依赖关系；<br>（4）一个Partitioner，即RDD的分片函数；<br>（5）一个列表，存储存取每个Partition的优先位置（preferred location）。</p><h2 id="RDD特点"><a href="#RDD特点" class="headerlink" title="RDD特点"></a>RDD特点</h2><p>RDD表示只读(不可变性)的分区的数据集，对RDD进行改动，只能通过RDD的转换操作，由一个RDD得到一个新的RDD，新的RDD包含了从其他RDD衍生所必需的信息。RDDs之间存在依赖，RDD的执行是按照血缘关系延时计算的。如果血缘关系较长，可以通过持久化RDD来切断血缘关系。</p><h2 id="弹性"><a href="#弹性" class="headerlink" title="弹性"></a>弹性</h2><p>存储的弹性：内存与磁盘的自动切换；<br>容错的弹性：数据丢失可以自动恢复；<br>计算的弹性：计算出错重试机制；<br>分片的弹性：可根据需要重新分片。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_333.png" alt="blog: www.xubatian.cn"></p><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>RDD逻辑上是分区的，每个分区的数据是抽象存在的，计算的时候会通过一个compute(计算)函数得到每个分区的数据。如果RDD是通过已有的文件系统构建，则compute(计算)函数是读取指定文件系统中的数据，如果RDD是通过其他RDD转换而来，则compute(计算)函数是执行转换逻辑将其他RDD的数据进行转换</p><h2 id="只读"><a href="#只读" class="headerlink" title="只读"></a>只读</h2><p>RDD是只读的（元素不可变），要想改变RDD中的数据，只能在现有的RDD基础上创建新的RDD。<br>由一个RDD转换到另一个RDD，可以通过丰富的操作算子实现，不再像MapReduce那样只能写map和reduce了。</p><p>RDD的操作算子包括两类，<br>一类叫做Transformations(转换)，它是用来将RDD进行转化，构建RDD的血缘关系；<br>另一类叫做Actions(行动)，它是用来触发RDD的计算，得到RDD的相关计算结果或者将RDD保存的文件系统中。下图是RDD所支持的操作算子列表。</p><h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2><p>RDDs通过操作算子进行转换，转换得到的新RDD包含了从其他RDDs衍生所必需的信息，RDDs之间维护着这种血缘关系，也称之为依赖。如下图所示，</p><p>依赖包括两种，<br>一种是窄依赖，RDDs之间分区是一一对应的，<br>另一种是宽依赖，下游RDD的每个分区与上游RDD(也称之为父RDD)的每个分区都有关，是多对多的关系。(一对一,多对多指的是分区) </p><p>这里的一对一,一对多指的是分区</p><p>注意: 依赖和shuffle有关系</p><p>原图:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_334.png" alt="blog: www.xubatian.cn"></p><p>博主解读:</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_336.png" alt="blog: www.xubatian.cn"></p><p>父RDD中的全部数据被某一个子RDD的某个分区全部拥有我们叫窄依赖</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_337.png" alt="blog: www.xubatian.cn"></p><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>如果在应用程序中多次使用同一个RDD，可以将该RDD缓存起来，该RDD只有在第一次计算的时候会根据血缘关系得到分区的数据，在后续其他地方用到该RDD的时候，会直接从缓存处取而不用再根据血缘关系计算，这样就加速后期的重用。如下图所示，RDD-1经过一系列的转换后得到RDD-n并保存到hdfs，RDD-1在这一过程中会有个中间结果，如果将其缓存到内存，那么在随后的RDD-1转换到RDD-m这一过程中，就不会计算其之前的RDD-0了。</p><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_338.png" alt="blog: www.xubatian.cn"></p><h2 id="CheckPoint"><a href="#CheckPoint" class="headerlink" title="CheckPoint"></a>CheckPoint</h2><p>切断血缘关系后可以从CheckPoint中拿数据</p><p>虽然RDD的血缘关系天然地可以实现容错，当RDD的某个分区数据失败或丢失，可以通过血缘关系重建。但是对于长时间迭代型应用来说，随着迭代的进行，RDDs之间的血缘关系会越来越长，一旦在后续迭代过程中出错，则需要通过非常长的血缘关系去重建，势必影响性能。为此，RDD支持checkpoint将数据保存到持久化的存储中，这样就可以切断之前的血缘关系，因为checkpoint后的RDD不需要知道它的父RDDs了，它可以从checkpoint处拿到数据。</p><p>checkPoint将数据持久化了之后他就会切断血缘关系, 因为他认为你持久化到文件当中后这个数据就不会丢了,这个依赖关系就不需要了,就切断了. 因为你是文件嘛, 而且默认一般存在hdfs中,hdfs又默认有三个副本. 所以他觉得你数据不会丢了. 既然不会丢了,依赖关系就不要了, 因为依赖关系就是防止你数据丢了重新计算做数据恢复的.</p><p>但是你缓存到内存当中,你不能将依赖切断, 因为内存当中数据可能会掉的.他可能还要用这个依赖关系重新做计算的.</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://xubatian.oss-cn-hangzhou.aliyuncs.com/xubatian_blogs_img2/aliyun/www.xubatian.cn_339.png" alt="blog: www.xubatian.cn"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;仰观天宇，时间更加深邃；俯身耕耘，未来无限可能                  ——人民日报    &lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="http://xubatian.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="spark" scheme="http://xubatian.cn/tags/spark/"/>
    
  </entry>
  
</feed>
